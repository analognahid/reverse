{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af388b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahid/anaconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de072e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os, pickle\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "\n",
    "\n",
    "with (open('DFGDATA.pkl' , \"rb\")) as openfile:\n",
    "    all_input_list , all_label_list = pickle.load(openfile)\n",
    "\n",
    "\n",
    "# input_text = [\"I love apples.\", \"She hates oranges.\", \"I enjoy reading books.\", \"He likes playing football.\"]\n",
    "\n",
    "# labels_task1 = [0, 1,0,1]  # Example task 1 labels\n",
    "# labels_task2 = [2, 3,4,5]  # Example task 2 labels\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "input_text = all_input_list#[:80]\n",
    "labels_dfg = all_label_list#[:80]\n",
    "\n",
    "labels_dfg =  torch.LongTensor(labels_dfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a256faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE :  7718\n"
     ]
    }
   ],
   "source": [
    "tokenizer  = BertTokenizer.from_pretrained(\"./binary-tokenizer\")\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "\n",
    "print('VOCAB SIZE : ', (tokenizer.vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8755564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# tokenizer.eos_token = \"<EOI>\"\n",
    "\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac256125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_collator(input_text_task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88bd9a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO fix inputs = tokenizer(history, next_instruction, return_tensors='pt', \n",
    "#                    max_length=64, truncation=True, padding='max_length')\n",
    "\n",
    "# Tokenize input text\n",
    "inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt',)\n",
    "# encoded_inputs_task2 = tokenizer(input_text_task2, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c82fd9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels_dfg'] = labels_dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f369c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLM\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "inputs.labels[0]\n",
    "\n",
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "        (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "\n",
    "#TODO FIX 101, 102\n",
    "\n",
    "# mask_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d919b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )\n",
    "# selection[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cb577f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58e34ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels_dfg', 'labels'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81a59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70219d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels_dfg', 'labels'])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.keys())\n",
    "print(inputs.token_type_ids)\n",
    "inputs.token_type_ids[0][0] =1\n",
    "print(inputs.token_type_ids)\n",
    "#TODO set token type ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd332543",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6640b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BinaryDataset(inputs)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "validation_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size])\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82ddc34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# Define the multitask BERT model\n",
    "\n",
    "hidden_size = BertModel.from_pretrained('bert-base-uncased').config.hidden_size\n",
    "# vocab_size = bert_model.config.vocab_size\n",
    "class MultitaskBert(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultitaskBert, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased') #BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc = nn.Linear(  hidden_size , VOCAB_SIZE)\n",
    "        self.dfg_classifier = nn.Linear(hidden_size, 2) #todo was 768 num_classes_task2\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask ):\n",
    "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        hidden_states = bert_outputs.last_hidden_state\n",
    "        logits_mlm = self.fc(hidden_states)\n",
    "        \n",
    "        bert_pooled_output = bert_outputs.pooler_output\n",
    "        logits_dfg = self.dfg_classifier(bert_pooled_output)\n",
    "        \n",
    "        \n",
    "        return logits_mlm,   logits_dfg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4054b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "model = MultitaskBert()  # Example number of classes for each task\n",
    "model.to(device)\n",
    "\n",
    "# initialize optimizer\n",
    "optim = AdamW( model.parameters() , lr=5e-6)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9fb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/7706 [00:00<?, ?it/s]/tmp/ipykernel_51065/3277124069.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|████████████████| 7706/7706 [1:05:40<00:00,  1.96it/s, loss=0.756]\n",
      "Epoch 1:  59%|███████████▊        | 4545/7706 [39:03<27:14,  1.93it/s, loss=1.1]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "global_instruction_metrices = []\n",
    "global_token_metrices = []\n",
    "\n",
    "v_global_instruction_metrices = []\n",
    "v_global_token_metrices = []\n",
    "\n",
    "for ecpoch in range(EPOCHS):\n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    for N,batch in enumerate(train_loop):\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        optim.zero_grad()\n",
    "        # logits_task1, logits_task2 , t1_outputs,t2_outputs = model(inputs['input_ids'], inputs['attention_mask'], inputs['input_ids'], inputs['attention_mask'])\n",
    "\n",
    "        logits_task1,   logits_task2 = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
    "#         print(logits_task1.shape, logits_task2.shape)\n",
    "#         print(logits_task1.shape , batch['labels'].shape)\n",
    "#         logits_task1.view(-1, VOCAB_SIZE).shape ,batch['labels'].view(-1).shape\n",
    "        \n",
    "        loss_task1 = criterion(logits_task1.view(-1, VOCAB_SIZE), batch['labels'].to(device).view(-1))\n",
    "        predictions_task1 = torch.argmax(logits_task1, dim=2)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        loss_task2 = criterion(logits_task2, batch['labels_dfg'].to(device))\n",
    "        predictions_task2 = torch.argmax(logits_task2, dim=1)\n",
    "        \n",
    "        (loss_task1+loss_task2).backward()\n",
    "        optim.step()\n",
    "        \n",
    "        \n",
    "        # print relevant info to progress bar\n",
    "        train_loop.set_description(f'Epoch {ecpoch}')\n",
    "        train_loop.set_postfix(loss=(loss_task1+loss_task2).item())\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec4a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef7b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
