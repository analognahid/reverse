{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Instruction Prediction Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahid/anaconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys,os\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from elftools.elf.segments import Segment\n",
    "\n",
    "filePath = './../../binaries/gnuit/src/gitfm'\n",
    "fh = open(filePath, 'rb')\n",
    "bin_bytearray = bytearray(fh.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from capstone import *\n",
    "\n",
    "from capstone.x86 import *\n",
    "\n",
    "\n",
    "address_inst = {}\n",
    "with open('./data/instruction_clusters.txt', 'w') as data_file:\n",
    "    with open(filePath, 'rb') as f:\n",
    "        elf = ELFFile(f)\n",
    "        dwarfinfo = elf.get_dwarf_info()\n",
    "        aranges = dwarfinfo.get_aranges()\n",
    "        print(len(aranges.entries))\n",
    "    #     for arange in aranges.entries:\n",
    "    #         print(arange)\n",
    "        for arange in aranges.entries:\n",
    "\n",
    "            entry = arange.begin_addr\n",
    "            exit  = arange.begin_addr + arange.length\n",
    "            ops = bin_bytearray[entry: exit]\n",
    "\n",
    "            md = Cs(CS_ARCH_X86, CS_MODE_64)\n",
    "            md.detail = True\n",
    "            for inst in md.disasm(ops, entry):\n",
    "\n",
    "                address_inst[hex(inst.address)] = inst\n",
    "                data_file.write(inst.mnemonic+\" \"+inst.op_str+\";\")\n",
    "            data_file.write('\\n')\n",
    "    #             print( inst.mnemonic+\"  \"+inst.op_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./binary-tokenizer\")\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "delim = ';'\n",
    "with open('./data/instruction_clusters.txt', 'r') as fp:\n",
    "    text = fp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'endbr64 ;push rbp;mov rbp, rsp;mov eax, dword ptr [rip + 0x2b9f5];cmp eax, 6;jle 0x501a;mov eax, dword ptr [rip + 0x2a036];test eax, eax;je 0x5008;mov eax, dword ptr [rip + 0x2b9e4];cmp eax, 0xb;jle 0x501a;mov eax, 1;jmp 0x501f;mov eax, dword ptr [rip + 0x2b9d2];cmp eax, 5;jle 0x501a;mov eax, 1;jmp 0x501f;mov eax, 0;pop rbp;ret ;'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split sentences into consecutive, and non-consecutive sequences.\n",
    "\n",
    "We have to deal with edge-cases too - for example where there is only a single sentence within a paragraph as with the three examples above (in comparison to below where we can easily split into multiple sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x10',\n",
       " 'mov dword ptr [rbp - 4], edi',\n",
       " 'mov eax, dword ptr [rip + 0x24da4]',\n",
       " 'cmp eax, 1',\n",
       " 'jne 0xbc8e',\n",
       " 'movzx eax, byte ptr [rip + 0x24d8d]',\n",
       " 'movzx eax, al',\n",
       " 'sar eax, 6',\n",
       " 'and eax, 1',\n",
       " 'cmp dword ptr [rbp - 4], eax',\n",
       " 'je 0xbd57',\n",
       " 'cmp dword ptr [rbp - 4], 1',\n",
       " 'jne 0xbcc1',\n",
       " 'mov rax, qword ptr [rip + 0x2404d]',\n",
       " 'test rax, rax',\n",
       " 'je 0xbd2e',\n",
       " 'mov rax, qword ptr [rip + 0x2403d]',\n",
       " 'lea rdx, [rip - 0xc66]',\n",
       " 'mov esi, 1',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x47e0',\n",
       " 'jmp 0xbd2e',\n",
       " 'mov rax, qword ptr [rip + 0x23fe0]',\n",
       " 'test rax, rax',\n",
       " 'je 0xbce8',\n",
       " 'mov rax, qword ptr [rip + 0x23fd4]',\n",
       " 'lea rdx, [rip - 0xc8f]',\n",
       " 'mov esi, 1',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x47e0',\n",
       " 'mov dword ptr [rip + 0x24d1a], 0',\n",
       " 'mov dword ptr [rip + 0x24d14], 0',\n",
       " 'movzx eax, byte ptr [rip + 0x24d06]',\n",
       " 'and eax, 0xffffffbf',\n",
       " 'mov byte ptr [rip + 0x24cfd], al',\n",
       " 'movzx eax, byte ptr [rip + 0x24cf6]',\n",
       " 'shr al, 7',\n",
       " 'cmp al, 1',\n",
       " 'jne 0xbd2e',\n",
       " 'mov dword ptr [rip + 0x24cf4], 0',\n",
       " 'mov edi, 1',\n",
       " 'call 0xbd5a',\n",
       " 'mov dword ptr [rip + 0x24cdc], 1',\n",
       " 'movzx eax, byte ptr [rip + 0x24cca]',\n",
       " 'and eax, 0xffffffbf',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rbp - 4]',\n",
       " 'shl eax, 6',\n",
       " 'and eax, 0x40',\n",
       " 'or eax, edx',\n",
       " 'mov byte ptr [rip + 0x24cb4], al',\n",
       " 'jmp 0xbd58',\n",
       " 'nop ',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[51].split(delim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assign a 50% probability of using the genuine next sentence, and 50% probability of using another random sentence.\n",
    "\n",
    "To make this simpler, we'll create a *'bag'* of individual sentences to pull from when selecting a random sentence B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33455\n"
     ]
    }
   ],
   "source": [
    "bag = [instruction for instruction_cluster in text for instruction in instruction_cluster.split(delim)  if instruction!= '']\n",
    "bag_size = len(bag)\n",
    "print(bag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call 0x4810',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'mov eax, dword ptr [rip + 0x2b9f5]',\n",
       " 'cmp eax, 6',\n",
       " 'jle 0x501a',\n",
       " 'mov eax, dword ptr [rip + 0x2a036]',\n",
       " 'test eax, eax',\n",
       " 'je 0x5008',\n",
       " 'mov eax, dword ptr [rip + 0x2b9e4]',\n",
       " 'cmp eax, 0xb',\n",
       " 'jle 0x501a',\n",
       " 'mov eax, 1',\n",
       " 'jmp 0x501f',\n",
       " 'mov eax, dword ptr [rip + 0x2b9d2]',\n",
       " 'cmp eax, 5',\n",
       " 'jle 0x501a',\n",
       " 'mov eax, 1',\n",
       " 'jmp 0x501f',\n",
       " 'mov eax, 0',\n",
       " 'pop rbp',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'mov eax, dword ptr [rip + 0x2b8b1]',\n",
       " 'cmp eax, 1',\n",
       " 'sete al',\n",
       " 'movzx eax, al',\n",
       " 'pop rbp',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'push rbx',\n",
       " 'sub rsp, 0x38',\n",
       " 'mov dword ptr [rbp - 0x34], edi',\n",
       " 'mov dword ptr [rbp - 0x28], 0',\n",
       " 'mov dword ptr [rbp - 0x24], 0',\n",
       " 'mov eax, dword ptr [rip + 0x2b97e]',\n",
       " 'mov dword ptr [rbp - 0x20], eax',\n",
       " 'mov eax, dword ptr [rip + 0x2b979]',\n",
       " 'mov dword ptr [rbp - 0x1c], eax',\n",
       " 'mov eax, 0',\n",
       " 'call 0xc866',\n",
       " 'cmp dword ptr [rbp - 0x34], 0',\n",
       " 'jne 0x5094',\n",
       " 'mov eax, dword ptr [rip + 0x2b95c]',\n",
       " 'cmp dword ptr [rbp - 0x20], eax',\n",
       " 'jne 0x5094',\n",
       " 'mov eax, dword ptr [rip + 0x2b955]',\n",
       " 'cmp dword ptr [rbp - 0x1c], eax',\n",
       " 'je 0x5360',\n",
       " 'mov eax, dword ptr [rip + 0x2b9a6]',\n",
       " 'test eax, eax',\n",
       " 'je 0x50ce',\n",
       " 'mov edx, dword ptr [rip + 0x2b93c]',\n",
       " 'mov eax, dword ptr [rip + 0x2b932]',\n",
       " 'imul eax, edx',\n",
       " 'add eax, 2',\n",
       " 'add eax, eax',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0x2b83c]',\n",
       " 'mov rsi, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x24670',\n",
       " 'mov qword ptr [rip + 0x2b82a], rax',\n",
       " 'mov eax, dword ptr [rip + 0x2b908]',\n",
       " 'cmp eax, 1',\n",
       " 'jle 0x50e0',\n",
       " 'mov dword ptr [rbp - 0x24], 1',\n",
       " 'mov eax, dword ptr [rip + 0x2b8f6]',\n",
       " 'cmp eax, 2',\n",
       " 'jle 0x50f2',\n",
       " 'mov dword ptr [rbp - 0x28], 1',\n",
       " 'mov eax, 0',\n",
       " 'call 0x4fd9',\n",
       " 'test eax, eax',\n",
       " 'je 0x529e',\n",
       " 'mov eax, dword ptr [rip + 0x29f1e]',\n",
       " 'test eax, eax',\n",
       " 'je 0x5234',\n",
       " 'mov eax, dword ptr [rip + 0x2b8c8]',\n",
       " 'sar eax, 1',\n",
       " 'mov dword ptr [rbp - 0x18], eax',\n",
       " 'mov eax, dword ptr [rip + 0x2b8bd]',\n",
       " 'and eax, 1',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rbp - 0x18]',\n",
       " 'add eax, edx',\n",
       " 'mov dword ptr [rbp - 0x14], eax',\n",
       " 'mov rax, qword ptr [rip + 0x2b7d9]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x10ced',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xdc6b',\n",
       " 'mov ebx, eax',\n",
       " 'mov rax, qword ptr [rip + 0x2b7c8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x10ced',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xdc6b',\n",
       " 'cmp ebx, eax',\n",
       " 'jg 0x51cc',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'movsxd rcx, eax',\n",
       " 'mov eax, dword ptr [rip + 0x2b86c]',\n",
       " 'sub eax, 3',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0x2b793]',\n",
       " 'mov r8, rcx',\n",
       " 'mov rcx, rdx',\n",
       " 'mov edx, 1',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x11348',\n",
       " 'mov eax, dword ptr [rbp - 0x18]',\n",
       " 'movsxd rcx, eax',\n",
       " 'mov eax, dword ptr [rip + 0x2b83b]',\n",
       " 'sub eax, 3',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'movsxd rsi, eax',\n",
       " 'mov rax, qword ptr [rip + 0x2b764]',\n",
       " 'mov r8, rcx',\n",
       " 'mov rcx, rdx',\n",
       " 'mov edx, 1',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x11348',\n",
       " 'jmp 0x52e6',\n",
       " 'mov eax, dword ptr [rbp - 0x18]',\n",
       " 'movsxd rcx, eax',\n",
       " 'mov eax, dword ptr [rip + 0x2b804]',\n",
       " 'sub eax, 3',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'movsxd rsi, eax',\n",
       " 'mov rax, qword ptr [rip + 0x2b725]',\n",
       " 'mov r8, rcx',\n",
       " 'mov rcx, rdx',\n",
       " 'mov edx, 1',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x11348',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'movsxd rcx, eax',\n",
       " 'mov eax, dword ptr [rip + 0x2b7d2]',\n",
       " 'sub eax, 3',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0x2b701]',\n",
       " 'mov r8, rcx',\n",
       " 'mov rcx, rdx',\n",
       " 'mov edx, 1',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x11348',\n",
       " 'jmp 0x52e6',\n",
       " 'mov eax, dword ptr [rip + 0x2b7a6]',\n",
       " 'movsxd rcx, eax',\n",
       " 'mov eax, dword ptr [rip + 0x2b799]',\n",
       " 'sub eax, 3',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0x2b6c0]',\n",
       " 'mov r8, rcx',\n",
       " 'mov rcx, rdx',\n",
       " 'mov edx, 1',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x11348',\n",
       " 'mov eax, dword ptr [rip + 0x2b772]',\n",
       " 'movsxd rcx, eax',\n",
       " 'mov eax, dword ptr [rip + 0x2b765]',\n",
       " 'sub eax, 3',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0x2b694]',\n",
       " 'mov r8, rcx',\n",
       " 'mov rcx, rdx',\n",
       " 'mov edx, 1',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x11348',\n",
       " 'jmp 0x52e6',\n",
       " 'mov rax, qword ptr [rip + 0x2b66b]',\n",
       " 'mov r8d, 0x50',\n",
       " 'mov ecx, 2',\n",
       " 'mov edx, 0x10000',\n",
       " 'mov esi, 0x10000',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x11348',\n",
       " 'mov rax, qword ptr [rip + 0x2b64f]',\n",
       " 'mov r8d, 0x50',\n",
       " 'mov ecx, 2',\n",
       " 'mov edx, 0x10000',\n",
       " 'mov esi, 0x10000',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x11348',\n",
       " 'cmp dword ptr [rbp - 0x28], 0',\n",
       " 'je 0x52f6',\n",
       " 'mov eax, dword ptr [rip + 0x2b6ee]',\n",
       " 'cdqe ',\n",
       " 'jmp 0x52fb',\n",
       " 'mov eax, 0',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x1c4e9',\n",
       " 'mov eax, dword ptr [rip + 0x2b6ce]',\n",
       " 'sub eax, 1',\n",
       " 'movsxd rdx, eax',\n",
       " 'cmp dword ptr [rbp - 0x24], 0',\n",
       " 'je 0x5324',\n",
       " 'mov eax, dword ptr [rip + 0x2b6c0]',\n",
       " 'cdqe ',\n",
       " 'jmp 0x5329',\n",
       " 'mov eax, 0',\n",
       " 'mov rsi, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x10167',\n",
       " 'mov eax, dword ptr [rip + 0x2b6a2]',\n",
       " 'cmp eax, 1',\n",
       " 'je 0x534a',\n",
       " 'mov eax, dword ptr [rip + 0x2b697]',\n",
       " 'lea edx, [rax - 2]',\n",
       " 'jmp 0x534f',\n",
       " 'mov edx, 0',\n",
       " 'mov eax, dword ptr [rip + 0x2b68b]',\n",
       " 'mov esi, edx',\n",
       " 'mov edi, eax',\n",
       " 'call 0xe1a9',\n",
       " 'jmp 0x5361',\n",
       " 'nop ',\n",
       " 'mov rbx, qword ptr [rbp - 8]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x10',\n",
       " 'mov dword ptr [rbp - 4], edi',\n",
       " 'mov edi, 0',\n",
       " 'mov eax, 0',\n",
       " 'call 0x503a',\n",
       " 'cmp dword ptr [rbp - 4], 0x12',\n",
       " 'jne 0x539f',\n",
       " 'mov edi, 1',\n",
       " 'call 0xadac',\n",
       " 'mov eax, 0',\n",
       " 'call 0xc083',\n",
       " 'mov eax, dword ptr [rip + 0x2b543]',\n",
       " 'test eax, eax',\n",
       " 'jne 0x549f',\n",
       " 'mov rax, qword ptr [rip + 0x2b55c]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x110b0',\n",
       " 'mov rax, qword ptr [rip + 0x2b555]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x110b0',\n",
       " 'mov rax, qword ptr [rip + 0x2b53e]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x112ef',\n",
       " 'mov rax, qword ptr [rip + 0x2b537]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x112ef',\n",
       " 'mov eax, dword ptr [rip + 0x2b4f1]',\n",
       " 'test eax, eax',\n",
       " 'jne 0x5449',\n",
       " 'mov eax, 0',\n",
       " 'call 0x4fd9',\n",
       " 'test eax, eax',\n",
       " 'jne 0x5415',\n",
       " 'mov eax, 0',\n",
       " 'call 0xc083',\n",
       " 'mov eax, 0',\n",
       " 'call 0xb8a5',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1c9f4',\n",
       " 'mov rax, qword ptr [rip + 0x2b4ea]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x14e6a',\n",
       " 'mov eax, dword ptr [rip + 0x29bf4]',\n",
       " 'test eax, eax',\n",
       " 'je 0x5458',\n",
       " 'mov rax, qword ptr [rip + 0x2b4d9]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x14e6a',\n",
       " 'jmp 0x5458',\n",
       " 'mov rax, qword ptr [rip + 0x2b4a8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xce57',\n",
       " 'mov eax, 0',\n",
       " 'call 0x106d4',\n",
       " 'mov eax, 0',\n",
       " 'call 0xf8eb',\n",
       " 'mov eax, 0',\n",
       " 'call 0xf768',\n",
       " 'mov eax, 0',\n",
       " 'call 0xb4b7',\n",
       " 'cmp dword ptr [rbp - 4], 0x12',\n",
       " 'jne 0x54a0',\n",
       " 'mov rax, qword ptr [rip + 0x2b483]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x1504f',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xd875',\n",
       " 'jmp 0x54a0',\n",
       " 'nop ',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x30',\n",
       " 'mov qword ptr [rbp - 0x28], rdi',\n",
       " 'mov eax, 0',\n",
       " 'call 0xc855',\n",
       " 'mov qword ptr [rbp - 0x20], rax',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x4960',\n",
       " 'mov qword ptr [rbp - 0x18], rax',\n",
       " 'cmp qword ptr [rbp - 0x18], 0',\n",
       " 'je 0x5582',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rax - 1]',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'cmp al, 7',\n",
       " 'je 0x5582',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xb2c6',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x4960',\n",
       " 'sub rax, -0x80',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x24650',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov rdx, qword ptr [rbp - 0x10]',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'lea rcx, [rip + 0x21c34]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x4dd0',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov edx, 1',\n",
       " 'mov esi, 2',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x107d0',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x1eeae',\n",
       " 'mov eax, 0',\n",
       " 'call 0xbfbf',\n",
       " 'mov eax, 0',\n",
       " 'call 0xb4b7',\n",
       " 'mov edi, 1',\n",
       " 'call 0x4e70',\n",
       " 'jmp 0x558c',\n",
       " 'mov eax, 0',\n",
       " 'call 0xbfbf',\n",
       " 'cmp qword ptr [rbp - 0x28], 0',\n",
       " 'je 0x55ab',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'mov edx, 0',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x107d0',\n",
       " 'jmp 0x55b5',\n",
       " 'mov eax, 0',\n",
       " 'call 0x10857',\n",
       " 'mov eax, 0',\n",
       " 'call 0xf768',\n",
       " 'mov eax, 0',\n",
       " 'call 0xb4b7',\n",
       " 'nop ',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov qword ptr [rbp - 0x18], rdi',\n",
       " 'mov qword ptr [rbp - 0x20], rsi',\n",
       " 'mov rax, qword ptr fs:[0x28]',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'xor eax, eax',\n",
       " 'lea rcx, [rbp - 0x10]',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'mov edx, 1',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x1f4b1',\n",
       " 'test rax, rax',\n",
       " 'je 0x5623',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'mov rdx, qword ptr [rbp - 0x20]',\n",
       " 'mov rsi, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x4af0',\n",
       " 'test eax, eax',\n",
       " 'je 0x5648',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x24780',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'lea rdx, [rbp - 0x10]',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'mov rsi, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x1f381',\n",
       " 'jmp 0x5649',\n",
       " 'nop ',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'sub rax, qword ptr fs:[0x28]',\n",
       " 'je 0x565d',\n",
       " 'call 0x4980',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov qword ptr [rbp - 0x18], rdi',\n",
       " 'mov dword ptr [rbp - 0x1c], esi',\n",
       " 'mov rax, qword ptr fs:[0x28]',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'xor eax, eax',\n",
       " 'mov edx, dword ptr [rbp - 0x1c]',\n",
       " 'lea rcx, [rbp - 0x10]',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x1f4b1',\n",
       " 'test rax, rax',\n",
       " 'je 0x56a2',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'jmp 0x56a7',\n",
       " 'mov eax, 0',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'sub rdx, qword ptr fs:[0x28]',\n",
       " 'je 0x56bb',\n",
       " 'call 0x4980',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x10',\n",
       " 'mov dword ptr [rbp - 4], edi',\n",
       " 'mov dword ptr [rbp - 8], esi',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 2',\n",
       " 'test eax, eax',\n",
       " 'jne 0x56e3',\n",
       " 'mov eax, 0',\n",
       " 'jmp 0x5994',\n",
       " 'mov eax, dword ptr [rbp - 4]',\n",
       " 'add eax, 0x42',\n",
       " 'cmp eax, 0x17',\n",
       " 'ja 0x5928',\n",
       " 'mov eax, eax',\n",
       " 'lea rdx, [rax*4]',\n",
       " 'lea rax, [rip + 0x21ffd]',\n",
       " 'mov eax, dword ptr [rdx + rax]',\n",
       " 'cdqe ',\n",
       " 'lea rdx, [rip + 0x21ff1]',\n",
       " 'add rax, rdx',\n",
       " 'jmp rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe4db',\n",
       " 'jmp 0x598f',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe522',\n",
       " 'jmp 0x598f',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe569',\n",
       " 'jmp 0x598f',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe655',\n",
       " 'jmp 0x598f',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe739',\n",
       " 'jmp 0x598f',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe768',\n",
       " 'jmp 0x598f',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x5967',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe901',\n",
       " 'jmp 0x5967',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x596a',\n",
       " 'mov eax, 0',\n",
       " 'call 0xea22',\n",
       " 'jmp 0x596a',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x596d',\n",
       " 'mov eax, 0',\n",
       " 'call 0xeb56',\n",
       " 'jmp 0x596d',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x5970',\n",
       " 'mov eax, 0',\n",
       " 'call 0xec1c',\n",
       " 'jmp 0x5970',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x5973',\n",
       " 'mov edi, 1',\n",
       " 'call 0xed98',\n",
       " 'jmp 0x5973',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x5976',\n",
       " 'mov eax, 0',\n",
       " 'call 0xedfe',\n",
       " 'jmp 0x5976',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x5979',\n",
       " 'mov eax, 0',\n",
       " 'call 0xeea7',\n",
       " 'jmp 0x5979',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x597c',\n",
       " 'mov eax, 0',\n",
       " 'call 0xef17',\n",
       " 'jmp 0x597c',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x597f',\n",
       " 'mov eax, 0',\n",
       " 'call 0xef64',\n",
       " 'jmp 0x597f',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x5982',\n",
       " 'mov eax, 0',\n",
       " 'call 0xf009',\n",
       " 'jmp 0x5982',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x5985',\n",
       " 'mov eax, 0',\n",
       " 'call 0xf0af',\n",
       " 'jmp 0x5985',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x5988',\n",
       " 'mov eax, 0',\n",
       " 'call 0xf155',\n",
       " 'jmp 0x5988',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe3ee',\n",
       " 'jmp 0x598f',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x598b',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe40f',\n",
       " 'jmp 0x598b',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe437',\n",
       " 'jmp 0x598f',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x598e',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe45f',\n",
       " 'jmp 0x598e',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe49b',\n",
       " 'jmp 0x598f',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'and eax, 1',\n",
       " 'test eax, eax',\n",
       " 'je 0x5960',\n",
       " 'call 0x4ec0',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov eax, dword ptr [rbp - 4]',\n",
       " 'cdqe ',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x4000',\n",
       " 'test eax, eax',\n",
       " 'je 0x5960',\n",
       " 'mov eax, dword ptr [rbp - 4]',\n",
       " 'mov edi, eax',\n",
       " 'call 0xe797',\n",
       " 'jmp 0x598f',\n",
       " 'mov eax, 0',\n",
       " 'jmp 0x5994',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'jmp 0x598f',\n",
       " 'nop ',\n",
       " 'mov eax, 1',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x30',\n",
       " 'mov qword ptr [rbp - 0x28], rdi',\n",
       " 'cmp qword ptr [rbp - 0x28], 0',\n",
       " 'jne 0x59b7',\n",
       " 'mov eax, 0',\n",
       " 'jmp 0x5ae7',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x4960',\n",
       " 'add rax, 1',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x24650',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'mov dword ptr [rbp - 0x18], 0',\n",
       " 'mov dword ptr [rbp - 0x14], 0',\n",
       " 'jmp 0x5abb',\n",
       " 'mov eax, dword ptr [rbp - 0x18]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'cmp al, 9',\n",
       " 'jne 0x5a48',\n",
       " 'add qword ptr [rbp - 8], 8',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'mov rsi, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x24670',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'add rax, rdx',\n",
       " 'mov edx, 8',\n",
       " 'lea rcx, [rip + 0x2173e]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x4b70',\n",
       " 'add dword ptr [rbp - 0x14], 8',\n",
       " 'jmp 0x5ab7',\n",
       " 'call 0x4ec0',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov eax, dword ptr [rbp - 0x18]',\n",
       " 'movsxd rcx, eax',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'add rax, rcx',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x4000',\n",
       " 'test eax, eax',\n",
       " 'je 0x5aa1',\n",
       " 'mov eax, dword ptr [rbp - 0x18]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'lea rcx, [rdx + rax]',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'lea edx, [rax + 1]',\n",
       " 'mov dword ptr [rbp - 0x14], edx',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'add rdx, rax',\n",
       " 'movzx eax, byte ptr [rcx]',\n",
       " 'mov byte ptr [rdx], al',\n",
       " 'jmp 0x5ab7',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'lea edx, [rax + 1]',\n",
       " 'mov dword ptr [rbp - 0x14], edx',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0x3f',\n",
       " 'add dword ptr [rbp - 0x18], 1',\n",
       " 'mov eax, dword ptr [rbp - 0x18]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'test al, al',\n",
       " 'jne 0x59ee',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x30',\n",
       " 'mov qword ptr [rbp - 0x28], rdi',\n",
       " 'mov qword ptr [rbp - 0x18], 0',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x4960',\n",
       " 'mov rdx, rax',\n",
       " 'mov rax, rdx',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'add rax, 9',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x24650',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rax + 1]',\n",
       " 'mov qword ptr [rbp - 0x18], rdx',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0x28',\n",
       " 'jmp 0x5b96',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rax + 1]',\n",
       " 'mov qword ptr [rbp - 0x18], rdx',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'add rdx, rax',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'mov byte ptr [rdx], al',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rax + 1]',\n",
       " 'mov qword ptr [rbp - 0x18], rdx',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0x2c',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rax + 1]',\n",
       " 'mov qword ptr [rbp - 0x18], rdx',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0x20',\n",
       " 'add qword ptr [rbp - 0x10], 1',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'add rax, 1',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'test al, al',\n",
       " 'jne 0x5b49',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rax + 1]',\n",
       " 'mov qword ptr [rbp - 0x18], rdx',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'add rdx, rax',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'mov byte ptr [rdx], al',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rax + 1]',\n",
       " 'mov qword ptr [rbp - 0x18], rdx',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0x29',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rax + 1]',\n",
       " 'mov qword ptr [rbp - 0x18], rdx',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0x20',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rax + 1]',\n",
       " 'mov qword ptr [rbp - 0x18], rdx',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x60',\n",
       " 'mov qword ptr [rbp - 0x48], rdi',\n",
       " 'mov qword ptr [rbp - 0x50], rsi',\n",
       " 'mov dword ptr [rbp - 0x54], edx',\n",
       " 'mov rax, qword ptr fs:[0x28]',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'xor eax, eax',\n",
       " 'mov qword ptr [rbp - 0x30], 0',\n",
       " 'mov eax, dword ptr [rbp - 0x54]',\n",
       " 'and eax, 0x10',\n",
       " 'test eax, eax',\n",
       " 'je 0x5c4f',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe205',\n",
       " 'mov qword ptr [rbp - 0x30], rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0xece2',\n",
       " 'cmp qword ptr [rbp - 0x48], 0',\n",
       " 'je 0x5cf2',\n",
       " 'mov rax, qword ptr [rbp - 0x48]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x5996',\n",
       " 'mov qword ptr [rbp - 0x28], rax',\n",
       " 'mov eax, dword ptr [rbp - 0x54]',\n",
       " 'and eax, 8',\n",
       " 'test eax, eax',\n",
       " 'je 0x5c97',\n",
       " 'lea rax, [rip + 0x214f9]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xf433',\n",
       " 'mov edi, 1',\n",
       " 'call 0xfd0b',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xf433',\n",
       " 'mov eax, dword ptr [rbp - 0x54]',\n",
       " 'and eax, 0x20',\n",
       " 'test eax, eax',\n",
       " 'je 0x5cb7',\n",
       " 'mov eax, 0',\n",
       " 'call 0xe739',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x1eeae',\n",
       " 'cmp qword ptr [rbp - 0x50], 0',\n",
       " 'je 0x5cf2',\n",
       " 'mov rax, qword ptr [rbp - 0x50]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x5ae9',\n",
       " 'mov qword ptr [rbp - 0x20], rax',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xf433',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x1eeae',\n",
       " 'mov eax, 0',\n",
       " 'call 0xf8eb',\n",
       " 'mov eax, 0',\n",
       " 'call 0xf768',\n",
       " 'mov eax, 0',\n",
       " 'call 0xb4b7',\n",
       " 'mov eax, dword ptr [rbp - 0x54]',\n",
       " 'and eax, 4',\n",
       " 'test eax, eax',\n",
       " 'je 0x5d44',\n",
       " 'mov eax, 0',\n",
       " 'call 0xbfbf',\n",
       " 'jmp 0x5d44',\n",
       " 'mov eax, 0',\n",
       " 'call 0xbfbf',\n",
       " 'mov eax, 0',\n",
       " 'call 0x106d4',\n",
       " 'mov eax, 0',\n",
       " 'call 0xf768',\n",
       " 'lea rax, [rbp - 0x38]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xc5ba',\n",
       " 'mov qword ptr [rbp - 0x18], rax',\n",
       " 'cmp qword ptr [rbp - 0x18], 0',\n",
       " 'je 0x5d26',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movzx eax, al',\n",
       " 'mov dword ptr [rbp - 0x34], eax',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'mov rax, qword ptr [rax + 0x10]',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'cmp qword ptr [rbp - 0x10], 0',\n",
       " 'je 0x5dc3',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'movzx eax, byte ptr [rax + 0x1b]',\n",
       " 'test al, al',\n",
       " 'je 0x5dc3',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'lea rdx, [rip + 0x29308]',\n",
       " 'sub rax, rdx',\n",
       " 'mov rcx, rax',\n",
       " 'movabs rdx, 0xea0ea0ea0ea0ea1',\n",
       " 'mov rax, rcx',\n",
       " 'imul rdx',\n",
       " 'mov rax, rdx',\n",
       " 'sar rax, 1',\n",
       " 'sar rcx, 0x3f',\n",
       " 'mov rdx, rcx',\n",
       " 'sub rax, rdx',\n",
       " 'not eax',\n",
       " 'mov dword ptr [rbp - 0x34], eax',\n",
       " 'cmp dword ptr [rbp - 0x34], 7',\n",
       " 'je 0x5e89',\n",
       " 'cmp dword ptr [rbp - 0x34], 7',\n",
       " 'jg 0x5e1d',\n",
       " 'cmp dword ptr [rbp - 0x34], -0x3d',\n",
       " 'je 0x5df0',\n",
       " 'cmp dword ptr [rbp - 0x34], -8',\n",
       " 'jne 0x5e1d',\n",
       " 'mov edi, 0',\n",
       " 'mov eax, 0',\n",
       " 'call 0x5367',\n",
       " 'jmp 0x5e66',\n",
       " 'cmp qword ptr [rbp - 0x50], 0',\n",
       " 'je 0x5e89',\n",
       " 'mov rax, qword ptr [rbp - 0x50]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx eax, al',\n",
       " 'mov dword ptr [rbp - 0x34], eax',\n",
       " 'jmp 0x5e89',\n",
       " 'mov edx, dword ptr [rbp - 0x54]',\n",
       " 'mov eax, dword ptr [rbp - 0x34]',\n",
       " 'mov esi, edx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x56bd',\n",
       " 'test eax, eax',\n",
       " 'je 0x5e36',\n",
       " 'mov eax, dword ptr [rbp - 0x38]',\n",
       " 'lea edx, [rax - 1]',\n",
       " 'mov dword ptr [rbp - 0x38], edx',\n",
       " 'test eax, eax',\n",
       " 'jne 0x5e0a',\n",
       " 'mov eax, 0',\n",
       " 'call 0xf8eb',\n",
       " 'jmp 0x5e66',\n",
       " 'nop ',\n",
       " 'cmp qword ptr [rbp - 0x50], 0',\n",
       " 'je 0x5e8c',\n",
       " 'cmp qword ptr [rbp - 0x50], 0',\n",
       " 'je 0x5e5b',\n",
       " 'mov edx, dword ptr [rbp - 0x34]',\n",
       " 'mov rax, qword ptr [rbp - 0x50]',\n",
       " 'mov esi, edx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x49b0',\n",
       " 'test rax, rax',\n",
       " 'jne 0x5e8f',\n",
       " 'mov eax, 0',\n",
       " 'call 0xbfbf',\n",
       " 'nop ',\n",
       " 'mov eax, 0',\n",
       " 'call 0x106d4',\n",
       " 'mov eax, 0',\n",
       " 'call 0xf768',\n",
       " 'mov eax, 0',\n",
       " 'call 0xb4b7',\n",
       " 'jmp 0x5d44',\n",
       " 'nop ',\n",
       " 'jmp 0x5e90',\n",
       " 'nop ',\n",
       " 'jmp 0x5e90',\n",
       " 'nop ',\n",
       " 'mov edi, 0',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we create our 50/50 NIP training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6827\n",
      "['endbr64 ', 'push rbp', 'mov rbp, rsp', 'mov eax, dword ptr [rip + 0x2b9f5]', 'cmp eax, 6']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "history = []\n",
    "next_instruction = []\n",
    "label = []\n",
    "\n",
    "page_len = 5\n",
    "instruction_pages = []\n",
    "for instruction_cluster in text:\n",
    "    instructions = [\n",
    "        instruction for instruction in instruction_cluster.split(delim) if instruction != ''\n",
    "    ]\n",
    "    if len(instructions)>page_len:\n",
    "        \n",
    "        for i in range(0,len(instructions),page_len):\n",
    "            instruction_pages.append(instructions[i:i+page_len])\n",
    "        \n",
    "print(len(instruction_pages))\n",
    "print(instruction_pages[0])\n",
    "\n",
    "for instruction_page in instruction_pages:\n",
    "    \n",
    "#     instructions = [\n",
    "#         instruction for instruction in instruction_page.split(';') if instruction != ''\n",
    "#     ]\n",
    "    \n",
    "    \n",
    "#     num_instructions = len(instruction_page)\n",
    "    \n",
    "    \n",
    "\n",
    "#     start = random.randint(0, num_instructions-2)\n",
    "    # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "    if random.random() >= 0.5:\n",
    "        # this is IsNextSentence\n",
    "        history.append(delim.join(instruction_page[:-1]))\n",
    "        next_instruction.append(instruction_page[-1])\n",
    "        label.append(0)\n",
    "    else:\n",
    "        index = random.randint(0, bag_size-1)\n",
    "        # this is NotNextSentence\n",
    "        history.append(delim.join(instruction_page[:-1]))\n",
    "        next_instruction.append(bag[index])\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6827\n",
      "0\n",
      "-> endbr64 ;push rbp;mov rbp, rsp;mov eax, dword ptr [rip + 0x2b9f5] \n",
      "\n",
      "#  cmp eax, 6 \n",
      "\n",
      "1\n",
      "-> jle 0x501a;mov eax, dword ptr [rip + 0x2a036];test eax, eax;je 0x5008 \n",
      "\n",
      "#  call 0x4960 \n",
      "\n",
      "0\n",
      "-> cmp eax, 0xb;jle 0x501a;mov eax, 1;jmp 0x501f \n",
      "\n",
      "#  mov eax, dword ptr [rip + 0x2b9d2] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(label))\n",
    "for i in range(3):\n",
    "    print(label[i])\n",
    "    print('->',history[i] , '\\n')\n",
    "    print('# ',next_instruction[i] , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready for tokenization, this time we truncate/pad each token to the same length of *512* tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(history, next_instruction, return_tensors='pt', max_length=128, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the *token_type_ids* tensors have been built correctly (eg **1** indicating sentence B tokens) by checking the first instance of *token_type_ids*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.token_type_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **0** tokens following our sentence B tokens correspond to *PAD* tokens.\n",
    "\n",
    "Alongside this, we need to create a *labels* tensor too - which corresponds to the values contained within our `label` variable. Our *labels* tensor must be a *LongTensor*, and we will need to transpose the tensor so that it matches our other tensors' dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = torch.LongTensor([label]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inputs` tensors are now ready, and we can begin building the model input pipeline for training. We first create a PyTorch dataset from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize our data using the `MeditationDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeditationsDataset(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And initialize the dataloader, which we'll be using to load our data into the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto setting up the training loop. First we setup GPU/CPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForNextSentencePrediction(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyNSPHead(\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the training mode of our model, and initialize our optimizer (Adam with weighted decay - reduces chance of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahid/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# activate training mode\n",
    "model.train()\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__dataclass_fields__',\n",
       " '__dataclass_params__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__post_init__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'attentions',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'hidden_states',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'logits',\n",
       " 'loss',\n",
       " 'move_to_end',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'setdefault',\n",
       " 'to_tuple',\n",
       " 'update',\n",
       " 'values']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['__annotations__', '__class__', '__contains__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'attentions', 'clear', 'copy', 'fromkeys', 'get', 'hidden_states', 'items', 'keys', 'logits', 'loss', 'move_to_end', 'pop', 'popitem', 'setdefault', 'to_tuple', 'update', 'values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto the training loop, we'll train for a couple of epochs (change `epochs` to modify this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|| 427/427 [02:56<00:00,  2.42it/s, loss=0.715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49655778526439137 0.49057605521635256 0.5490196078431373 0.5181550539744848 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 1: 100%|| 427/427 [02:57<00:00,  2.40it/s, loss=0.671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5085689175333236 0.5015882183078256 0.516042780748663 0.5087128422902328 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 2: 100%|| 427/427 [02:55<00:00,  2.43it/s, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5088618719789073 0.5020092735703245 0.48247177658942364 0.4920466595970307 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 3: 100%|| 427/427 [02:54<00:00,  2.44it/s, loss=0.695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5155998242273326 0.5093740069907848 0.476232917409388 0.4922462766774144 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 4: 100%|| 427/427 [02:54<00:00,  2.44it/s, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5098872125384503 0.5031525851197982 0.4741532976827095 0.48822269807280516 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 5: 100%|| 427/427 [02:54<00:00,  2.44it/s, loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5210194814706313 0.5158415841584159 0.464349376114082 0.48874296435272047 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 6: 100%|| 427/427 [02:54<00:00,  2.44it/s, loss=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5352277720814413 0.5297380585516178 0.5106951871657754 0.5200423536530026 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 7: 100%|| 427/427 [02:55<00:00,  2.43it/s, loss=0.741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5359601581954007 0.5321011673151751 0.4875222816399287 0.5088372093023256 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 8: 100%|| 427/427 [02:53<00:00,  2.47it/s, loss=0.705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5400615204335726 0.5365459249676585 0.4928698752228164 0.5137813564571075 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 9: 100%|| 427/427 [02:54<00:00,  2.45it/s, loss=0.596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5462135637908305 0.5468859342197341 0.464349376114082 0.5022493573264781 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 10: 100%|| 427/427 [02:54<00:00,  2.44it/s, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5627654899663103 0.5729047072330654 0.4447415329768271 0.5007526342197692 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 11: 100%|| 427/427 [02:58<00:00,  2.40it/s, loss=0.744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5591035593965138 0.5683039140445126 0.43998811645870467 0.49598124581379777 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 12: 100%|| 427/427 [03:04<00:00,  2.31it/s, loss=0.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5765343489087447 0.5838926174496645 0.4910873440285205 0.5334839438437955 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 13: 100%|| 427/427 [03:04<00:00,  2.32it/s, loss=0.496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6135930862750842 0.6374622356495468 0.5014854426619133 0.5613568340538743 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 14: 100%|| 427/427 [02:59<00:00,  2.38it/s, loss=0.526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6466969386260436 0.6773234200743494 0.5412953060011884 0.6017173051519155 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 15: 100%|| 427/427 [02:53<00:00,  2.47it/s, loss=0.515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6745276109564963 0.7050179211469534 0.5843731431966727 0.6390513320337882 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 16: 100%|| 427/427 [02:53<00:00,  2.47it/s, loss=0.364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7177383916800938 0.7541504768632992 0.6342840166369578 0.6890430853638857 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 17: 100%|| 427/427 [02:53<00:00,  2.47it/s, loss=0.521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7413212245495825 0.7711864406779662 0.6758764111705288 0.720392653578214 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 18: 100%|| 427/427 [02:53<00:00,  2.47it/s, loss=0.569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7690054196572433 0.805603006491288 0.7005347593582888 0.7494040997934212 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 19: 100%|| 427/427 [02:53<00:00,  2.47it/s, loss=0.641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781455983594551 0.8180583842498302 0.7159833630421866 0.7636248415716095 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 20: 100%|| 427/427 [02:53<00:00,  2.47it/s, loss=0.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980079097700308 0.8260584181161799 0.7477718360071302 0.7849680336815844 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 21: 100%|| 427/427 [02:53<00:00,  2.47it/s, loss=0.242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811044382598506 0.837890625 0.7647058823529411 0.799627213420317 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 22: 100%|| 427/427 [02:53<00:00,  2.47it/s, loss=0.512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8280357404423612 0.8519588953114965 0.7881758764111705 0.8188271604938273 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 23: 100%|| 427/427 [02:53<00:00,  2.47it/s, loss=0.0788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8327230115717006 0.8589412524209167 0.7905525846702317 0.823329207920792 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 24: 100%|| 427/427 [02:53<00:00,  2.47it/s, loss=0.315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8423905082759631 0.8616550852811118 0.8104575163398693 0.835272504592774 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/427 [00:00<?, ?it/s]/tmp/ipykernel_61195/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 25:  19%|                | 82/427 [00:33<02:25,  2.37it/s, loss=0.135]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    \n",
    "    \n",
    "    predictions_all, ground_truths_all = None, None\n",
    "    for N,batch in enumerate(loop):\n",
    "\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        labels=labels)\n",
    "#         print(torch.nn.functional.softmax(outputs.logits, dim=-1))\n",
    "        prediction = torch.argmax(outputs.logits, axis=-1)\n",
    "        prediction = prediction.detach().cpu().numpy().flatten()\n",
    "        ground_truth = labels.detach().cpu().numpy().flatten()\n",
    "        \n",
    "        if N==0:\n",
    "            predictions_all = prediction\n",
    "            ground_truths_all = ground_truth\n",
    "        else:\n",
    "            predictions_all   = np.concatenate((predictions_all, prediction))\n",
    "            ground_truths_all = np.concatenate((ground_truths_all, ground_truth))\n",
    "            \n",
    "#         predictions_all.append(prediction)\n",
    "#         ground_truths_all.append(ground_truth)\n",
    "        \n",
    "#         print(ground_truth.flatten())\n",
    "#         print(predictions_all ,ground_truths_all )\n",
    "#         print(prediction, ground_truth ,(accuracy_score(ground_truth.flatten(),prediction.flatten())))\n",
    "        \n",
    "\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    accuracy = (accuracy_score(ground_truths_all,predictions_all))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ground_truths_all,predictions_all, average='binary')\n",
    "    print(accuracy, precision, recall, f1, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
