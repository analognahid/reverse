{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb49c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO  sort the basic blocks\n",
    "# TODO convert hex values to int\n",
    "# TODO SANITY CHECK\n",
    "# TODO GHIDRA Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c7288a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    }
   ],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2022/04/all-about-popular-graph-network-tools-in-natural-language-processing/\n",
    "import sys,os, pickle\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "net = Network(notebook=True)\n",
    "import random\n",
    "from capstone import *\n",
    "\n",
    "from capstone.x86 import *\n",
    "import sys,os\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from elftools.elf.segments import Segment\n",
    "\n",
    "\n",
    "\n",
    "def merge_graphs(ins_data):\n",
    "\n",
    "    merged_ins_data= {}\n",
    "\n",
    "\n",
    "    for fname, connected_comps in ins_data.items():\n",
    "        Graph = nx.DiGraph()\n",
    "        for ia, connected_comp in enumerate(connected_comps):\n",
    "            for addr in connected_comp:\n",
    "                Graph.add_node(addr)\n",
    "\n",
    "\n",
    "#             for k in range(len(connected_comp)-1):\n",
    "#                 Graph.add_edge(connected_comp[k] , connected_comp[k+1])\n",
    "        for k in range(len(connected_comp)-1):\n",
    "            Graph.add_edge(connected_comp[k] , connected_comp[k+1])\n",
    "#TODO FIX\n",
    "        merged_conn_comps = list(nx.weakly_connected_components(Graph) )\n",
    "        merged_conn_comps = [ list(i) for i in merged_conn_comps]\n",
    "\n",
    "\n",
    "\n",
    "        merged_ins_data[fname] = merged_conn_comps\n",
    "        \n",
    "    return merged_ins_data\n",
    "\n",
    "#For visualizing the graph\n",
    "# net.from_nx(Graph)\n",
    "# net.show(\"graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f636429",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def process_data(merged_ins_data):\n",
    "\n",
    "    input_list = []\n",
    "    label_list = []\n",
    "    \n",
    "\n",
    "    for fname, connected_comps in merged_ins_data.items():\n",
    "\n",
    "\n",
    "\n",
    "        prev_basic_blocks = []\n",
    "        for connected_comp in connected_comps:\n",
    "            if len(connected_comp)<2:\n",
    "                continue\n",
    "            bbs = []\n",
    "            for addr in connected_comp:\n",
    "                addr_int = int(addr, 16)\n",
    "                if addr_int not in bb_data: #address out of scope\n",
    "                    continue\n",
    "                bb_inf = bb_data[addr_int]  \n",
    "\n",
    "                if bb_inf not in bbs:\n",
    "                    bbs.append(bb_inf)\n",
    "\n",
    "\n",
    "            if bbs == prev_basic_blocks: #we dont wanna repeat the same program slice\n",
    "                print(\">>>> same program. So CONTINUE\")\n",
    "                continue\n",
    "                \n",
    "\n",
    "            not_connected_nodes = []\n",
    "            addr_inst = {}\n",
    "            for bb_entry, bb_end in bbs:\n",
    "                for inst in md.disasm(bin_bytearray[bb_entry:bb_end], bb_entry):\n",
    "                    if hex(inst.address) not in connected_comp:\n",
    "                        not_connected_nodes.append(str(hex(inst.address)))\n",
    "\n",
    "                    addr_inst[inst.address]=inst\n",
    "\n",
    "                    if inst.address == bb_end:\n",
    "                        break\n",
    "            prev_basic_blocks = bbs\n",
    "            node1 =None\n",
    "            node2 = None\n",
    "            label = None\n",
    "            if len(not_connected_nodes)>0: #at least some note conneted instructions\n",
    "                if random.randint(1,2)%2==0: # pair connected\n",
    "\n",
    "                    node1, node2 = random.sample(connected_comp, 2)\n",
    "                    label = True\n",
    "                else:                        #pair disconnected\n",
    "\n",
    "                    node1 = random.choice(connected_comp)\n",
    "                    node2 = random.choice(not_connected_nodes)\n",
    "                    label = False\n",
    "\n",
    "            else:\n",
    "                node1, node2 = random.sample(connected_comp, 2)\n",
    "                label = True\n",
    "\n",
    "            input_slice = []\n",
    "\n",
    "\n",
    "            for addr,inst in addr_inst.items():\n",
    "    #             print(addr,inst.mnemonic, inst.op_str)\n",
    "                inst_str =str(hex(addr))+\":\" + inst.mnemonic + ' '+ inst.op_str + \"[EOI]\"\n",
    "\n",
    "                if str(hex(addr)) in [node1,node2]:\n",
    "                    inst_str  =  \"[LOOK]\" +inst_str + \"[LOOK]\"  \n",
    "\n",
    "                input_slice.append(inst_str)\n",
    "\n",
    "            input_list.append( ''.join(input_slice))\n",
    "            label_list.append( 1 if label==True else 0  )\n",
    "    return input_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e045b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import magic, hashlib\n",
    "def is_elf_file(file_path):\n",
    "    try:\n",
    "        file_type = magic.from_file(file_path)\n",
    "        return 'ELF' in file_type\n",
    "    except Exception as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f512e774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# DATA_PATH = './dfg_data/'\n",
    "# BIN_PATH = './../../just_bins/'\n",
    "\n",
    "# ANALYSIS_DATA_PATH    = '/media/raisul/nahid_personal/analysis_data_100k/files/'\n",
    "ANALYSIS_DATA_PATH    = '/media/raisul/nahid_personal/dwarf4/ghidra_types/analysis_data_state_format_100k_dwarf4_O2/'\n",
    "SRC_N_BIN_PATH        = '/media/raisul/nahid_personal/clones_100k/'\n",
    "\n",
    "filtered_files = []\n",
    "for path, subdirs, files in os.walk(SRC_N_BIN_PATH):\n",
    "    if len(filtered_files)>1000:\n",
    "        break\n",
    "    print(name)\n",
    "    for name in files:\n",
    "\n",
    "        if '_elf_file_gdwarf4_O2' not in name:\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(path, name)\n",
    "        \n",
    "        if is_elf_file(file_path)== False:\n",
    "            continue\n",
    "\n",
    "        filtered_files.append(file_path)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f868f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_list     = []\n",
    "all_label_list     = []\n",
    "\n",
    "\n",
    "for binary_path in filtered_files:\n",
    "    unique_path = binary_path.split('clones_100k')[1][1:]\n",
    "    github_path = unique_path.split('/')[0]\n",
    "\n",
    "    unique_pkl_file_name=github_path + '_____'+(hashlib.md5(unique_path.encode())).hexdigest()\n",
    "\n",
    "    analysed_pkl_path = os.path.join( ANALYSIS_DATA_PATH ,unique_pkl_file_name+'.pkl')\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(analysed_pkl_path) == False:\n",
    "        continue\n",
    "    \n",
    "    with (open(analysed_pkl_path , \"rb\")) as openfile:\n",
    "        bb_data , ins_data , tool_addresses_list = pickle.load(openfile)\n",
    "        \n",
    "        \n",
    "    md = Cs(CS_ARCH_X86, CS_MODE_64) #TODO MAKE DYNAMIC\n",
    "\n",
    "    with open(binary_path, 'rb') as f:\n",
    "\n",
    "        bin_bytearray = bytearray(f.read())\n",
    "        elffile = ELFFile(f)\n",
    "    merged_ins_data = merge_graphs(ins_data)\n",
    "    input_list, label_list = process_data(merged_ins_data)\n",
    "    all_input_list.extend(input_list)\n",
    "    all_label_list.extend(label_list)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c021cf35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for d in range(len(all_input_list)):\n",
    "    if len(all_input_list[d])>200 and  all_label_list[d] ==0:\n",
    "        print(all_input_list[d])\n",
    "        \n",
    "         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af619700",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "len(all_input_list)\n",
    "with open('02_d4_DFGDATA.pkl' , 'wb') as f:\n",
    "    pickle.dump([all_input_list , all_label_list], f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13babdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
