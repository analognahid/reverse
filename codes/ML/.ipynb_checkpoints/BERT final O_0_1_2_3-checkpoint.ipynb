{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af388b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device ,torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c86ae04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de072e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os, pickle\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score,f1_score\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME=\"TYPE_WRITER_BERT_final_O_0123\"\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "MAX_TOKEN_SIZE = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46d98a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\n",
    "             '/home/raisul/type_data/instructions_and_type_data_100k/',\n",
    "              '/home/raisul/type_data/O1_mix/instructions_and_type_data_100k',\n",
    "              '/media/raisul/nahid_personal/optimizations/O2_ghidra/instructions_and_type_data_100k_mix/',\n",
    "              '/home/raisul/type_data/O3_mix/instructions_and_type_data_100k'\n",
    "             ]\n",
    "\n",
    "all_bins_paths = []\n",
    "for oi,data_path in enumerate(data_paths):\n",
    "    for fi,pkl_file_name in enumerate(os.listdir(data_path)):\n",
    "            if fi>300000:\n",
    "                 break\n",
    "            user_proj = pkl_file_name.rsplit('_____', 1)[0]\n",
    "            user_proj = ''.join(user_proj.split('_____'))\n",
    "            pkl_path = os.path.join(data_path,pkl_file_name)\n",
    "            all_bins_paths.append( (pkl_path,oi ,user_proj) )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6d5d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_types(type_name):\n",
    "    global TYPE_FIX_MAP\n",
    "    \n",
    "    prev_type_name= type_name\n",
    "    \n",
    "    if '*' in type_name:\n",
    "        if type_name.rindex('*')>0:#reduce to single * (rightmost, ignore array before that)\n",
    "            type_name = type_name[ type_name.rindex('*'): ]\n",
    "    if 'array_' in type_name:\n",
    "        if type_name.rindex('array_')>0:\n",
    "            type_name = type_name[ type_name.rindex('array_'): ]\n",
    "    if 'unsigned char' in type_name:\n",
    "        type_name = type_name.replace('unsigned char' , 'char')\n",
    "        \n",
    "        \n",
    "    if type_name not in TYPE_FIX_MAP:\n",
    "        TYPE_FIX_MAP[prev_type_name] = type_name\n",
    "    return type_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5c4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_SAVE_PATH =  '/home/raisul/models/'\n",
    "TYPE_COUNT ={}\n",
    "FINAL_TYPE_COUNT = {}\n",
    "TYPE_PROBABILITY = {}\n",
    "\n",
    "\n",
    "REJECT = ['union' , 'enumeration' , 'int128' , '_Bool' , 'complex' ,'bool']\n",
    "TYPE_FIX_MAP = {}\n",
    "MAX_TYPE_SAMPLE  =40*1000\n",
    "TYPE_MAPPING = {}\n",
    "\n",
    "\n",
    "ALL_INPUT_LIST = []\n",
    "ALL_INPUT_SLICE_INFO  = []\n",
    "ALL_LABEL_LIST = []\n",
    "ALL_OPT_LIST = []\n",
    "\n",
    "TRAIN_SAMPLE_COUNT = 0\n",
    "VAL_SAMPLE_COUNT   =0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37270a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'int': 7151, '*char': 445, 'structure': 1028, 'long int': 44, '*int': 569, 'array_int': 1771, 'char': 239, 'array_char': 326, '*structure': 484, 'short int': 4, 'array_structure': 5, 'float': 256, 'double': 106, 'unsigned int': 53, '*double': 32, 'long unsigned int': 36, '*float': 42, 'array_signed char': 1051, 'unsigned long int': 96, 'signed char': 79, 'array_double': 15, 'long long int': 48, 'long double': 2, 'array_long int': 10, '*signed char': 344, 'array_long long int': 11, 'array_short int': 6, 'array_float': 8}\n",
      "DBG 2 int int128\n",
      "temp_removed_keys ['int128']\n",
      "40000 7151 int\n",
      "40000 1771 array_int\n",
      "40000 1051 array_signed char\n",
      "40000 1028 structure\n",
      "40000 569 *int\n",
      "40000 484 *structure\n",
      "40000 445 *char\n",
      "40000 344 *signed char\n",
      "40000 326 array_char\n",
      "40000 256 float\n",
      "40000 239 char\n",
      "40000 106 double\n",
      "40000 96 unsigned long int\n",
      "40000 79 signed char\n",
      "40000 53 unsigned int\n",
      "40000 48 long long int\n",
      "40000 44 long int\n",
      "40000 42 *float\n",
      "40000 36 long unsigned int\n",
      "40000 32 *double\n",
      "40000 15 array_double\n",
      "40000 11 array_long long int\n",
      "40000 10 array_long int\n",
      "40000 8 array_float\n",
      "40000 6 array_short int\n",
      "40000 5 array_structure\n",
      "40000 4 short int\n",
      "40000 2 long double\n",
      "{'int': 5.593623269472801, 'array_int': 22.58610954263128, 'array_signed char': 38.05899143672693, 'structure': 38.91050583657587, '*int': 70.298769771529, '*structure': 82.64462809917356, '*char': 89.88764044943821, '*signed char': 116.27906976744185, 'array_char': 122.69938650306749, 'float': 156.25, 'char': 167.36401673640168, 'double': 377.35849056603774, 'unsigned long int': 416.6666666666667, 'signed char': 506.32911392405066, 'unsigned int': 754.7169811320755, 'long long int': 833.3333333333334, 'long int': 909.0909090909091, '*float': 952.3809523809524, 'long unsigned int': 1111.111111111111, '*double': 1250.0, 'array_double': 2666.6666666666665, 'array_long long int': 3636.3636363636365, 'array_long int': 4000.0, 'array_float': 5000.0, 'array_short int': 6666.666666666667, 'array_structure': 8000.0, 'short int': 10000.0, 'long double': 20000.0}\n",
      "2330 11850\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "#TODO dont load all at a time in memry\n",
    "def make_dataset():\n",
    "    global TYPE_FIX_MAP, REJECT ,TYPE_COUNT,TYPE_MAPPING,TRAIN_SAMPLE_COUNT,VAL_SAMPLE_COUNT\n",
    "    \n",
    "    dbg_temp = []\n",
    "    \n",
    "    #count how many real samples\n",
    "    for pkl_path, oi, user_proj_name in all_bins_paths:\n",
    "\n",
    "\n",
    "        with open(pkl_path, 'rb') as file:\n",
    "            try:\n",
    "                model_input_list, model_type_list = pickle.load(file)\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            for i in range(len(model_input_list)):\n",
    "\n",
    "                type_str = fix_types(model_type_list[i])\n",
    "                \n",
    "                if type_str not in TYPE_COUNT:\n",
    "                    TYPE_COUNT[type_str] = 0\n",
    "                    FINAL_TYPE_COUNT[type_str] = 0\n",
    "                \n",
    "                TYPE_COUNT[type_str] +=1\n",
    "\n",
    "    print(TYPE_COUNT)\n",
    "    \n",
    "    #remove the unwanted types\n",
    "    temp_removed_keys = []\n",
    "    for rk in REJECT:\n",
    "        for tk in TYPE_COUNT:\n",
    "            \n",
    "            if rk in tk:\n",
    "                print(\"DBG 1\", rk,tk)\n",
    "                temp_removed_keys.append(tk)\n",
    "        for tfm in TYPE_FIX_MAP:\n",
    "            if tfm in rk:\n",
    "                print(\"DBG 2\", tfm,rk)\n",
    "                temp_removed_keys.append(rk)\n",
    "    print('temp_removed_keys',temp_removed_keys)\n",
    "    for trk in temp_removed_keys:\n",
    "        if trk in TYPE_COUNT:\n",
    "            TYPE_COUNT.pop(trk)\n",
    "        if trk in FINAL_TYPE_COUNT:\n",
    "            FINAL_TYPE_COUNT.pop(trk)\n",
    "        if trk in TYPE_FIX_MAP:\n",
    "            TYPE_FIX_MAP.pop(trk)\n",
    "    \n",
    "    TYPE_COUNT = {k: v for k, v in sorted(TYPE_COUNT.items(), key=lambda item: item[1] , reverse=True)}\n",
    "\n",
    "\n",
    "    ti = 0\n",
    "    for key,val in TYPE_COUNT.items():\n",
    "        TYPE_MAPPING[key]  = ti\n",
    "        ti+=1\n",
    "\n",
    "    #make the probability\n",
    "    for key in TYPE_COUNT.keys():\n",
    "        print(MAX_TYPE_SAMPLE , TYPE_COUNT[key] ,key)\n",
    "        TYPE_PROBABILITY[key] = MAX_TYPE_SAMPLE/TYPE_COUNT[key]\n",
    "    \n",
    "\n",
    "    print(TYPE_PROBABILITY)\n",
    "    \n",
    "    \n",
    "    ######################################\n",
    "    #######################################\n",
    "    \n",
    "\n",
    "    #fill dataset with that probability\n",
    "    for pkl_path,oi, user_proj_name in all_bins_paths:\n",
    "        \n",
    "        bin_numeric_value = sum(bytearray(user_proj_name,'utf-8') )%10\n",
    "        \n",
    "        \n",
    "        with open(pkl_path, 'rb') as file:\n",
    "            try:\n",
    "                model_input_list, model_type_list = pickle.load(file)\n",
    "            except Exception as e:\n",
    "#                 print('err: ',e)\n",
    "                pass\n",
    "            for i in range(len(model_input_list)):\n",
    "                \n",
    "                try:\n",
    "                    type_str = TYPE_FIX_MAP[model_type_list[i]]\n",
    "                    type_label = TYPE_MAPPING[type_str]\n",
    "\n",
    "                    backward_slice , target_slice, forward_slice = model_input_list[i]\n",
    "\n",
    "                    if random.random()<=TYPE_PROBABILITY[type_str]:\n",
    "                        \n",
    "                        if bin_numeric_value>7:\n",
    "                            \n",
    "                            VAL_SAMPLE_COUNT = VAL_SAMPLE_COUNT + 1\n",
    "                            ALL_INPUT_LIST.append(backward_slice + target_slice + forward_slice)\n",
    "                            ALL_INPUT_SLICE_INFO.append([len(backward_slice) , len(target_slice) , len(forward_slice)])\n",
    "                            ALL_LABEL_LIST.append(type_label)\n",
    "                            ALL_OPT_LIST.append(oi)\n",
    "                        else:\n",
    "                            TRAIN_SAMPLE_COUNT=TRAIN_SAMPLE_COUNT+1\n",
    "                            ALL_INPUT_LIST.insert( 0,  backward_slice + target_slice + forward_slice)\n",
    "                            ALL_INPUT_SLICE_INFO.insert( 0 , [len(backward_slice) , len(target_slice) , len(forward_slice)])\n",
    "                            ALL_LABEL_LIST.insert( 0 , type_label)\n",
    "                            ALL_OPT_LIST.insert(0,oi)\n",
    "\n",
    "\n",
    "                        FINAL_TYPE_COUNT[type_str]+=1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "#                       print('err: _',e)\n",
    "#                       print(traceback.print_exc())\n",
    "\n",
    "make_dataset()\n",
    "print(VAL_SAMPLE_COUNT , TRAIN_SAMPLE_COUNT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65ff019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp_path = 'data/typedata'+EXPERIMENT_NAME+'.ignore.pkl'\n",
    "with open(data_temp_path, 'wb') as f:\n",
    "    pickle.dump([ALL_OPT_LIST,VAL_SAMPLE_COUNT , TRAIN_SAMPLE_COUNT,TYPE_COUNT , TYPE_MAPPING ,ALL_INPUT_LIST, ALL_INPUT_SLICE_INFO ,ALL_LABEL_LIST,   FINAL_TYPE_COUNT ], f)\n",
    "    \n",
    "    \n",
    "with open(data_temp_path, 'rb') as file:\n",
    "    ALL_OPT_LIST,VAL_SAMPLE_COUNT , TRAIN_SAMPLE_COUNT,TYPE_COUNT , TYPE_MAPPING ,ALL_INPUT_LIST, ALL_INPUT_SLICE_INFO ,ALL_LABEL_LIST,     FINAL_TYPE_COUNT  = pickle.load(file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76f9c1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14165 {'int': 7149, '*char': 399, 'structure': 1028, 'long int': 42, '*int': 540, 'array_int': 1765, 'char': 239, 'array_char': 326, '*structure': 484, 'short int': 2, 'array_structure': 5, 'float': 254, 'double': 104, 'unsigned int': 53, '*double': 32, 'long unsigned int': 36, '*float': 42, 'array_signed char': 1050, 'unsigned long int': 96, 'signed char': 79, 'array_double': 15, 'long long int': 46, 'long double': 0, 'array_long int': 10, '*signed char': 344, 'array_long long int': 11, 'array_short int': 6, 'array_float': 8}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(ALL_INPUT_LIST), FINAL_TYPE_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a256faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 6 5\n"
     ]
    }
   ],
   "source": [
    "tokenizer  = BertTokenizer.from_pretrained(\"./multytask-tokenizer_optim_3_d4\")\n",
    "\n",
    "#https://github.com/huggingface/tokenizers/issues/247\n",
    "\n",
    "mask_token_id, look_token_id, eoi_token_id = tokenizer.encode('[MASK] [LOOK] [EOI]')[1:-1]\n",
    "\n",
    "print(mask_token_id, look_token_id, eoi_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa991f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE :  3000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "\n",
    "print('VOCAB SIZE : ', (tokenizer.vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c7d400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/raisul/models/pretrain_100k_O2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"/home/raisul/models/pretrain_100k_O2\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.33.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "#TODO*** USE PRETRAINED\n",
    "# PATH, local_files_only=True #/home/raisul/models/pretrain_100k #bert-base-uncased\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/home/raisul/models/pretrain_100k_O2\", num_labels=len(TYPE_MAPPING.items()))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88bd9a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize input text\n",
    "# inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt')\n",
    "# inputs = tokenizer(ALL_INPUT_LIST, max_length= MAX_TOKEN_SIZE,padding='max_length', truncation=True , return_tensors='pt')\n",
    "# print(inputs.keys())\n",
    "\n",
    "# labels = ALL_LABEL_LIST.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70219d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(inputs.keys())\n",
    "# print(inputs.token_type_ids)\n",
    "# inputs.token_type_ids[0][0] =1\n",
    "# print(inputs.token_type_ids)\n",
    "# #TODO set token type ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd332543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BinaryDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings):\n",
    "#         self.encodings = encodings\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#     def __len__(self):\n",
    "#         return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b2d13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        tokenized_text = (self.tokenizer(text , max_length= MAX_TOKEN_SIZE,padding='max_length', truncation=True , return_tensors='pt')).to(device)\n",
    "        \n",
    "        # Convert tokens to input IDs\n",
    "#         input_ids = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        \n",
    "        # Create input tensors\n",
    "#         input_ids = tokenized_text['input_ids']  #torch.tensor(input_ids)\n",
    "        label = torch.tensor([label]).to(device)\n",
    "        \n",
    "        return tokenized_text, label\n",
    "        \n",
    "#         return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6640b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = BinaryDataset(ALL_INPUT_LIST, ALL_LABEL_LIST,tokenizer)\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# validation_size = len(dataset) - train_size\n",
    "\n",
    "\n",
    "\n",
    "# Created using indices from 0 to train_size.\n",
    "train_dataset = torch.utils.data.Subset(dataset, range(TRAIN_SAMPLE_COUNT))\n",
    "\n",
    "# Created using indices from train_size to train_size + test_size.\n",
    "validation_dataset = torch.utils.data.Subset(dataset, range(TRAIN_SAMPLE_COUNT, TRAIN_SAMPLE_COUNT + VAL_SAMPLE_COUNT))\n",
    "\n",
    "\n",
    "# train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size])\n",
    "\n",
    "\n",
    "\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE ,shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "492ad250",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'data/typedata_dataset'+EXPERIMENT_NAME+'.ignore.pkl'\n",
    "with open(dataset_path, 'wb') as f:\n",
    "    pickle.dump([train_dataset, validation_dataset], f)\n",
    "    \n",
    "    \n",
    "with open(dataset_path, 'rb') as file:\n",
    "    train_dataset, validation_dataset  = pickle.load(file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac6496e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE ,shuffle=True) \n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44653e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_task2_metrices, global_task1_metrices ,v_global_task1_metrices, v_global_task2_metrices\n",
    "\n",
    "from numpy import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graph(task1_metrices,   v_task1_metrices, label = \"TypeGraph\" ):\n",
    "    \n",
    "    plt.ioff()\n",
    "\n",
    "    font_size = 10\n",
    "    x_labels = [ i for i in range(len(task1_metrices)) ]\n",
    "    \n",
    "    task1_f1 = [ i['f1'] for i in task1_metrices ]\n",
    "\n",
    "    \n",
    "    v_task1_f1 = [ i['f1'] for i in v_task1_metrices ]\n",
    "\n",
    "    \n",
    "\n",
    "    plt.ylabel(' F1 ',fontsize=font_size)\n",
    "    plt.plot(x_labels, task1_f1 , 'r') \n",
    "\n",
    "    \n",
    "    plt.plot(x_labels, v_task1_f1 , 'r' , linestyle = '--') \n",
    "\n",
    "    \n",
    "    plt.xlabel(\"Epoch\", fontsize=font_size)\n",
    "    plt.title(label,fontsize=font_size)\n",
    "    plt.legend([' Type Train',  'Type Val' ], loc='upper left')\n",
    "    \n",
    "    plt.savefig('./output/'+label+'_f1.pdf')\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "    \n",
    "    ################################\n",
    "    ################# LOSS #########\n",
    "    ################################\n",
    "    \n",
    "    task1_loss = [ i['loss'] for i in task1_metrices ]\n",
    "\n",
    "    \n",
    "    v_task1_loss = [ i['loss'] for i in v_task1_metrices ]\n",
    "    \n",
    "\n",
    "    plt.ylabel(' LOSS ',fontsize=font_size)\n",
    "    plt.plot(x_labels, task1_loss , 'r') \n",
    "    \n",
    "    plt.plot(x_labels, v_task1_loss , 'r' , linestyle = '--') \n",
    "\n",
    "    \n",
    "    plt.xlabel(\"Epoch\", fontsize=font_size)\n",
    "    plt.title(label,fontsize=font_size)\n",
    "    plt.legend([' Type Train',  'Type Val'], loc='upper left')\n",
    "    \n",
    "    plt.savefig('./output/'+label+'_loss.pdf')\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5142580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix,ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predicted_labels, label='confusion_matrix'):\n",
    "\n",
    "    class_labels = list(TYPE_MAPPING.keys())  \n",
    "    class_labels = [c for c in class_labels]\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels ) \n",
    "    \n",
    "    conf_per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "    average_acc = sum([i for i in conf_per_class  if not math.isnan(i)] )/len(conf_per_class)\n",
    "    \n",
    "    print('CONFUSION PER CLASS' , conf_per_class,average_acc)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    \n",
    "    res = sns.heatmap(cm,\n",
    "            annot=True , cmap=\"Blues\" , fmt='g' , xticklabels=class_labels,linewidths = .01,\n",
    "                      yticklabels=class_labels,linecolor=\"Gray\")\n",
    "    for _, spine in res.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(1)\n",
    "    \n",
    "    plt.ylabel('Actual',fontsize=13)\n",
    "    plt.xlabel('Prediction',fontsize=13)\n",
    "    plt.title('Confusion Matrix',fontsize=17)\n",
    "    plt.savefig('./output/'+label+'_conf.pdf',dpi=200)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    f1_score_per_class = f1_score(true_labels, predicted_labels, average=None)\n",
    "    print(f1_score_per_class,class_labels)\n",
    "    f1_scores_with_labels = {label:score for label,score in zip(class_labels, f1_score_per_class)}\n",
    "    print(f1_scores_with_labels)\n",
    "# plot_confusion_matrix(v_ground_truth_s , v_prediction_s ,label=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4054b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "  #--optimizer adam --adam-betas '(0.9,0.98)' --adam-eps 1e-6 --clip-norm 0.0 \\\n",
    " # --lr-scheduler polynomial_decay --lr $PEAK_LR --warmup-updates $WARMUP_UPDATES --total-num-update $TOTAL_UPDATES \\\n",
    "  #--dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \\\n",
    "\n",
    "#     ( params: typing.Iterable[torch.nn.parameter.Parameter]lr: float = 0.001betas: typing.Tuple[float, \n",
    "# float] = (0.9, 0.999)eps: float = 1e-06weight_decay: float = 0.0correct_bias: bool = Trueno_deprecation_warning: bool = False )\n",
    "    \n",
    "# initialize optimizer\n",
    "optim = AdamW( model.parameters() , lr=1e-5, eps = 1e-6, betas=(0.9,0.98), weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d84807a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model ,data_loop, is_training = False):\n",
    "    \n",
    "    prediction_s, ground_truth_s = [], []\n",
    "    losses = []\n",
    "\n",
    "    for N,batch in enumerate(data_loop):\n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        if is_training == True:\n",
    "            optim.zero_grad()\n",
    "        \n",
    "        batch_input, batch_labels = batch\n",
    "        if len(batch_labels)<BATCH_SIZE:\n",
    "            continue\n",
    "        batch_input_ids= batch_input['input_ids']\n",
    "        batch_attention_mask=batch_input['attention_mask']\n",
    "        batch_token_type_ids =batch_input['token_type_ids']\n",
    "\n",
    "        outputs = model(input_ids=batch_input_ids.squeeze(),\n",
    "                        attention_mask=batch_attention_mask.squeeze(),\n",
    "                        token_type_ids=batch_token_type_ids.squeeze(),\n",
    "                        labels=batch_labels )\n",
    "        \n",
    "#\n",
    "\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "\n",
    "\n",
    "        prediction_s.extend(predictions.detach().cpu().numpy().flatten())\n",
    "        ground_truth_s.extend(batch_labels.detach().cpu().numpy().flatten())\n",
    "\n",
    "\n",
    "        if is_training == True:\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "\n",
    "        # print relevant info to progress bar\n",
    "        data_loop.set_description(f'Epoch {ecpoch}')\n",
    "        data_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    ###### Training Scores\n",
    "    accuracy = accuracy_score(ground_truth_s, prediction_s)    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ground_truth_s,prediction_s,average='weighted')\n",
    "    metrices = {'accuracy':accuracy ,\n",
    "                      'precision':precision, \n",
    "                      'recall':recall, \n",
    "                      'f1':f1,\n",
    "                      'loss': (sum(losses) / len(losses))}\n",
    "    \n",
    "\n",
    "\n",
    "    return metrices , prediction_s, ground_truth_s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81a74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  14%|██▌               | 55/395 [00:25<02:27,  2.30it/s, loss=2.01]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "\n",
    "global_metrices = []\n",
    "v_global_metrices = []\n",
    "\n",
    "\n",
    "for ecpoch in range(EPOCHS):\n",
    "    \n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    model.train()\n",
    "    metrices,prediction_s, ground_truth_s  = training_loop(model ,train_loop, is_training = True)\n",
    "    print('Training metrices: ',metrices)\n",
    "    global_metrices.append(metrices)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        validation_loop = tqdm(validation_loader, leave=True)\n",
    "        v_metrices, v_prediction_s, v_ground_truth_s  = training_loop(model ,validation_loop, is_training = False)\n",
    "        plot_confusion_matrix(v_ground_truth_s , v_prediction_s ,label=EXPERIMENT_NAME)\n",
    "        print('v_metrices: ',v_metrices)\n",
    "        v_global_metrices.append(v_metrices)\n",
    "    plot_graph(global_metrices,v_global_metrices , label = EXPERIMENT_NAME)\n",
    "#     break\n",
    "    print('SAVING MODEL @ ',MODEL_SAVE_PATH +EXPERIMENT_NAME)\n",
    "    model.save_pretrained(MODEL_SAVE_PATH +EXPERIMENT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ddaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained( MODEL_SAVE_PATH  + EXPERIMENT_NAME )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Alhamdulillah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cce0879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae93b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
