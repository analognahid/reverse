{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af388b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device ,torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c86ae04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de072e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os, pickle\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME=\"TYPE_WRITER_BERT_SLIDING_WINDOW\"\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "MAX_TOKEN_SIZE = 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d98a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d5d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_types(type_name):\n",
    "    global TYPE_FIX_MAP\n",
    "    \n",
    "    prev_type_name= type_name\n",
    "    \n",
    "    if '*' in type_name:\n",
    "        if type_name.rindex('*')>0:#reduce to single * (rightmost, ignore array before that)\n",
    "            type_name = type_name[ type_name.rindex('*'): ]\n",
    "    if 'array_' in type_name:\n",
    "        if type_name.rindex('array_')>0:\n",
    "            type_name = type_name[ type_name.rindex('array_'): ]\n",
    "    if 'unsigned char' in type_name:\n",
    "        type_name = type_name.replace('unsigned char' , 'char')\n",
    "        \n",
    "        \n",
    "    if type_name not in TYPE_FIX_MAP:\n",
    "        TYPE_FIX_MAP[prev_type_name] = type_name\n",
    "    return type_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5c4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/media/raisul/nahid_personal/no_address/instructions_and_type_data_100k/'\n",
    "MODEL_SAVE_PATH =  '/home/raisul/models/'\n",
    "TYPE_COUNT ={}\n",
    "FINAL_TYPE_COUNT = {}\n",
    "TYPE_PROBABILITY = {}\n",
    "\n",
    "\n",
    "REJECT = ['union' , 'enumeration' , 'int128' , '_Bool' , 'complex' ,'bool']\n",
    "TYPE_FIX_MAP = {}\n",
    "MAX_TYPE_SAMPLE  =20*1000\n",
    "ALL_INPUT_LIST = []\n",
    "ALL_INPUT_SLICE_INFO  = []\n",
    "ALL_LABEL_LIST = []\n",
    "TYPE_MAPPING = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37270a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'int': 11101894, 'char': 434192, 'array_char': 609344, '*char': 1255594, 'array_int': 465690, '*structure': 2122842, 'float': 283988, '*int': 1522535, 'array_float': 17154, 'structure': 189656, 'double': 207029, 'long int': 146240, 'long unsigned int': 57514, '*double': 36982, 'array_double': 12242, 'array_structure': 24715, 'unsigned int': 217247, '*long unsigned int': 7279, 'short unsigned int': 29678, 'long long int': 86175, '*float': 24079, 'enumeration': 22400, '*long int': 23244, 'short int': 37036, '_Bool': 1984, 'long long unsigned int': 66040, 'array_unsigned int': 5131, 'array_long long int': 4264, '*long long int': 6573, 'union': 6065, '*short unsigned int': 4840, 'array_long int': 5138, '*signed char': 4414, 'signed char': 10188, '*unsigned int': 15627, 'array_short int': 1184, '*short int': 7230, '*long long unsigned int': 2043, 'array_long long unsigned int': 2450, 'array_long unsigned int': 1905, '*_Bool': 370, 'array__Bool': 23, '*union': 19396, 'array_union': 129, '*enumeration': 2230, 'array_signed char': 193, 'array_short unsigned int': 1044, '__int128 unsigned': 255, '*__int128 unsigned': 10, 'array___int128 unsigned': 11, 'array_enumeration': 24630, 'complex double': 31, '*long double': 6, 'array_long double': 1, '__int128': 16, 'long double': 11, 'bool': 10}\n",
      "20000 11101894 int\n",
      "20000 2122842 *structure\n",
      "20000 1522535 *int\n",
      "20000 1255594 *char\n",
      "20000 609344 array_char\n",
      "20000 465690 array_int\n",
      "20000 434192 char\n",
      "20000 283988 float\n",
      "20000 217247 unsigned int\n",
      "20000 207029 double\n",
      "20000 189656 structure\n",
      "20000 146240 long int\n",
      "20000 86175 long long int\n",
      "20000 66040 long long unsigned int\n",
      "20000 57514 long unsigned int\n",
      "20000 37036 short int\n",
      "20000 36982 *double\n",
      "20000 29678 short unsigned int\n",
      "20000 24715 array_structure\n",
      "20000 24079 *float\n",
      "20000 23244 *long int\n",
      "20000 17154 array_float\n",
      "20000 15627 *unsigned int\n",
      "20000 12242 array_double\n",
      "20000 10188 signed char\n",
      "20000 7279 *long unsigned int\n",
      "20000 7230 *short int\n",
      "20000 6573 *long long int\n",
      "20000 5138 array_long int\n",
      "20000 5131 array_unsigned int\n",
      "20000 4840 *short unsigned int\n",
      "20000 4414 *signed char\n",
      "20000 4264 array_long long int\n",
      "20000 2450 array_long long unsigned int\n",
      "20000 2043 *long long unsigned int\n",
      "20000 1905 array_long unsigned int\n",
      "20000 1184 array_short int\n",
      "20000 1044 array_short unsigned int\n",
      "20000 193 array_signed char\n",
      "20000 11 long double\n",
      "20000 6 *long double\n",
      "20000 1 array_long double\n",
      "{'int': 0.0018014944116742603, '*structure': 0.009421332345977704, '*int': 0.013135987021644823, '*char': 0.0159287158110026, 'array_char': 0.032822182543850435, 'array_int': 0.042947024844853875, 'char': 0.04606257139698566, 'float': 0.07042551093708185, 'unsigned int': 0.09206111016492748, 'double': 0.0966048234788363, 'structure': 0.10545408529126418, 'long int': 0.13676148796498905, 'long long int': 0.23208587177255585, 'long long unsigned int': 0.30284675953967294, 'long unsigned int': 0.3477414194804743, 'short int': 0.5400151204233719, '*double': 0.5408036342004219, 'short unsigned int': 0.6738998584810297, 'array_structure': 0.8092251669026906, '*float': 0.8305992773786287, '*long int': 0.8604371020478403, 'array_float': 1.1659088259298123, '*unsigned int': 1.279836180968836, 'array_double': 1.6337199803953601, 'signed char': 1.9630938358853554, '*long unsigned int': 2.7476301689792555, '*short int': 2.7662517289073305, '*long long int': 3.0427506465845124, 'array_long int': 3.8925652004671076, 'array_unsigned int': 3.8978756577665172, '*short unsigned int': 4.132231404958677, '*signed char': 4.531037607612143, 'array_long long int': 4.690431519699812, 'array_long long unsigned int': 8.16326530612245, '*long long unsigned int': 9.789525208027412, 'array_long unsigned int': 10.498687664041995, 'array_short int': 16.89189189189189, 'array_short unsigned int': 19.157088122605366, 'array_signed char': 103.62694300518135, 'long double': 1818.1818181818182, '*long double': 3333.3333333333335, 'array_long double': 20000.0}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'array_enumeration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m                     FINAL_TYPE_COUNT[type_str]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#         if fi>100:\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m#             break\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 71\u001b[0m, in \u001b[0;36mmake_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     69\u001b[0m type_str \u001b[38;5;241m=\u001b[39m TYPE_FIX_MAP[model_type_list[i]]\n\u001b[0;32m---> 71\u001b[0m type_label \u001b[38;5;241m=\u001b[39m \u001b[43mTYPE_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtype_str\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     72\u001b[0m backward_slice , target_slice, forward_slice \u001b[38;5;241m=\u001b[39m model_input_list[i]\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom()\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39mTYPE_PROBABILITY[type_str]:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'array_enumeration'"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO dont load all at a time in memry\n",
    "def make_dataset():\n",
    "    global TYPE_FIX_MAP, REJECT ,TYPE_COUNT,TYPE_MAPPING\n",
    "    #count how many real samples\n",
    "    for fi,pkl_file_name in enumerate(os.listdir(DATA_PATH)):\n",
    "        pkl_path = os.path.join(DATA_PATH,pkl_file_name)\n",
    "        with open(pkl_path, 'rb') as file:\n",
    "            try:\n",
    "                model_input_list, model_type_list = pickle.load(file)\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            for i in range(len(model_input_list)):\n",
    "\n",
    "                type_str = fix_types(model_type_list[i])\n",
    "                \n",
    "                if type_str not in TYPE_COUNT:\n",
    "                    TYPE_COUNT[type_str] = 0\n",
    "                    FINAL_TYPE_COUNT[type_str] = 0\n",
    "                \n",
    "                TYPE_COUNT[type_str] +=1\n",
    "#         if fi>100:\n",
    "#             break\n",
    "    print(TYPE_COUNT)\n",
    "    \n",
    "    #remove the unwanted types\n",
    "    temp_removed_keys = []\n",
    "    for rk in REJECT:\n",
    "        for tk in TYPE_COUNT:\n",
    "            if rk in tk:\n",
    "                temp_removed_keys.append(tk)\n",
    "    print('temp_removed_keys',temp_removed_keys)\n",
    "    for trk in temp_removed_keys:\n",
    "        TYPE_COUNT.pop(trk)\n",
    "        FINAL_TYPE_COUNT.pop(trk)\n",
    "        TYPE_FIX_MAP.pop(trk)\n",
    "    \n",
    "    TYPE_COUNT = {k: v for k, v in sorted(TYPE_COUNT.items(), key=lambda item: item[1] , reverse=True)}\n",
    "\n",
    "\n",
    "    ti = 0\n",
    "    for key,val in TYPE_COUNT.items():\n",
    "        TYPE_MAPPING[key]  = ti\n",
    "        ti+=1\n",
    "\n",
    "    #make the probability\n",
    "    for key in TYPE_COUNT.keys():\n",
    "        print(MAX_TYPE_SAMPLE , TYPE_COUNT[key] ,key)\n",
    "        TYPE_PROBABILITY[key] = MAX_TYPE_SAMPLE/TYPE_COUNT[key]\n",
    "    \n",
    "\n",
    "    print(TYPE_PROBABILITY)\n",
    "    \n",
    "    #fill dataset with that probability\n",
    "    for fi,pkl_file_name in enumerate(os.listdir(DATA_PATH)):\n",
    "        pkl_path = os.path.join(DATA_PATH,pkl_file_name)\n",
    "\n",
    "        with open(pkl_path, 'rb') as file:\n",
    "            try:\n",
    "                model_input_list, model_type_list = pickle.load(file)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            for i in range(len(model_input_list)):\n",
    "#                 if tyoe\n",
    "#                 TYPE_FIX_MAP\n",
    "                \n",
    "\n",
    "                if model_type_list[i] not in TYPE_FIX_MAP:\n",
    "                    continue\n",
    "                type_str = TYPE_FIX_MAP[model_type_list[i]]\n",
    "                \n",
    "                type_label = TYPE_MAPPING[type_str]\n",
    "                backward_slice , target_slice, forward_slice = model_input_list[i]\n",
    "\n",
    "                if random.random()<=TYPE_PROBABILITY[type_str]:\n",
    "\n",
    "                    ALL_INPUT_LIST.append(backward_slice + target_slice + forward_slice)\n",
    "                    ALL_INPUT_SLICE_INFO.append([len(backward_slice) , len(target_slice) , len(forward_slice)])\n",
    "                    ALL_LABEL_LIST.append(type_label)\n",
    "                    \n",
    "                    FINAL_TYPE_COUNT[type_str]+=1\n",
    "#         if fi>100:\n",
    "#             break\n",
    "make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc5c057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'int': 0,\n",
       "  '*structure': 1,\n",
       "  '*int': 2,\n",
       "  '*char': 3,\n",
       "  'array_char': 4,\n",
       "  'array_int': 5,\n",
       "  'char': 6,\n",
       "  'float': 7,\n",
       "  'unsigned int': 8,\n",
       "  'double': 9,\n",
       "  'structure': 10,\n",
       "  'long int': 11,\n",
       "  'long long int': 12,\n",
       "  'long long unsigned int': 13,\n",
       "  'long unsigned int': 14,\n",
       "  'short int': 15,\n",
       "  '*double': 16,\n",
       "  'short unsigned int': 17,\n",
       "  'array_structure': 18,\n",
       "  '*float': 19,\n",
       "  '*long int': 20,\n",
       "  'array_float': 21,\n",
       "  '*unsigned int': 22,\n",
       "  'array_double': 23,\n",
       "  'signed char': 24,\n",
       "  '*long unsigned int': 25,\n",
       "  '*short int': 26,\n",
       "  '*long long int': 27,\n",
       "  'array_long int': 28,\n",
       "  'array_unsigned int': 29,\n",
       "  '*short unsigned int': 30,\n",
       "  '*signed char': 31,\n",
       "  'array_long long int': 32,\n",
       "  'array_long long unsigned int': 33,\n",
       "  '*long long unsigned int': 34,\n",
       "  'array_long unsigned int': 35,\n",
       "  'array_short int': 36,\n",
       "  'array_short unsigned int': 37,\n",
       "  'array_signed char': 38,\n",
       "  'long double': 39,\n",
       "  '*long double': 40,\n",
       "  'array_long double': 41},\n",
       " {'int': 'int',\n",
       "  'char': 'char',\n",
       "  'array_char': 'array_char',\n",
       "  '*char': '*char',\n",
       "  'array_int': 'array_int',\n",
       "  '*structure': '*structure',\n",
       "  'float': 'float',\n",
       "  '*int': '*int',\n",
       "  'array_float': 'array_float',\n",
       "  'structure': 'structure',\n",
       "  'double': 'double',\n",
       "  'long int': 'long int',\n",
       "  'long unsigned int': 'long unsigned int',\n",
       "  '*double': '*double',\n",
       "  'array_double': 'array_double',\n",
       "  'array_structure': 'array_structure',\n",
       "  'unsigned int': 'unsigned int',\n",
       "  '*long unsigned int': '*long unsigned int',\n",
       "  'short unsigned int': 'short unsigned int',\n",
       "  'long long int': 'long long int',\n",
       "  '*float': '*float',\n",
       "  '*long int': '*long int',\n",
       "  'short int': 'short int',\n",
       "  'long long unsigned int': 'long long unsigned int',\n",
       "  'array_unsigned int': 'array_unsigned int',\n",
       "  'array_long long int': 'array_long long int',\n",
       "  '**long long int': '*long long int',\n",
       "  '*long long int': '*long long int',\n",
       "  '*short unsigned int': '*short unsigned int',\n",
       "  'array_long int': 'array_long int',\n",
       "  '**signed char': '*signed char',\n",
       "  '*signed char': '*signed char',\n",
       "  'signed char': 'signed char',\n",
       "  '*unsigned int': '*unsigned int',\n",
       "  'array_short int': 'array_short int',\n",
       "  '*short int': '*short int',\n",
       "  '*long long unsigned int': '*long long unsigned int',\n",
       "  'array_long long unsigned int': 'array_long long unsigned int',\n",
       "  'array_long unsigned int': 'array_long unsigned int',\n",
       "  'array_signed char': 'array_signed char',\n",
       "  'array_short unsigned int': 'array_short unsigned int',\n",
       "  '*array_enumeration': 'array_enumeration',\n",
       "  '*long double': '*long double',\n",
       "  'array_long double': 'array_long double',\n",
       "  'long double': 'long double'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TYPE_MAPPING,TYPE_FIX_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp_path = 'data/typedata.ignore.pkl'\n",
    "with open(data_temp_path, 'wb') as f:\n",
    "    pickle.dump([TYPE_COUNT , TYPE_MAPPING ,ALL_INPUT_LIST, ALL_INPUT_SLICE_INFO ,ALL_LABEL_LIST,FINAL_TYPE_COUNT ], f)\n",
    "    \n",
    "    \n",
    "with open(data_temp_path, 'rb') as file:\n",
    "    TYPE_COUNT , TYPE_MAPPING ,ALL_INPUT_LIST, ALL_INPUT_SLICE_INFO ,ALL_LABEL_LIST,FINAL_TYPE_COUNT  = pickle.load(file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ALL_INPUT_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer  = BertTokenizer.from_pretrained(\"./multytask-tokenizer\")\n",
    "\n",
    "#https://github.com/huggingface/tokenizers/issues/247\n",
    "\n",
    "mask_token_id, look_token_id, eoi_token_id = tokenizer.encode('[MASK] [LOOK] [EOI]')[1:-1]\n",
    "\n",
    "print(mask_token_id, look_token_id, eoi_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa991f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "\n",
    "print('VOCAB SIZE : ', (tokenizer.vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ddc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "#TODO*** USE PRETRAINED\n",
    "# PATH, local_files_only=True\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(TYPE_MAPPING.items()))\n",
    "model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd9a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize input text\n",
    "# inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt')\n",
    "# inputs = tokenizer(ALL_INPUT_LIST, max_length= MAX_TOKEN_SIZE,padding='max_length', truncation=True , return_tensors='pt')\n",
    "# print(inputs.keys())\n",
    "\n",
    "# labels = ALL_LABEL_LIST.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70219d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(inputs.keys())\n",
    "# print(inputs.token_type_ids)\n",
    "# inputs.token_type_ids[0][0] =1\n",
    "# print(inputs.token_type_ids)\n",
    "# #TODO set token type ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd332543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BinaryDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings):\n",
    "#         self.encodings = encodings\n",
    "#     def __getitem__(self, idx):\n",
    "#         return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#     def __len__(self):\n",
    "#         return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        tokenized_text = (self.tokenizer(text , max_length= MAX_TOKEN_SIZE,padding='max_length', truncation=True , return_tensors='pt')).to(device)\n",
    "        \n",
    "        # Convert tokens to input IDs\n",
    "#         input_ids = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        \n",
    "        # Create input tensors\n",
    "#         input_ids = tokenized_text['input_ids']  #torch.tensor(input_ids)\n",
    "        label = torch.tensor([label]).to(device)\n",
    "        \n",
    "        return tokenized_text, label\n",
    "        \n",
    "#         return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b1ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ALL_INPUT_LIST ), len(ALL_LABEL_LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BinaryDataset(ALL_INPUT_LIST, ALL_LABEL_LIST,tokenizer)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "validation_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size])\n",
    "\n",
    "TRAIN_LABELS = ALL_LABEL_LIST[:train_size]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83556b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPE_PROBABILITY\n",
    "total_samples = sum(list(TYPE_COUNT.values()))\n",
    "TYPE_WEIGHTS = [ (total_samples/i) for i in list(TYPE_COUNT.values()) ]\n",
    "weights = [0] * len(train_dataset)\n",
    "for indx, tlabel in enumerate(TRAIN_LABELS):\n",
    "    type_index =  tlabel\n",
    "    weights [indx]= TYPE_WEIGHTS[type_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6496e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(train_dataset), replacement=True)\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE ,shuffle=True) #sampler = sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44653e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_task2_metrices, global_task1_metrices ,v_global_task1_metrices, v_global_task2_metrices\n",
    "\n",
    "from numpy import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graph(task1_metrices,   v_task1_metrices, label = \"TypeGraph\" ):\n",
    "    \n",
    "    plt.ioff()\n",
    "\n",
    "    font_size = 10\n",
    "    x_labels = [ i for i in range(len(task1_metrices)) ]\n",
    "    \n",
    "    task1_f1 = [ i['f1'] for i in task1_metrices ]\n",
    "\n",
    "    \n",
    "    v_task1_f1 = [ i['f1'] for i in v_task1_metrices ]\n",
    "\n",
    "    \n",
    "\n",
    "    plt.ylabel(' F1 ',fontsize=font_size)\n",
    "    plt.plot(x_labels, task1_f1 , 'r') \n",
    "\n",
    "    \n",
    "    plt.plot(x_labels, v_task1_f1 , 'r' , linestyle = '--') \n",
    "\n",
    "    \n",
    "    plt.xlabel(\"Epoch\", fontsize=font_size)\n",
    "    plt.title(label,fontsize=font_size)\n",
    "    plt.legend([' Type Train',  'Type Val' ], loc='upper left')\n",
    "    \n",
    "    plt.savefig('./output/'+label+'_f1.pdf')\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "    \n",
    "    ################################\n",
    "    ################# LOSS #########\n",
    "    ################################\n",
    "    \n",
    "    task1_loss = [ i['loss'] for i in task1_metrices ]\n",
    "\n",
    "    \n",
    "    v_task1_loss = [ i['loss'] for i in v_task1_metrices ]\n",
    "    \n",
    "\n",
    "    plt.ylabel(' LOSS ',fontsize=font_size)\n",
    "    plt.plot(x_labels, task1_loss , 'r') \n",
    "    \n",
    "    plt.plot(x_labels, v_task1_loss , 'r' , linestyle = '--') \n",
    "\n",
    "    \n",
    "    plt.xlabel(\"Epoch\", fontsize=font_size)\n",
    "    plt.title(label,fontsize=font_size)\n",
    "    plt.legend([' Type Train',  'Type Val'], loc='upper left')\n",
    "    \n",
    "    plt.savefig('./output/'+label+'_loss.pdf')\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix,ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predicted_labels, label='confusion_matrix'):\n",
    "\n",
    "    class_labels = list(TYPE_MAPPING.keys())  \n",
    "    class_labels = [c for c in class_labels]\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels ) \n",
    "    \n",
    "    conf_per_class = cm.diagonal()/cm.sum(axis=1)\n",
    "    average_acc = sum([i for i in conf_per_class  if not math.isnan(i)] )/len(conf_per_class)\n",
    "    \n",
    "    print('CONFUSION PER CLASS',conf_per_class,average_acc)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    \n",
    "    res = sns.heatmap(cm,\n",
    "            annot=True , cmap=\"Blues\" , fmt='g' , xticklabels=class_labels,linewidths = .01,\n",
    "                      yticklabels=class_labels,linecolor=\"Gray\")\n",
    "    for _, spine in res.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(1)\n",
    "    \n",
    "    plt.ylabel('Actual',fontsize=13)\n",
    "    plt.xlabel('Prediction',fontsize=13)\n",
    "    plt.title('Confusion Matrix',fontsize=17)\n",
    "    plt.savefig('./output/'+label+'_conf.pdf',dpi=200)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "# plot_confusion_matrix(v_ground_truth_s , v_prediction_s ,label=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4054b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# initialize optimizer\n",
    "optim = AdamW( model.parameters() , lr=5e-6)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84807a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model ,data_loop, is_training = False):\n",
    "    \n",
    "    prediction_s, ground_truth_s = [], []\n",
    "    losses = []\n",
    "\n",
    "    for N,batch in enumerate(data_loop):\n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        if is_training == True:\n",
    "            optim.zero_grad()\n",
    "        \n",
    "        batch_input, batch_labels = batch\n",
    "        if len(batch_labels)<BATCH_SIZE:\n",
    "            continue\n",
    "        batch_input_ids= batch_input['input_ids']\n",
    "        batch_attention_mask=batch_input['attention_mask']\n",
    "        batch_token_type_ids =batch_input['token_type_ids']\n",
    "\n",
    "        outputs = model(input_ids=batch_input_ids.squeeze(),\n",
    "                        attention_mask=batch_attention_mask.squeeze(),\n",
    "                        token_type_ids=batch_token_type_ids.squeeze(),\n",
    "                        labels=batch_labels )\n",
    "        \n",
    "#\n",
    "\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        \n",
    "\n",
    "\n",
    "        prediction_s.extend(predictions.detach().cpu().numpy().flatten())\n",
    "        ground_truth_s.extend(batch_labels.detach().cpu().numpy().flatten())\n",
    "\n",
    "\n",
    "        if is_training == True:\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "\n",
    "        # print relevant info to progress bar\n",
    "        data_loop.set_description(f'Epoch {ecpoch}')\n",
    "        data_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    ###### Training Scores\n",
    "    accuracy = accuracy_score(ground_truth_s, prediction_s)    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(ground_truth_s,prediction_s,average='weighted')\n",
    "    metrices = {'accuracy':accuracy ,\n",
    "                      'precision':precision, \n",
    "                      'recall':recall, \n",
    "                      'f1':f1,\n",
    "                      'loss': (sum(losses) / len(losses))}\n",
    "    \n",
    "\n",
    "\n",
    "    return metrices , prediction_s, ground_truth_s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "global_metrices = []\n",
    "v_global_metrices = []\n",
    "\n",
    "\n",
    "for ecpoch in range(EPOCHS):\n",
    "    \n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    model.train()\n",
    "    metrices,prediction_s, ground_truth_s  = training_loop(model ,train_loop, is_training = True)\n",
    "    print('Training metrices: ',metrices)\n",
    "    global_metrices.append(metrices)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        validation_loop = tqdm(validation_loader, leave=True)\n",
    "        v_metrices, v_prediction_s, v_ground_truth_s  = training_loop(model ,validation_loop, is_training = False)\n",
    "        plot_confusion_matrix(v_ground_truth_s , v_prediction_s ,label=EXPERIMENT_NAME)\n",
    "        print('v_metrices: ',v_metrices)\n",
    "        v_global_metrices.append(v_metrices)\n",
    "    plot_graph(global_metrices,v_global_metrices , label = EXPERIMENT_NAME)\n",
    "#     break\n",
    "    print('SAVING MODEL @ ',MODEL_SAVE_PATH +EXPERIMENT_NAME)\n",
    "    model.save_pretrained(MODEL_SAVE_PATH +EXPERIMENT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ddaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(MODEL_SAVE_PATH +EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Alhamdulillah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac6017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
