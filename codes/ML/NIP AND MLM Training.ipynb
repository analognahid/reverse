{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Instruction Prediction Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahid/anaconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gitwipe 4\n",
      "gitps 147\n",
      "gitview 140\n",
      "gitfm 341\n",
      "gitwhich 6\n",
      "gitkeys 4\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys,os\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from elftools.elf.segments import Segment\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dir_path = \"./data/binaries/\"\n",
    "dir_file_list = os.listdir(data_dir_path)\n",
    "\n",
    "with open('./data/instruction_clusters.txt', 'w') as data_file:\n",
    "    for filename in dir_file_list:\n",
    "        filePath = os.path.join(data_dir_path,filename)\n",
    "\n",
    "        fh = open(filePath, 'rb')\n",
    "        bin_bytearray = bytearray(fh.read())\n",
    "        \n",
    "        with open(filePath, 'rb') as f:\n",
    "            elf = ELFFile(f)\n",
    "            dwarfinfo = elf.get_dwarf_info()\n",
    "            aranges = dwarfinfo.get_aranges()\n",
    "            print(filename, len(aranges.entries))\n",
    "            for arange in aranges.entries:\n",
    "\n",
    "                entry = arange.begin_addr\n",
    "                exit  = arange.begin_addr + arange.length\n",
    "                ops = bin_bytearray[entry: exit]\n",
    "\n",
    "                md = Cs(CS_ARCH_X86, CS_MODE_64)\n",
    "                md.detail = True\n",
    "                for inst in md.disasm(ops, entry):\n",
    "\n",
    "                    data_file.write(inst.mnemonic+\" \"+inst.op_str+\";\")\n",
    "                data_file.write('\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction,BertForPreTraining\n",
    "import torch\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./binary-tokenizer\")\n",
    "# model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delim = ';'\n",
    "with open('./data/instruction_clusters.txt', 'r') as fp:\n",
    "    text = fp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = text[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split sentences into consecutive, and non-consecutive sequences.\n",
    "\n",
    "We have to deal with edge-cases too - for example where there is only a single sentence within a paragraph as with the three examples above (in comparison to below where we can easily split into multiple sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text[51].split(delim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assign a 50% probability of using the genuine next sentence, and 50% probability of using another random sentence.\n",
    "\n",
    "To make this simpler, we'll create a *'bag'* of individual sentences to pull from when selecting a random sentence B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49783\n"
     ]
    }
   ],
   "source": [
    "bag = [instruction for instruction_cluster in text for instruction in instruction_cluster.split(delim)  if instruction!= '']\n",
    "bag_size = len(bag)\n",
    "print(bag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'mov rdx, qword ptr [rip + 0x2d98]',\n",
       " 'mov rax, qword ptr [rip + 0x2d81]',\n",
       " 'lea rcx, [rip + 0xd62]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1120',\n",
       " 'mov edi, 1',\n",
       " 'call 0x1170',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov dword ptr [rbp - 0x14], edi',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'mov edx, 1',\n",
       " 'mov esi, 0',\n",
       " 'mov edi, eax',\n",
       " 'call 0x1180',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'mov edx, 2',\n",
       " 'mov esi, 0',\n",
       " 'mov edi, eax',\n",
       " 'call 0x1180',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov rcx, qword ptr [rbp - 0x10]',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'mov edx, 0',\n",
       " 'mov rsi, rcx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x1180',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x40',\n",
       " 'mov qword ptr [rbp - 0x38], rdi',\n",
       " 'mov rax, qword ptr [rbp - 0x38]',\n",
       " 'mov esi, 2',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1160',\n",
       " 'mov dword ptr [rbp - 0x2c], eax',\n",
       " 'cmp dword ptr [rbp - 0x2c], -1',\n",
       " 'jne 0x137a',\n",
       " 'mov rdx, qword ptr [rip + 0x2cdf]',\n",
       " 'mov rax, qword ptr [rip + 0x2cc8]',\n",
       " 'mov rcx, qword ptr [rbp - 0x38]',\n",
       " 'lea rsi, [rip + 0xcbd]',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1120',\n",
       " 'mov eax, 1',\n",
       " 'jmp 0x14cd',\n",
       " 'mov eax, dword ptr [rbp - 0x2c]',\n",
       " 'mov edi, eax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x12c0',\n",
       " 'mov qword ptr [rbp - 0x18], rax',\n",
       " 'cmp qword ptr [rbp - 0x18], 0',\n",
       " 'jne 0x139e',\n",
       " 'mov eax, 0',\n",
       " 'jmp 0x14cd',\n",
       " 'mov edi, 0x10000',\n",
       " 'call 0x1150',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'cmp qword ptr [rbp - 0x10], 0',\n",
       " 'jne 0x13e2',\n",
       " 'mov rdx, qword ptr [rip + 0x2c76]',\n",
       " 'mov rax, qword ptr [rip + 0x2c5f]',\n",
       " 'lea rcx, [rip + 0xc78]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1120',\n",
       " 'mov eax, 1',\n",
       " 'jmp 0x14cd',\n",
       " 'mov qword ptr [rbp - 0x28], 0',\n",
       " 'jmp 0x14ab',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'sub rax, qword ptr [rbp - 0x28]',\n",
       " 'mov edx, 0x10000',\n",
       " 'cmp rax, rdx',\n",
       " 'cmovg rax, rdx',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov qword ptr [rbp - 0x20], 0',\n",
       " 'jmp 0x1451',\n",
       " 'call 0x1190',\n",
       " 'movsxd rdx, eax',\n",
       " 'imul rdx, rdx, -0x7f7f7f7f',\n",
       " 'shr rdx, 0x20',\n",
       " 'add edx, eax',\n",
       " 'sar edx, 7',\n",
       " 'mov esi, eax',\n",
       " 'sar esi, 0x1f',\n",
       " 'mov ecx, edx',\n",
       " 'sub ecx, esi',\n",
       " 'mov edx, ecx',\n",
       " 'shl edx, 8',\n",
       " 'sub edx, ecx',\n",
       " 'sub eax, edx',\n",
       " 'mov ecx, eax',\n",
       " 'mov rdx, qword ptr [rbp - 0x20]',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'add rax, rdx',\n",
       " 'mov edx, ecx',\n",
       " 'mov byte ptr [rax], dl',\n",
       " 'add qword ptr [rbp - 0x20], 1',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'cmp rax, qword ptr [rbp - 8]',\n",
       " 'jl 0x1411',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'mov rcx, qword ptr [rbp - 0x10]',\n",
       " 'mov eax, dword ptr [rbp - 0x2c]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x10f0',\n",
       " 'cmp qword ptr [rbp - 8], rax',\n",
       " 'je 0x14a3',\n",
       " 'mov rdx, qword ptr [rip + 0x2bb3]',\n",
       " 'mov rax, qword ptr [rip + 0x2b9c]',\n",
       " 'mov rcx, qword ptr [rbp - 0x38]',\n",
       " 'lea rsi, [rip + 0xbd0]',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1120',\n",
       " 'mov eax, 1',\n",
       " 'jmp 0x14cd',\n",
       " 'add qword ptr [rbp - 0x28], 0x10000',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'cmp rax, qword ptr [rbp - 0x18]',\n",
       " 'jl 0x13ef',\n",
       " 'mov eax, dword ptr [rbp - 0x2c]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x1100',\n",
       " 'call 0x1140',\n",
       " 'mov eax, 0',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov dword ptr [rbp - 0x14], edi',\n",
       " 'mov qword ptr [rbp - 0x20], rsi',\n",
       " 'mov dword ptr [rbp - 4], 0',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'mov qword ptr [rip + 0x2b39], rax',\n",
       " 'cmp dword ptr [rbp - 0x14], 1',\n",
       " 'jg 0x1507',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1289',\n",
       " 'mov edi, 0',\n",
       " 'call 0x1130',\n",
       " 'mov edi, eax',\n",
       " 'call 0x1110',\n",
       " 'mov dword ptr [rbp - 8], 1',\n",
       " 'jmp 0x154c',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'cdqe ',\n",
       " 'lea rdx, [rax*8]',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'add rax, rdx',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x131b',\n",
       " 'add dword ptr [rbp - 4], eax',\n",
       " 'add dword ptr [rbp - 8], 1',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'cmp eax, dword ptr [rbp - 0x14]',\n",
       " 'jl 0x1521',\n",
       " 'cmp dword ptr [rbp - 4], 0',\n",
       " 'setne al',\n",
       " 'movzx eax, al',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'mov rax, qword ptr [rip + 0xdd38]',\n",
       " 'test rax, rax',\n",
       " 'je 0x3b2c',\n",
       " 'mov rax, qword ptr [rip + 0xdd2c]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x35b0',\n",
       " 'mov rax, qword ptr [rip + 0xdd25]',\n",
       " 'test rax, rax',\n",
       " 'je 0x3b47',\n",
       " 'mov rax, qword ptr [rip + 0xdd19]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x35b0',\n",
       " 'nop ',\n",
       " 'pop rbp',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'mov eax, dword ptr [rip + 0xde08]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xdd0e]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3700',\n",
       " 'mov rax, qword ptr [rip + 0xdd32]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rip + 0xddda]',\n",
       " 'cmp edx, eax',\n",
       " 'jge 0x3b9d',\n",
       " 'mov rax, qword ptr [rip + 0xdd17]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cdqe ',\n",
       " 'jmp 0x3ba5',\n",
       " 'mov eax, dword ptr [rip + 0xddbd]',\n",
       " 'cdqe ',\n",
       " 'mov rsi, qword ptr [rip + 0xdcfc]',\n",
       " 'mov rcx, qword ptr [rip + 0xdcbd]',\n",
       " 'mov rdx, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'mov edx, dword ptr [rip + 0xc4c0]',\n",
       " 'mov ecx, dword ptr [rip + 0xc4b6]',\n",
       " 'mov eax, dword ptr [rip + 0xc4b8]',\n",
       " 'mov esi, ecx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x759a',\n",
       " 'mov rax, qword ptr [rip + 0xdca8]',\n",
       " 'mov edx, 0',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov edx, dword ptr [rip + 0xdd68]',\n",
       " 'mov rcx, qword ptr [rip + 0xdc71]',\n",
       " 'mov rax, qword ptr [rip + 0xdc82]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'nop ',\n",
       " 'pop rbp',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'push rbx',\n",
       " 'sub rsp, 8',\n",
       " 'mov eax, dword ptr [rip + 0xdd39]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xdc3f]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3700',\n",
       " 'mov eax, dword ptr [rip + 0xdd1c]',\n",
       " 'lea ebx, [rax - 2]',\n",
       " 'lea rax, [rip + 0xd3f2]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cmp ebx, eax',\n",
       " 'jg 0x3c67',\n",
       " 'mov eax, dword ptr [rip + 0xdd00]',\n",
       " 'sub eax, 2',\n",
       " 'cdqe ',\n",
       " 'jmp 0x3c78',\n",
       " 'lea rax, [rip + 0xd3d2]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cdqe ',\n",
       " 'mov rdx, qword ptr [rip + 0xdbf1]',\n",
       " 'lea rcx, [rdx + 2]',\n",
       " 'mov rdx, rax',\n",
       " 'lea rax, [rip + 0xd3b3]',\n",
       " 'mov rsi, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'mov edx, dword ptr [rip + 0xc3f2]',\n",
       " 'mov ecx, dword ptr [rip + 0xc3e8]',\n",
       " 'mov eax, dword ptr [rip + 0xc3ea]',\n",
       " 'mov esi, ecx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x759a',\n",
       " 'mov rax, qword ptr [rip + 0xdbd6]',\n",
       " 'mov edx, 0',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov edx, dword ptr [rip + 0xdc8e]',\n",
       " 'mov rcx, qword ptr [rip + 0xdb97]',\n",
       " 'mov rax, qword ptr [rip + 0xdbb0]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'nop ',\n",
       " 'mov rbx, qword ptr [rbp - 8]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x10',\n",
       " 'mov qword ptr [rbp - 8], rdi',\n",
       " 'mov eax, dword ptr [rip + 0xdc58]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xdb5e]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3700',\n",
       " 'cmp qword ptr [rbp - 8], 0',\n",
       " 'je 0x3d6e',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rip + 0xdc26]',\n",
       " 'cmp edx, eax',\n",
       " 'jge 0x3d4e',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cdqe ',\n",
       " 'jmp 0x3d56',\n",
       " 'mov eax, dword ptr [rip + 0xdc0c]',\n",
       " 'cdqe ',\n",
       " 'mov rcx, qword ptr [rip + 0xdb13]',\n",
       " 'mov rsi, qword ptr [rbp - 8]',\n",
       " 'mov rdx, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'jmp 0x3dbd',\n",
       " 'mov rax, qword ptr [rip + 0xdb3b]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rip + 0xdbdb]',\n",
       " 'cmp edx, eax',\n",
       " 'jge 0x3d9c',\n",
       " 'mov rax, qword ptr [rip + 0xdb20]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cdqe ',\n",
       " 'jmp 0x3da4',\n",
       " 'mov eax, dword ptr [rip + 0xdbbe]',\n",
       " 'cdqe ',\n",
       " 'mov rsi, qword ptr [rip + 0xdb05]',\n",
       " 'mov rcx, qword ptr [rip + 0xdabe]',\n",
       " 'mov rdx, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'mov edx, dword ptr [rip + 0xc2e5]',\n",
       " 'mov ecx, dword ptr [rip + 0xc2db]',\n",
       " 'mov eax, dword ptr [rip + 0xc2dd]',\n",
       " 'mov esi, ecx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x759a',\n",
       " 'mov rax, qword ptr [rip + 0xdac1]',\n",
       " 'mov edx, 0',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov eax, dword ptr [rip + 0xdb69]',\n",
       " 'cmp eax, 9',\n",
       " 'jg 0x3e1d',\n",
       " 'mov edx, dword ptr [rip + 0xdb5e]',\n",
       " 'mov rcx, qword ptr [rip + 0xda67]',\n",
       " 'mov rax, qword ptr [rip + 0xda90]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'jmp 0x3e5d',\n",
       " 'mov rdx, qword ptr [rip + 0xda4c]',\n",
       " 'mov eax, dword ptr [rip + 0xdb36]',\n",
       " 'sub eax, 1',\n",
       " 'cdqe ',\n",
       " 'sub rax, 0xa',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0x20',\n",
       " 'mov eax, dword ptr [rip + 0xdb21]',\n",
       " 'sub eax, 0xa',\n",
       " 'mov edx, eax',\n",
       " 'mov rcx, qword ptr [rip + 0xda25]',\n",
       " 'mov rax, qword ptr [rip + 0xda4e]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'nop ',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov dword ptr [rbp - 0x14], edi',\n",
       " 'mov dword ptr [rbp - 4], 9',\n",
       " 'cmp dword ptr [rbp - 0x14], 0',\n",
       " 'js 0x3eb5',\n",
       " 'mov dword ptr [rbp - 8], 0',\n",
       " 'jmp 0x3eaf',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 4',\n",
       " 'mov rdx, rax',\n",
       " 'lea rax, [rip + 0xc2b4]',\n",
       " 'mov eax, dword ptr [rdx + rax]',\n",
       " 'cmp dword ptr [rbp - 0x14], eax',\n",
       " 'jne 0x3eab',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'mov dword ptr [rip + 0xda0f], eax',\n",
       " 'jmp 0x3eb5',\n",
       " 'add dword ptr [rbp - 8], 1',\n",
       " 'cmp dword ptr [rbp - 8], 0x21',\n",
       " 'jle 0x3e85',\n",
       " 'mov eax, dword ptr [rip + 0xdaa5]',\n",
       " 'cmp dword ptr [rbp - 4], eax',\n",
       " 'jge 0x3f3b',\n",
       " 'mov edx, dword ptr [rip + 0xc1e2]',\n",
       " 'mov eax, dword ptr [rip + 0xc1e0]',\n",
       " 'mov esi, 7',\n",
       " 'mov edi, eax',\n",
       " 'call 0x759a',\n",
       " 'mov eax, dword ptr [rip + 0xda82]',\n",
       " 'sub eax, dword ptr [rbp - 4]',\n",
       " 'lea edx, [rax - 1]',\n",
       " 'mov rax, qword ptr [rip + 0xd9b5]',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov eax, dword ptr [rip + 0xd9ba]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 4',\n",
       " 'mov rdx, rax',\n",
       " 'lea rax, [rip + 0xc232]',\n",
       " 'lea rcx, [rdx + rax]',\n",
       " 'mov rax, qword ptr [rip + 0xd987]',\n",
       " 'mov edx, dword ptr [rbp - 4]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'mov rax, qword ptr [rip + 0xd972]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x91cd',\n",
       " 'mov eax, dword ptr [rip + 0xda1f]',\n",
       " 'lea edx, [rax - 1]',\n",
       " 'mov rax, qword ptr [rip + 0xd955]',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'nop ',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov eax, 0',\n",
       " 'call 0x7e66',\n",
       " 'mov qword ptr [rbp - 0x20], rax',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov qword ptr [rbp - 0x18], rax',\n",
       " 'cmp qword ptr [rbp - 0x18], 0',\n",
       " 'je 0x40d6',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rax - 1]',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'cmp al, 7',\n",
       " 'je 0x40d6',\n",
       " 'mov eax, 0',\n",
       " 'call 0x7e66',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x68d7',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'sub rax, -0x80',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xba00',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov rdx, qword ptr [rbp - 0x10]',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'lea rcx, [rip + 0x80e6]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x3980',\n",
       " 'mov eax, dword ptr [rip + 0xd95f]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xd865]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3700',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rip + 0xd934]',\n",
       " 'cmp edx, eax',\n",
       " 'jge 0x4040',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cdqe ',\n",
       " 'jmp 0x4048',\n",
       " 'mov eax, dword ptr [rip + 0xd91a]',\n",
       " 'cdqe ',\n",
       " 'mov rcx, qword ptr [rip + 0xd821]',\n",
       " 'mov rsi, qword ptr [rbp - 8]',\n",
       " 'mov rdx, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xb878',\n",
       " 'mov edx, 1',\n",
       " 'mov esi, 7',\n",
       " 'mov edi, 1',\n",
       " 'call 0x759a',\n",
       " 'mov rax, qword ptr [rip + 0xd81b]',\n",
       " 'mov edx, 0',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov edx, dword ptr [rip + 0xd8c3]',\n",
       " 'mov rcx, qword ptr [rip + 0xd7cc]',\n",
       " 'mov rax, qword ptr [rip + 0xd7f5]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'mov eax, 0',\n",
       " 'call 0x75d0',\n",
       " 'mov eax, 0',\n",
       " 'call 0x6ac8',\n",
       " 'mov edi, 1',\n",
       " 'call 0x39d0',\n",
       " 'jmp 0x40e0',\n",
       " 'mov eax, 0',\n",
       " 'call 0x75d0',\n",
       " 'mov edi, 0',\n",
       " 'mov eax, 0',\n",
       " 'call 0x3cf2',\n",
       " 'mov edi, 0xffffffff',\n",
       " 'mov eax, 0',\n",
       " 'call 0x3e60',\n",
       " 'mov eax, 0',\n",
       " 'call 0x6ac8',\n",
       " 'nop ',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x10',\n",
       " 'mov dword ptr [rbp - 4], 0',\n",
       " 'jmp 0x415c',\n",
       " 'mov rdx, qword ptr [rip + 0xd739]',\n",
       " 'mov eax, dword ptr [rbp - 4]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xb878',\n",
       " 'mov rdx, qword ptr [rip + 0xd71b]',\n",
       " 'mov eax, dword ptr [rbp - 4]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov qword ptr [rax], 0',\n",
       " 'add dword ptr [rbp - 4], 1',\n",
       " 'mov eax, dword ptr [rip + 0xceaa]',\n",
       " 'cmp dword ptr [rbp - 4], eax',\n",
       " 'jl 0x4120',\n",
       " 'nop ',\n",
       " 'nop ',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x30',\n",
       " 'mov qword ptr [rbp - 0x28], rdi',\n",
       " 'mov qword ptr [rbp - 0x30], rsi',\n",
       " 'mov rdx, qword ptr [rbp - 0x28]',\n",
       " 'mov rax, qword ptr [rbp - 0x30]',\n",
       " 'mov esi, 0x7ff',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x37a0',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'cmp qword ptr [rbp - 0x10], 0',\n",
       " 'jne 0x41a6',\n",
       " 'mov eax, 0',\n",
       " 'jmp 0x41fc',\n",
       " 'mov rax, qword ptr [rbp - 0x30]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'sub rax, 1',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov rdx, qword ptr [rbp - 0x30]',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'cmp al, 0xa',\n",
       " 'jne 0x41dc',\n",
       " 'mov rdx, qword ptr [rbp - 0x30]',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0',\n",
       " 'jmp 0x41f8',\n",
       " 'nop ',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3740',\n",
       " 'mov dword ptr [rbp - 0x14], eax',\n",
       " 'cmp dword ptr [rbp - 0x14], 0xa',\n",
       " 'je 0x41f8',\n",
       " 'cmp dword ptr [rbp - 0x14], -1',\n",
       " 'jne 0x41dd',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov qword ptr [rbp - 0x18], rdi',\n",
       " 'lea rax, [rip + 0xce2b]',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rip + 0xce1c]',\n",
       " 'mov rsi, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x416b',\n",
       " 'test rax, rax',\n",
       " 'jne 0x4243',\n",
       " 'mov eax, 0xffffffff',\n",
       " 'jmp 0x42f8',\n",
       " 'lea rax, [rip + 0x7e98]',\n",
       " 'mov rsi, rax',\n",
       " 'lea rax, [rip + 0xcdec]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x39f0',\n",
       " 'test rax, rax',\n",
       " 'jne 0x426b',\n",
       " 'mov eax, 0xffffffff',\n",
       " 'jmp 0x42f8',\n",
       " 'mov dword ptr [rbp - 0xc], 0',\n",
       " 'jmp 0x4279',\n",
       " 'add qword ptr [rbp - 8], 1',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'jne 0x4274',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov edx, 3',\n",
       " 'lea rcx, [rip + 0x7e31]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3790',\n",
       " 'test eax, eax',\n",
       " 'jne 0x42ca',\n",
       " 'mov eax, dword ptr [rbp - 0xc]',\n",
       " 'jmp 0x42f8',\n",
       " 'add qword ptr [rbp - 8], 1',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'je 0x42c5',\n",
       " 'add dword ptr [rbp - 0xc], 1',\n",
       " 'jmp 0x4279',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'push rbx',\n",
       " 'sub rsp, 0xb8',\n",
       " 'mov dword ptr [rbp - 0xb4], edi',\n",
       " 'mov rax, qword ptr fs:[0x28]',\n",
       " 'mov qword ptr [rbp - 0x18], rax',\n",
       " 'xor eax, eax',\n",
       " 'mov rdx, qword ptr [rip + 0xd53a]',\n",
       " 'mov eax, dword ptr [rbp - 0xb4]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'mov qword ptr [rbp - 0xa8], rax',\n",
       " 'mov dword ptr [rbp - 0xb0], 0',\n",
       " 'jmp 0x43ba',\n",
       " 'add qword ptr [rbp - 0xa8], 1',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 0xa8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'jne 0x434b',\n",
       " 'jmp 0x4388',\n",
       " 'add qword ptr [rbp - 0xa8], 1',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 0xa8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'je 0x4380',\n",
       " 'add dword ptr [rbp - 0xb0], 1',\n",
       " 'mov eax, dword ptr [rip + 0xcc50]',\n",
       " 'cmp dword ptr [rbp - 0xb0], eax',\n",
       " 'jl 0x4353',\n",
       " 'mov dword ptr [rbp - 0xb0], 0',\n",
       " 'jmp 0x43dc',\n",
       " 'add qword ptr [rbp - 0xa8], 1',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 0xa8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'jne 0x43d4',\n",
       " 'jmp 0x4437',\n",
       " 'mov rax, qword ptr [rbp - 0xa8]',\n",
       " 'lea rdx, [rax + 1]',\n",
       " 'mov qword ptr [rbp - 0xa8], rdx',\n",
       " 'mov edx, dword ptr [rbp - 0xb0]',\n",
       " 'lea ecx, [rdx + 1]',\n",
       " 'mov dword ptr [rbp - 0xb0], ecx',\n",
       " 'movzx ecx, byte ptr [rax]',\n",
       " 'movsxd rax, edx',\n",
       " 'mov byte ptr [rbp + rax - 0xa0], cl',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 0xa8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'je 0x4409',\n",
       " 'mov eax, dword ptr [rbp - 0xb0]',\n",
       " 'cdqe ',\n",
       " 'mov byte ptr [rbp + rax - 0xa0], 0',\n",
       " 'lea rax, [rbp - 0xa0]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3960',\n",
       " 'mov dword ptr [rbp - 0xac], eax',\n",
       " 'cmp dword ptr [rbp - 0xac], 0',\n",
       " 'je 0x44cb',\n",
       " 'mov eax, dword ptr [rip + 0xd422]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 4',\n",
       " 'mov rdx, rax',\n",
       " 'lea rax, [rip + 0xbca6]',\n",
       " 'mov ebx, dword ptr [rdx + rax]',\n",
       " 'lea rax, [rbp - 0xa0]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3960',\n",
       " 'mov esi, ebx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x3830',\n",
       " 'test eax, eax',\n",
       " 'sete al',\n",
       " 'movzx eax, al',\n",
       " 'jmp 0x44d0',\n",
       " 'mov eax, 0xffffffff',\n",
       " 'mov rdx, qword ptr [rbp - 0x18]',\n",
       " 'sub rdx, qword ptr fs:[0x28]',\n",
       " 'je 0x44e4',\n",
       " 'call 0x3680',\n",
       " 'mov rbx, qword ptr [rbp - 8]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'push rbx',\n",
       " 'sub rsp, 0x838',\n",
       " 'mov qword ptr [rbp - 0x838], rdi',\n",
       " 'mov rax, qword ptr fs:[0x28]',\n",
       " 'mov qword ptr [rbp - 0x18], rax',\n",
       " 'xor eax, eax',\n",
       " 'mov dword ptr [rbp - 0x824], 0',\n",
       " 'jmp 0x4578',\n",
       " 'mov eax, dword ptr [rbp - 0x824]',\n",
       " 'add eax, 1',\n",
       " 'cdqe ',\n",
       " 'lea rdx, [rax*8]',\n",
       " 'mov rax, qword ptr [rip + 0xd32a]',\n",
       " 'mov rsi, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xba20',\n",
       " 'mov qword ptr [rip + 0xd318], rax',\n",
       " 'mov rdx, qword ptr [rip + 0xd311]',\n",
       " 'mov eax, dword ptr [rbp - 0x824]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'lea rbx, [rdx + rax]',\n",
       " 'lea rax, [rbp - 0x820]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xbb30',\n",
       " 'mov qword ptr [rbx], rax',\n",
       " 'add dword ptr [rbp - 0x824], 1',\n",
       " 'lea rdx, [rbp - 0x820]',\n",
       " 'mov rax, qword ptr [rbp - 0x838]',\n",
       " 'mov rsi, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x416b',\n",
       " 'test rax, rax',\n",
       " 'jne 0x451c',\n",
       " 'mov eax, dword ptr [rbp - 0x824]',\n",
       " 'mov dword ptr [rip + 0xca65], eax',\n",
       " 'nop ',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'sub rax, qword ptr fs:[0x28]',\n",
       " 'je 0x45bc',\n",
       " 'call 0x3680',\n",
       " 'mov rbx, qword ptr [rbp - 8]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'push rbx',\n",
       " 'sub rsp, 0x28',\n",
       " 'mov dword ptr [rbp - 0x24], edi',\n",
       " 'mov dword ptr [rbp - 0x28], esi',\n",
       " 'mov rdx, qword ptr [rip + 0xd284]',\n",
       " 'mov eax, dword ptr [rbp - 0x24]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov dword ptr [rbp - 0x18], eax',\n",
       " 'mov eax, dword ptr [rip + 0xd364]',\n",
       " 'sub eax, 2',\n",
       " 'mov dword ptr [rbp - 0x14], eax',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'cmp eax, dword ptr [rbp - 0x18]',\n",
       " 'jl 0x4613',\n",
       " 'mov dword ptr [rbp - 0x1c], 0',\n",
       " 'jmp 0x4629',\n",
       " 'mov eax, dword ptr [rbp - 0x18]',\n",
       " 'sub eax, dword ptr [rbp - 0x14]',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rip + 0xd263]',\n",
       " 'cmp edx, eax',\n",
       " 'cmovle eax, edx',\n",
       " 'mov dword ptr [rbp - 0x1c], eax',\n",
       " 'mov eax, dword ptr [rip + 0xd331]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xd237]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3700',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'movsxd rbx, eax',\n",
       " 'mov rdx, qword ptr [rip + 0xd20d]',\n",
       " 'mov eax, dword ptr [rbp - 0x24]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov eax, dword ptr [rbp - 0x1c]',\n",
       " 'cdqe ',\n",
       " 'add rax, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cmp rbx, rax',\n",
       " 'ja 0x467e',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'cdqe ',\n",
       " 'jmp 0x46a4',\n",
       " 'mov rdx, qword ptr [rip + 0xd1db]',\n",
       " 'mov eax, dword ptr [rbp - 0x24]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov eax, dword ptr [rbp - 0x1c]',\n",
       " 'cdqe ',\n",
       " 'add rax, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov rcx, qword ptr [rip + 0xd1b5]',\n",
       " 'mov edx, dword ptr [rbp - 0x24]',\n",
       " 'movsxd rdx, edx',\n",
       " 'shl rdx, 3',\n",
       " 'add rdx, rcx',\n",
       " 'mov rcx, qword ptr [rdx]',\n",
       " 'mov edx, dword ptr [rbp - 0x1c]',\n",
       " 'movsxd rdx, edx',\n",
       " 'lea rsi, [rcx + rdx]',\n",
       " 'mov rdx, qword ptr [rip + 0xd1a4]',\n",
       " 'lea rcx, [rdx + 2]',\n",
       " 'mov rdx, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'mov eax, dword ptr [rip + 0xd19b]',\n",
       " 'cmp dword ptr [rbp - 0x24], eax',\n",
       " 'jne 0x46ed',\n",
       " 'mov edx, 0x3e',\n",
       " 'jmp 0x46f2',\n",
       " 'mov edx, 0x20',\n",
       " 'mov rax, qword ptr [rip + 0xd177]',\n",
       " 'mov byte ptr [rax], dl',\n",
       " 'mov rax, qword ptr [rip + 0xd16e]',\n",
       " 'add rax, 1',\n",
       " 'mov byte ptr [rax], 0x20',\n",
       " 'cmp dword ptr [rbp - 0x28], 0',\n",
       " 'je 0x475d',\n",
       " 'mov eax, dword ptr [rip + 0xb98b]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x7547',\n",
       " 'mov eax, dword ptr [rip + 0xd15a]',\n",
       " 'cmp dword ptr [rbp - 0x24], eax',\n",
       " 'jne 0x4743',\n",
       " 'mov eax, dword ptr [rip + 0xb96f]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x74f4',\n",
       " 'mov eax, dword ptr [rip + 0xb95e]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x751c',\n",
       " 'jmp 0x475d',\n",
       " 'mov eax, dword ptr [rip + 0xb94f]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x74f4',\n",
       " 'mov eax, dword ptr [rip + 0xb946]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x751c',\n",
       " 'mov edx, dword ptr [rip + 0xd115]',\n",
       " 'mov eax, dword ptr [rbp - 0x24]',\n",
       " 'sub eax, edx',\n",
       " 'mov ecx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xd127]',\n",
       " 'mov edx, 0',\n",
       " 'mov esi, ecx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov edx, dword ptr [rip + 0xd1da]',\n",
       " 'mov rcx, qword ptr [rip + 0xd0e3]',\n",
       " 'mov rax, qword ptr [rip + 0xd104]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'mov eax, dword ptr [rip + 0xd1bb]',\n",
       " 'lea edx, [rax - 1]',\n",
       " 'mov rax, qword ptr [rip + 0xd0f1]',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we create our 50/50 NIP training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10221\n",
      "['endbr64 ', 'push rbp', 'mov rbp, rsp', 'mov rdx, qword ptr [rip + 0x2d98]', 'mov rax, qword ptr [rip + 0x2d81]']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "history = []\n",
    "next_instruction = []\n",
    "label = []\n",
    "\n",
    "page_len = 5\n",
    "instruction_pages = []\n",
    "for instruction_cluster in text:\n",
    "    instructions = [\n",
    "        instruction for instruction in instruction_cluster.split(delim) if instruction != ''\n",
    "    ]\n",
    "    if len(instructions)>page_len:\n",
    "        \n",
    "        for i in range(0,len(instructions),page_len):\n",
    "            instruction_pages.append(instructions[i:i+page_len])\n",
    "        \n",
    "print(len(instruction_pages))\n",
    "print(instruction_pages[0])\n",
    "\n",
    "for instruction_page in instruction_pages:\n",
    "    \n",
    "#     instructions = [\n",
    "#         instruction for instruction in instruction_page.split(';') if instruction != ''\n",
    "#     ]\n",
    "    \n",
    "    \n",
    "#     num_instructions = len(instruction_page)\n",
    "    \n",
    "    \n",
    "\n",
    "#     start = random.randint(0, num_instructions-2)\n",
    "    # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "    if random.random() >= 0.5:\n",
    "        # this is IsNextSentence\n",
    "        history.append(delim.join(instruction_page[:-1]))\n",
    "        next_instruction.append(instruction_page[-1])\n",
    "        label.append(0)\n",
    "    else:\n",
    "        index = random.randint(0, bag_size-1)\n",
    "        # this is NotNextSentence\n",
    "        history.append(delim.join(instruction_page[:-1]))\n",
    "        next_instruction.append(bag[index])\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10221\n",
      "1\n",
      "-> endbr64 ;push rbp;mov rbp, rsp;mov rdx, qword ptr [rip + 0x2d98] \n",
      "\n",
      "#  call 0xe319 \n",
      "\n",
      "0\n",
      "-> lea rcx, [rip + 0xd62];mov rsi, rcx;mov rdi, rax;mov eax, 0 \n",
      "\n",
      "#  call 0x1120 \n",
      "\n",
      "0\n",
      "-> mov edi, 1 \n",
      "\n",
      "#  call 0x1170 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(label))\n",
    "for i in range(3):\n",
    "    print(label[i])\n",
    "    print('->',history[i] , '\\n')\n",
    "    print('# ',next_instruction[i] , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready for tokenization, this time we truncate/pad each token to the same length of *512* tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(history, next_instruction, return_tensors='pt', \n",
    "                   max_length=64, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the *token_type_ids* tensors have been built correctly (eg **1** indicating sentence B tokens) by checking the first instance of *token_type_ids*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.token_type_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **0** tokens following our sentence B tokens correspond to *PAD* tokens.\n",
    "\n",
    "Alongside this, we need to create a *labels* tensor too - which corresponds to the values contained within our `label` variable. Our *labels* tensor must be a *LongTensor*, and we will need to transpose the tensor so that it matches our other tensors' dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the labels tensor is simply a clone of the input_ids tensor before masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2, 180,   1, 162,  94,   1,  86,  94,   9, 122,   1,  86, 101,   9,\n",
       "         95,  89,  22, 107,   8, 469, 255,  23,   3, 104, 755,   3,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we mask tokens in the input_ids tensor using the 15% probability for MLM - ensuring we don't mask CLS, SEP, or PAD tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True, False, False, False, False,  True, False, False, False,\n",
       "        False, False, False, False, False, False,  True, False,  True,  True,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr[0]\n",
    "# inputs.input_ids.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now take the indices of each True value within each vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6, 16, 18, 19]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then apply these indices to each row in input_ids, assigning each value at these indices a value of 103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inputs` tensors are now ready, and we can begin building the model input pipeline for training. We first create a PyTorch dataset from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize our data using the `MeditationDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeditationsDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "validation_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And initialize the dataloader, which we'll be using to load our data into the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto setting up the training loop. First we setup GPU/CPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the training mode of our model, and initialize our optimizer (Adam with weighted decay - reduces chance of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto the training loop, we'll train for a couple of epochs (change `epochs` to modify this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odict_keys(['loss', 'prediction_logits', 'seq_relationship_logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|███████████████████| 1022/1022 [02:44<00:00,  6.21it/s, loss=3.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.5100293542074364 0.5079513564078578 0.5331369661266568 0.5202395209580838 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 1:  96%|███████████████████▏| 978/1022 [02:35<00:07,  6.02it/s, loss=2.52]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 30522]) tensor([[[ 8.2182e+00,  8.3281e+00,  8.6531e+00,  ..., -1.8650e+00,\n",
      "          -8.1123e-01, -3.0827e+00],\n",
      "         [ 7.1044e+00,  8.3823e+00,  6.9689e+00,  ..., -1.7266e+00,\n",
      "           1.2043e-01, -3.9926e+00],\n",
      "         [ 2.9552e+00,  4.2867e+00,  3.3036e+00,  ..., -5.6875e+00,\n",
      "          -4.5578e+00, -7.1035e+00],\n",
      "         ...,\n",
      "         [ 1.5857e+01,  8.5598e+00,  8.4537e+00,  ...,  1.7169e+00,\n",
      "           2.3162e+00, -1.2559e+00],\n",
      "         [ 1.6430e+01,  9.4550e+00,  9.5399e+00,  ...,  1.3539e+00,\n",
      "           2.2787e+00,  4.2687e-01],\n",
      "         [ 1.4751e+01,  7.7021e+00,  7.6795e+00,  ..., -1.7905e-01,\n",
      "           1.0883e+00, -1.9829e+00]],\n",
      "\n",
      "        [[ 1.0502e+01,  1.0775e+01,  1.0563e+01,  ...,  3.5160e-01,\n",
      "           3.5340e-01, -1.1113e+00],\n",
      "         [ 1.1889e+01,  1.3569e+01,  1.1991e+01,  ...,  2.7444e+00,\n",
      "           1.7586e+00,  6.1909e-01],\n",
      "         [ 1.4836e+01,  1.6090e+01,  1.4027e+01,  ...,  3.9560e+00,\n",
      "           3.3064e+00,  2.2776e+00],\n",
      "         ...,\n",
      "         [ 1.7840e+01,  1.1025e+01,  1.0753e+01,  ...,  2.9854e+00,\n",
      "           3.0605e+00,  1.1008e+00],\n",
      "         [ 1.7669e+01,  1.1135e+01,  1.1003e+01,  ...,  3.6644e+00,\n",
      "           4.1202e+00,  8.5491e-01],\n",
      "         [ 1.9242e+01,  1.3112e+01,  1.2652e+01,  ...,  4.5115e+00,\n",
      "           4.2047e+00,  1.9154e+00]],\n",
      "\n",
      "        [[ 9.6515e+00,  6.3862e+00,  6.7445e+00,  ..., -2.7921e+00,\n",
      "          -2.4787e+00, -4.1479e+00],\n",
      "         [ 1.2270e+01,  1.3930e+01,  1.2335e+01,  ...,  2.6397e+00,\n",
      "           1.4790e+00,  1.9475e+00],\n",
      "         [ 1.1780e+01,  1.3579e+01,  1.1718e+01,  ...,  2.1667e+00,\n",
      "           8.2421e-01,  2.0487e-01],\n",
      "         ...,\n",
      "         [ 1.5259e+01,  8.1125e+00,  8.4761e+00,  ...,  8.9727e-01,\n",
      "           8.3945e-01, -1.2856e+00],\n",
      "         [ 1.5354e+01,  8.1274e+00,  8.3604e+00,  ...,  4.3282e-01,\n",
      "           8.9196e-02, -7.3308e-01],\n",
      "         [ 1.5865e+01,  8.9801e+00,  8.9370e+00,  ...,  1.9528e+00,\n",
      "           1.9578e+00, -8.2710e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.1892e+00,  6.6828e+00,  7.1785e+00,  ..., -3.4707e+00,\n",
      "          -3.0981e+00, -4.8738e+00],\n",
      "         [ 1.2163e+01,  1.4670e+01,  1.2443e+01,  ...,  2.9846e+00,\n",
      "           1.7703e+00,  2.6724e-01],\n",
      "         [ 7.8660e+00,  1.1691e+01,  9.4363e+00,  ...,  6.3306e-01,\n",
      "          -7.4702e-01, -2.6577e-01],\n",
      "         ...,\n",
      "         [ 1.5867e+01,  8.9318e+00,  9.1375e+00,  ..., -1.3774e-02,\n",
      "           6.4586e-01, -1.6177e+00],\n",
      "         [ 1.5780e+01,  9.0651e+00,  9.4073e+00,  ...,  9.3638e-01,\n",
      "           1.0453e+00, -1.1821e+00],\n",
      "         [ 1.5686e+01,  8.8125e+00,  8.9378e+00,  ...,  6.9136e-01,\n",
      "           1.6856e+00, -1.4365e+00]],\n",
      "\n",
      "        [[ 8.0188e+00,  6.0680e+00,  6.7955e+00,  ..., -1.5465e+00,\n",
      "          -2.8942e+00, -4.7237e+00],\n",
      "         [ 1.1562e+01,  1.3271e+01,  1.1423e+01,  ...,  2.7722e+00,\n",
      "           1.6199e+00,  2.1488e+00],\n",
      "         [ 9.7801e+00,  1.2636e+01,  1.0184e+01,  ...,  2.0217e+00,\n",
      "           8.5390e-01,  1.1753e+00],\n",
      "         ...,\n",
      "         [ 1.5144e+01,  7.2416e+00,  7.6030e+00,  ...,  1.9126e+00,\n",
      "           1.2842e+00,  2.6606e-01],\n",
      "         [ 1.5465e+01,  7.6616e+00,  7.9439e+00,  ...,  3.0488e+00,\n",
      "           1.3161e+00, -5.5387e-01],\n",
      "         [ 1.5591e+01,  7.8884e+00,  8.1342e+00,  ...,  2.7884e+00,\n",
      "           1.6829e+00, -3.5649e-01]],\n",
      "\n",
      "        [[ 8.1939e+00,  7.3625e+00,  7.5746e+00,  ..., -2.7300e+00,\n",
      "          -2.2141e+00, -3.9471e+00],\n",
      "         [ 1.3656e+01,  1.4950e+01,  1.3029e+01,  ...,  3.0949e+00,\n",
      "           2.8887e+00,  1.4157e+00],\n",
      "         [ 9.5608e+00,  1.2293e+01,  1.0077e+01,  ...,  8.5961e-01,\n",
      "           6.4885e-01, -8.3968e-01],\n",
      "         ...,\n",
      "         [ 1.5279e+01,  8.2622e+00,  8.4131e+00,  ...,  7.8839e-01,\n",
      "           1.0657e+00, -1.2171e+00],\n",
      "         [ 1.7111e+01,  1.0192e+01,  1.0087e+01,  ...,  1.4701e+00,\n",
      "           2.1765e+00,  4.3021e-01],\n",
      "         [ 1.6078e+01,  8.9370e+00,  9.3464e+00,  ...,  5.7596e-01,\n",
      "           1.6054e+00, -9.9951e-02]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[ 101,   86, 2034,    1,    9,    1,    1,  100,   89,    9,    9,    1,\n",
      "            1,    1,    1,    9,    9,    9,    9,    9,    9,    9,    1,    3,\n",
      "            3,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   9,    9,    1,    9,    1,    1,    1,    1, 1284,    1,    1,    1,\n",
      "            1,    9,    9,    9,    9,    9, 1285,    3,    3,    9,    9,    9,\n",
      "            9,    9,    3,    9,    9,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   0,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    0,    9,    9,    9,    9,    9,    9,   23,   23,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [ 101,    9,  101,    9,    9,    9,    9,    9,    9,    9,    9,    1,\n",
      "            9,    9,  101,    9,    9,    9,    1,    9,    9,    9,    9,    9,\n",
      "            9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    0,    9,\n",
      "            9,    9,  101,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [ 101,    9,    9,    9,    9,    9,  101,    9,    9,    9,    9,    9,\n",
      "            9,    1,    9,    9,    9,    9,    1,    1,    9,    9,  100,    1,\n",
      "            9,    9,    9,    9,    9,    9,    9,    9,    0,    9,    9,    9,\n",
      "            9,    9,    9,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [ 101,    9,    1,    9,    1,    9,    9,    1,    1,    9,    9,    9,\n",
      "            1,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,\n",
      "            9,    9,  100,    9,    9,    9,    9,    9,    9,    9,    9,  101,\n",
      "            9,    9,    3,    9,    9,    9,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [ 101,    9,    1,    1,    1,    1,    1, 2047,    1,    1,    1, 1288,\n",
      "            1,    1,    1,    9,  100,    1,    1,    0, 2047, 1999, 2735,    9,\n",
      "            0,    9,    9,    9,    3,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   0,    9,    1,    9,    9,    9,    1,    9,    9,    9,    9,    9,\n",
      "            9,    9,    3,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n",
      "['rdx mov 0x22d05 [UNK], [UNK] [UNK] dword ptr,, [UNK] [UNK] [UNK] [UNK],,,,,,, [UNK] [SEP] [SEP],,,,,,,,,,, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', ',, [UNK], [UNK] [UNK] [UNK] [UNK]b1 [UNK] [UNK] [UNK] [UNK],,,,,b2 [SEP] [SEP],,,,, [SEP],, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[PAD] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [PAD],,,,,, ] ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'rdx, rdx,,,,,,,, [UNK],, rdx,,, [UNK],,,,,,,,,,,,,,, [PAD],,, rdx [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'rdx,,,,, rdx,,,,,, [UNK],,,, [UNK] [UNK],, dword [UNK],,,,,,,, [PAD],,,,,, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'rdx, [UNK], [UNK],, [UNK] [UNK],,, [UNK],,,,,,,,,,,,, dword,,,,,,,, rdx,, [SEP],,, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'rdx, [UNK] [UNK] [UNK] [UNK] [UNK] 0x49d0 [UNK] [UNK] [UNK]c1 [UNK] [UNK] [UNK], dword [UNK] [UNK] [PAD] 0x49d0 0x14bb8d, [PAD],,, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[PAD], [UNK],,, [UNK],,,,,,, [SEP] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "torch.Size([8, 64]) tensor([[   2,  119, 2034,    1,   86,  120,    9,  100,   89,   22,   94,   10,\n",
      "          134,   23,    1,   86,   96,    9,  120,    1,  159,   96,    9,   13,\n",
      "            3,   86,   87,    9,   95,   89,   22,  107,    8,  870, 1517,   23,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  133,   87,    9,   87,    1,  139,  167, 1284,   63,    1,  133,\n",
      "          189,    9,  189,    1,  139,  167, 1285,   52,    3,  116,   87,    9,\n",
      "           22,  107,    8, 3211,   23,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  180,    1,  162,   94,    1,   86,   94,    9,  122,    1,  149,\n",
      "          122,    9,  127,    3,   86,   87,    9,   95,   89,   22,   87,   23,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  116,  101,    9,   22,   87,    8,   13,   23,    1,   86,  129,\n",
      "           89,   22,  101,   23,    9,  134,    1,   86,   87,    9,   95,   89,\n",
      "           22,   94,   10,  134,   23,    1,  115,   87,    9,   12,    3,  115,\n",
      "           87,    9,  101,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  104,  915,  244,    1,   86,  101,    9,   95,   89,   22,   87,\n",
      "           23,    1,   86,   87,    9,   95,   89,   22,   94,   10, 1128,   23,\n",
      "            1,  153,   96,    9,  129,   89,   22,   87,   23,    3,   86,  229,\n",
      "            9,  174,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  117,    9,   95,   89,   22,   87,    8,  146,   23,    1,\n",
      "           86,   87,    9,   95,   89,   22,   94,   10,  281,   23,    1,   86,\n",
      "           96,    9,  100,   89,   22,   87,    8,  135,   23,    1,  154,  101,\n",
      "            9,   96,    3,  104,  875,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   96,    9,   11,    1,  104, 2047,    1,  119,  211, 1288,\n",
      "            1,   86,   96,    9,  100,   89,   22,  107,    8, 1322, 2735,   23,\n",
      "            3,   86,  164,    9,  163,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   96,    9,   11,    1,  104,  659,  330,    1,  165,    1,\n",
      "          200,   94,    3,  183,    3,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████| 1022/1022 [02:42<00:00,  6.27it/s, loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.5204256360078278 0.5182534001431639 0.5331369661266568 0.525589836660617 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 2: 100%|███████████████████| 1022/1022 [02:45<00:00,  6.18it/s, loss=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.5299657534246576 0.5270808909730363 0.551791850760923 0.539153375704521 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 3:  91%|███████████████████▏ | 934/1022 [02:27<00:14,  5.98it/s, loss=1.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 30522]) tensor([[[ 4.8569,  3.0642,  8.4831,  ..., -4.2121, -4.6648, -5.0275],\n",
      "         [ 9.7800,  9.8827,  9.9903,  ...,  1.0099, -0.2144, -4.0216],\n",
      "         [ 5.3497,  8.5034,  7.5117,  ..., -2.1596, -1.1514, -6.4077],\n",
      "         ...,\n",
      "         [16.8085,  7.3693,  8.0538,  ...,  0.1898, -0.7422,  1.1627],\n",
      "         [16.6647,  6.4952,  8.0178,  ...,  0.8615, -0.0357, -0.6246],\n",
      "         [18.3609,  8.9514,  9.6482,  ...,  1.0330,  0.5950, -0.6513]],\n",
      "\n",
      "        [[ 6.1671,  6.3186, 10.5674,  ..., -3.3194, -3.6099, -3.7328],\n",
      "         [ 8.6013,  8.6139,  8.2121,  ..., -0.5204, -1.6258, -2.3219],\n",
      "         [ 3.4770,  3.3306,  4.3195,  ..., -1.3236, -3.0779, -5.6692],\n",
      "         ...,\n",
      "         [16.2036,  7.2324,  7.9815,  ..., -0.2070, -0.8587, -2.5573],\n",
      "         [16.1823,  6.9145,  7.9099,  ..., -0.2690, -1.0871, -2.1080],\n",
      "         [17.1722,  8.5498,  8.7344,  ...,  0.3369, -0.3548, -2.0142]],\n",
      "\n",
      "        [[ 4.4646,  4.2612,  9.1370,  ..., -3.9766, -3.8175, -4.8614],\n",
      "         [ 8.3902,  9.4574,  8.4137,  ...,  0.7143, -1.9812,  0.0530],\n",
      "         [ 8.8044, 10.7137,  9.7918,  ...,  2.4843,  0.3533,  0.2466],\n",
      "         ...,\n",
      "         [17.7453,  9.0142,  8.8533,  ...,  0.6477, -0.2150, -0.9744],\n",
      "         [17.9966,  8.4112,  9.4904,  ...,  0.7288, -0.1488, -0.8990],\n",
      "         [17.8751,  9.3322,  8.9670,  ...,  1.4426,  1.0848, -1.4581]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.6020,  6.3154, 10.8403,  ..., -3.6045, -3.0512, -2.9219],\n",
      "         [ 8.4923, 10.4137,  9.6221,  ...,  2.4188, -0.0357,  0.4587],\n",
      "         [ 8.2500,  7.8188,  6.6913,  ...,  0.4960, -0.0718, -5.3230],\n",
      "         ...,\n",
      "         [16.2702,  6.1752,  7.8575,  ..., -1.6697, -1.0220, -0.8998],\n",
      "         [17.4455,  8.1094,  9.2635,  ...,  0.1532,  0.2157, -0.8840],\n",
      "         [17.2268,  7.7346,  8.6012,  ...,  0.1502, -0.6300, -0.4391]],\n",
      "\n",
      "        [[ 5.5575,  4.2739,  9.7104,  ..., -4.3670, -4.0125, -6.0764],\n",
      "         [ 7.2524,  9.1032,  7.9240,  ...,  1.2665, -1.6392, -0.7758],\n",
      "         [ 9.0033,  7.9663,  7.7369,  ...,  0.8603, -0.4783, -2.4101],\n",
      "         ...,\n",
      "         [17.6549,  7.9421,  8.8398,  ...,  0.8183,  0.5038, -1.6011],\n",
      "         [17.3917,  7.8492,  8.6796,  ...,  0.4049, -0.4155, -0.5810],\n",
      "         [17.9481,  8.3115,  9.0427,  ...,  0.4565,  0.5320, -0.5646]],\n",
      "\n",
      "        [[ 8.3844,  7.5660, 12.4513,  ..., -1.4979, -1.6329, -3.1932],\n",
      "         [12.1152, 15.3984, 12.6425,  ...,  4.1624,  1.8320,  2.1036],\n",
      "         [11.8635, 14.4507, 12.8268,  ...,  5.8464,  2.4336,  2.3303],\n",
      "         ...,\n",
      "         [18.3585,  9.4376,  9.6349,  ...,  1.3786,  1.0767, -0.5872],\n",
      "         [18.4311, 10.3139,  9.6790,  ...,  1.9335,  0.7542, -0.4823],\n",
      "         [18.0470,  8.9850,  9.3636,  ...,  0.3665,  0.3306, -1.4163]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([[  101,    86,    96,     1,   104,    96,     9,    96,     1,    86,\n",
      "            96,     9,    96,     1,    86,   101,     9,   104,     3,    86,\n",
      "            96,     9,   100,    89,    22,    87,    23,     3,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,    86,   100,    89,    22,    87,    23,     9,     9,     1,\n",
      "            86,    96,     9,   100,    89,    22,   107,     8,     8,     8,\n",
      "            23,     1,    86,   100,    89,    22,    94,    10,    23,    23,\n",
      "             9,    96,     1,     1, 23464,     3,     3,   104,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,    86,    87,     9,    95,    89,    22,     8,     8,  5562,\n",
      "            23,     1,    86,    87,     9,    95,    89,    22,    87,     8,\n",
      "             8,    23,     1,    86,    87,     9,   101,     1,    86,    87,\n",
      "             9,    87,     3,   104,     9,   104,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,    96,     1,     1,   104,     1,     1,     1,     1,     3,\n",
      "             3,    86,    96,     9,     9,    89,    22,    94,    10,    10,\n",
      "            23,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,    86,   100,    89,    22,    94,    10,    10,    23,     9,\n",
      "            11,     1,   104,  5530,     1,    86,    96,     9,   100,    89,\n",
      "            22,    94,    10,    10,    23,     1,   116,    96,     9,    22,\n",
      "            87,    10,     9,     9,     3,    86,   100,    89,    22,    94,\n",
      "            10,    10,    23,     9,     3,     3,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,   116,    87,     9,    22,    94,    94,    23,    23,     1,\n",
      "            86,     1,     9,    87,     1,     1,  1295,    87,     1,    86,\n",
      "           101,     9,    95,    89,    22,    94,    10,    23,    23,     3,\n",
      "            86,    87,     9,    87,     3,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,    86,    87,     9,    95,    89,    22,    94,    10,    23,\n",
      "            23,     1,    86,    96,     9,    95,    89,    22,    87,     8,\n",
      "             8,    23,     1,    86,    96,     9,   100,    89,    22,    94,\n",
      "            10,    10,    23,     1,    86,   101,     9,    96,     3,    86,\n",
      "            87,     9,   101,     3,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,    86,   104,     9,    96,     1,   104,     1,   104,     1,\n",
      "            86,    96,     9,   100,    89,    22,   107,     8,     8,     8,\n",
      "            23,     1,    86,    96,     9,    96,     3,    86,    87,     9,\n",
      "            87,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]], device='cuda:0')\n",
      "['rdx mov eax [UNK] call eax, eax [UNK] mov eax, eax [UNK] mov rdx, call [SEP] mov eax, dword ptr [ rax ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov dword ptr [ rax ],, [UNK] mov eax, dword ptr [ rip + + + ] [UNK] mov dword ptr [ rbp - ] ], eax [UNK] [UNK] [UNK] [SEP] [SEP] call [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'rdx mov rax, qword ptr [ + + 0x225cc ] [UNK] mov rax, qword ptr [ rax + + ] [UNK] mov rax, rdx [UNK] mov rax, rax [SEP] call, call [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] eax [UNK] [UNK] call [UNK] [UNK] [UNK] [UNK] [SEP] [SEP] mov eax,, ptr [ rbp - - ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov dword ptr [ rbp - - ], 0 [UNK] call 0x20e00 [UNK] mov eax, dword ptr [ rbp - - ] [UNK] lea eax, [ rax -,, [SEP] mov dword ptr [ rbp - - ], [SEP] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] lea rax, [ rbp rbp ] ] [UNK] mov [UNK], rax [UNK] [UNK] 0x35 rax [UNK] mov rdx, qword ptr [ rbp - ] ] [SEP] mov rax, rax [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rax, qword ptr [ rbp - ] ] [UNK] mov eax, qword ptr [ rax + + ] [UNK] mov eax, dword ptr [ rbp - - ] [UNK] mov rdx, eax [SEP] mov rax, rdx [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov call, eax [UNK] call [UNK] call [UNK] mov eax, dword ptr [ rip + + + ] [UNK] mov eax, eax [SEP] mov rax, rax [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "torch.Size([8, 64]) tensor([[   2,  104,  450,    1,  133,  151,    9,  151,    1,   86,  117,    9,\n",
      "          259,    1,   86,  101,    9,  260,    3,   86,  249,    9,  100,   89,\n",
      "           22,   87,   23,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  100,   89,   22,   87,   23,    9,  120,    1,   86,   96,\n",
      "            9,  100,   89,   22,  107,    8,  367,  361,   23,    1,  118,  100,\n",
      "           89,   22,   94,   10,  127,   23,    9,   96,    1,  512,  734,  316,\n",
      "            3,  209,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,  107,    8, 5562,   23,    1,\n",
      "           86,  117,    9,   95,   89,   22,   87,    8,  124,   23,    1,   86,\n",
      "           87,    9,  101,    1,  149,   87,    9,  117,    3,  104,  146,  239,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  165,    1,  119,  850,    1,  165,    1,  119,  850,    3,   86,\n",
      "          123,    9,   95,   89,   22,   94,   10,  135,   23,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  118,  100,   89,   22,   94,   10,  494,   23,    9,   11,    1,\n",
      "          274, 5530,    1,   86,   96,    9,  100,   89,   22,   94,   10,  494,\n",
      "           23,    1,  116,  194,    9,   22,   87,   10,   12,   23,    3,  118,\n",
      "          100,   89,   22,   94,   10,  437,   23,    9,   11,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  116,   87,    9,   22,   94,   10,  127,   23,    1,   86,  108,\n",
      "            9,   87,    1,  104, 1295,  186,    1,   86,  101,    9,   95,   89,\n",
      "           22,   94,   10,   19,   23,    3,   86,  123,    9,  117,    3,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   94,   10,  135,   23,    1,\n",
      "           86,  117,    9,   95,   89,   22,   87,    8,  146,   23,    1,   86,\n",
      "           96,    9,  100,   89,   22,   94,   10,  163,   23,    1,  154,  101,\n",
      "            9,   96,    3,   86,   87,    9,  101,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  164,    9,   12,    1,  104,  915,  263,    1,   86,   96,\n",
      "            9,  100,   89,   22,  107,    8,  870,  991,   23,    1,   86,  164,\n",
      "            9,   96,    3,   86,  108,    9,   87,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████| 1022/1022 [02:40<00:00,  6.35it/s, loss=1.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.5434197651663405 0.5409757269887047 0.5525282277859598 0.5466909532483304 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 4: 100%|███████████████████| 1022/1022 [02:43<00:00,  6.24it/s, loss=1.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.5593199608610567 0.5576499388004896 0.5591556210112911 0.5584017649221719 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 5:  87%|█████████████████▍  | 890/1022 [02:22<00:23,  5.71it/s, loss=1.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 30522]) tensor([[[ 7.2367e+00,  9.6140e+00,  1.4405e+01,  ..., -3.7860e-01,\n",
      "          -2.1508e+00,  6.1996e-01],\n",
      "         [ 5.4465e+00,  7.6073e+00,  6.8403e+00,  ..., -5.0868e-01,\n",
      "          -1.6260e+00, -7.1499e-01],\n",
      "         [ 8.0273e+00,  8.6460e+00,  7.5630e+00,  ..., -1.0702e+00,\n",
      "          -1.4359e+00, -5.6456e+00],\n",
      "         ...,\n",
      "         [ 1.9372e+01,  9.3230e+00,  9.6650e+00,  ...,  1.5249e+00,\n",
      "           3.6203e-01, -1.1098e+00],\n",
      "         [ 1.9628e+01,  1.0529e+01,  1.0221e+01,  ...,  1.2275e+00,\n",
      "           4.2393e-02, -4.4877e-01],\n",
      "         [ 1.9168e+01,  9.7940e+00,  9.5270e+00,  ...,  5.7744e-01,\n",
      "           2.2575e-01,  1.5923e-01]],\n",
      "\n",
      "        [[ 6.1535e+00,  6.9113e+00,  1.2495e+01,  ..., -2.9739e+00,\n",
      "          -3.8914e+00, -2.3382e+00],\n",
      "         [ 9.5945e+00,  1.0114e+01,  1.0367e+01,  ...,  3.0028e+00,\n",
      "           1.4632e+00,  3.2904e+00],\n",
      "         [ 2.2412e+00,  2.9328e+00,  2.3903e+00,  ..., -3.5931e+00,\n",
      "          -4.3061e+00, -6.4464e+00],\n",
      "         ...,\n",
      "         [ 1.8696e+01,  9.2954e+00,  7.8926e+00,  ...,  8.1059e-01,\n",
      "          -2.5497e-01, -1.7764e+00],\n",
      "         [ 1.8259e+01,  8.5071e+00,  7.9529e+00,  ...,  8.4214e-01,\n",
      "          -6.9458e-01, -9.8381e-01],\n",
      "         [ 1.9500e+01,  9.2035e+00,  9.8049e+00,  ...,  1.0791e+00,\n",
      "          -3.5369e-01, -1.1344e+00]],\n",
      "\n",
      "        [[ 7.8090e+00,  8.5844e+00,  1.3296e+01,  ..., -1.1828e+00,\n",
      "          -1.0632e+00, -1.4298e+00],\n",
      "         [ 6.5314e+00,  7.2580e+00,  6.6723e+00,  ..., -1.1014e+00,\n",
      "          -2.3066e+00, -1.1547e+00],\n",
      "         [ 1.0101e+01,  9.5748e+00,  8.8438e+00,  ..., -6.2529e-01,\n",
      "          -7.9729e-01, -1.9687e+00],\n",
      "         ...,\n",
      "         [ 1.7449e+01,  9.2291e+00,  8.2569e+00,  ..., -7.1532e-01,\n",
      "           4.8776e-01, -3.2772e-01],\n",
      "         [ 1.9158e+01,  9.7094e+00,  9.9233e+00,  ...,  4.8552e-01,\n",
      "           2.0555e-02, -3.5938e-02],\n",
      "         [ 1.8958e+01,  1.0390e+01,  9.5182e+00,  ...,  9.4767e-01,\n",
      "           4.1370e-01, -3.9520e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.5793e+00,  7.6016e+00,  1.2578e+01,  ..., -2.4205e+00,\n",
      "          -2.0392e+00, -2.1950e+00],\n",
      "         [ 9.0858e+00,  1.0719e+01,  9.5409e+00,  ...,  1.8633e+00,\n",
      "           5.6678e-01, -2.8405e-01],\n",
      "         [ 9.1608e+00,  9.1097e+00,  9.7975e+00,  ...,  1.9084e+00,\n",
      "           2.1625e+00, -3.2156e+00],\n",
      "         ...,\n",
      "         [ 1.8439e+01,  8.3624e+00,  8.6325e+00,  ...,  9.1332e-01,\n",
      "           3.3117e-02, -8.2835e-01],\n",
      "         [ 1.8640e+01,  9.0669e+00,  8.9547e+00,  ...,  1.0557e+00,\n",
      "           1.2981e-01, -5.0912e-01],\n",
      "         [ 1.8328e+01,  8.3147e+00,  8.0085e+00,  ...,  6.7873e-01,\n",
      "          -7.1949e-01,  6.2955e-01]],\n",
      "\n",
      "        [[ 4.6178e+00,  5.9987e+00,  1.1293e+01,  ..., -3.5103e+00,\n",
      "          -4.2437e+00, -2.3667e+00],\n",
      "         [ 7.0942e+00,  7.9997e+00,  8.1932e+00,  ...,  3.3589e-01,\n",
      "          -1.8916e+00,  8.5460e-01],\n",
      "         [ 5.4287e+00,  5.7820e+00,  7.3362e+00,  ..., -1.5422e+00,\n",
      "          -3.7573e+00, -2.8456e+00],\n",
      "         ...,\n",
      "         [ 1.9036e+01,  9.6017e+00,  9.2488e+00,  ...,  1.6258e+00,\n",
      "           9.6344e-02, -3.0363e-01],\n",
      "         [ 1.8527e+01,  8.2861e+00,  8.6504e+00,  ...,  1.3726e+00,\n",
      "          -3.6093e-01, -7.3323e-01],\n",
      "         [ 1.7870e+01,  8.4532e+00,  8.0192e+00,  ...,  1.7761e-02,\n",
      "          -1.5824e+00, -5.5673e-01]],\n",
      "\n",
      "        [[ 8.0733e+00,  7.7383e+00,  1.3564e+01,  ...,  4.2814e-01,\n",
      "           6.0303e-01, -4.5691e-01],\n",
      "         [ 1.1231e+01,  1.2589e+01,  1.1290e+01,  ...,  3.8953e+00,\n",
      "           3.4282e+00, -9.2074e-01],\n",
      "         [ 8.2281e+00,  1.0794e+01,  1.0172e+01,  ...,  3.0083e+00,\n",
      "           3.7965e-01,  3.0557e-01],\n",
      "         ...,\n",
      "         [ 1.9254e+01,  9.5327e+00,  9.3420e+00,  ...,  1.0553e+00,\n",
      "          -3.7959e-01, -2.9251e-01],\n",
      "         [ 1.9175e+01,  9.1099e+00,  9.7285e+00,  ...,  1.8003e+00,\n",
      "           7.5079e-01,  9.7409e-02],\n",
      "         [ 1.9715e+01,  9.5850e+00,  1.0285e+01,  ...,  2.4864e+00,\n",
      "           8.4464e-01,  2.1761e-01]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[   2,   86,   87,    9,   95,   89,   22,   10,   10,  124,   23,    1,\n",
      "           86,  108,    9,   87,    1,  104,  104,  122,    1,   86,  100,   89,\n",
      "           22,   94,   10,  124,   23,    9,   96,    3,  104, 1890,  141,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  125, 1832,    1,   86,   96,    9,   11,    1,  104, 1833,    1,\n",
      "           86,   87,    9,   95,   89,   22,   94,   10,   19,   23,    3,  153,\n",
      "           87,    9,  129,   89,   22,   87,   23,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   96,    9,  100,   89,   22,   94,   10,   10,   23,    1,\n",
      "            3,    3,    3,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   95,   89,   22,   94,   10,   19,   23,    9,   11,    1,\n",
      "           86,  100,   89,   22,   94,   10,   19,   23,    9,   11,    1,   86,\n",
      "           95,   89,   22,   94,   10,   15,   23,    9,   11,    1,   86,  100,\n",
      "           89,   22,   94,   10,   15,   23,    9,   12,    3,   86,  100,   89,\n",
      "           22,   94,   10,   15,   23,    9,   12,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  164,    9,   12,    1,  104, 1896,  125,    1,   86,  100,\n",
      "           89,   22,  107,    8, 3106,  127,   23,    9,   96,    1,   86,   96,\n",
      "            9,   11,    3,  119,  104,   23,    3,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  104,  146,    1,    1,   86,  164,    9,   96,    1,  104, 1896,\n",
      "           23,    1,  104,  125,   15,    3,  153,   96,    9,  129,   89,   22,\n",
      "           87,   23,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  100,   89,   22,   94,   10,  134,   23,    9,   96,    1,\n",
      "           86, 1918, 2734,    1,   86,   96,    9,  100,   89,   22,  107,    8,\n",
      "         1161,  134,   23,    1,  116,   96,    9,   89,   94,   10,   19,   23,\n",
      "            3,   86,  123,    9,  101,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  119,  104,  141,    1,  118,  100,   89,   22,   94,   10,  124,\n",
      "           23,    9,  141,    1,  125,  125,  125,    1,  118,  100,   89,   22,\n",
      "           94,   10,  124,   23,    9,  122,    3,  104,  133,  139,    3,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n",
      "['[CLS] mov rax, qword ptr [ - - 0x18 ] [UNK] mov rdi, rax [UNK] call call rsp [UNK] mov dword ptr [ rbp - 0x18 ], eax [SEP] call 0x45 al [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] je 0xb2aa [UNK] mov eax, 0 [UNK] call 0xb2c4 [UNK] mov rax, qword ptr [ rbp - 8 ] [SEP] movzx rax, byte ptr [ rax ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov eax, dword ptr [ rbp - - ] [UNK] [SEP] [SEP] [SEP] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov qword ptr [ rbp - 8 ], 0 [UNK] mov dword ptr [ rbp - 8 ], 0 [UNK] mov qword ptr [ rbp - 4 ], 0 [UNK] mov dword ptr [ rbp - 4 ], 1 [SEP] mov dword ptr [ rbp - 4 ], 1 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov edi, 1 [UNK] call 0x37 je [UNK] mov dword ptr [ rip + 0xa65 0x10 ], eax [UNK] mov eax, 0 [SEP] jmp call ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] call 0x38 [UNK] [UNK] mov edi, eax [UNK] call 0x37 ] [UNK] call je 4 [SEP] movzx eax, byte ptr [ rax ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov dword ptr [ rbp - 0x20 ], eax [UNK] mov 0x5b88 [UNK] mov eax, dword ptr [ rip + 0xb5 0x20 ] [UNK] lea eax, ptr rbp - 8 ] [SEP] mov rsi, rdx [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] jmp call al [UNK] cmp dword ptr [ rbp - 0x18 ], al [UNK] je je je [UNK] cmp dword ptr [ rbp - 0x18 ], rsp [SEP] call test jne [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "torch.Size([8, 64]) tensor([[   2,   86,   87,    9,   95,   89,   22,   94,   10,  124,   23,    1,\n",
      "           86,  108,    9,   87,    1,  104, 1295,  300,    1,   86,  100,   89,\n",
      "           22,   94,   10,   15,   23,    9,   96,    3,  119, 1890,  262,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  125, 1832,    1,   86,   96,    9,   11,    1,  119, 1833,    1,\n",
      "           86,   87,    9,   95,   89,   22,   94,   10,   19,   23,    3,  153,\n",
      "           96,    9,  129,   89,   22,   87,   23,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   96,    9,  100,   89,   22,   94,   10,   15,   23,    1,\n",
      "          209,    3,  183,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   95,   89,   22,   94,   10,  497,   23,    9,   11,    1,\n",
      "           86,  100,   89,   22,   94,   10,  425,   23,    9,   11,    1,   86,\n",
      "           95,   89,   22,   94,   10,  228,   23,    9,   11,    1,   86,  100,\n",
      "           89,   22,   94,   10,  522,   23,    9,  335,    3,   86,  100,   89,\n",
      "           22,   94,   10,  436,   23,    9,   12,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  164,    9,   12,    1,  104, 1896,  191,    1,   86,  100,\n",
      "           89,   22,  107,    8, 3106,   64,   23,    9,   11,    1,   86,   96,\n",
      "            9,   11,    3,  119,  734,  725,    3,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  104,  146,  263,    1,   86,  164,    9,   96,    1,  104, 1896,\n",
      "          225,    1,  104,  815,  186,    3,  153,   96,    9,  129,   89,   22,\n",
      "           87,   23,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  100,   89,   22,   94,   10,  358,   23,    9,   96,    1,\n",
      "          119, 1918, 2734,    1,   86,   96,    9,  100,   89,   22,  107,    8,\n",
      "         1161,  282,   23,    1,  116,  120,    9,   22,   87,   10,   12,   23,\n",
      "            3,   86,  123,    9,  101,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  119,  307,  525,    1,  118,  100,   89,   22,   94,   10,  303,\n",
      "           23,    9,  447,    1,  125,  307,  422,    1,  118,  100,   89,   22,\n",
      "           94,   10,  303,   23,    9,  447,    3,  223,  307,  859,    3,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:  97%|███████████████████▎| 987/1022 [02:37<00:05,  6.35it/s, loss=1.01]"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=5e-6)\n",
    "\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "counter = 0\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    \n",
    "    instruction_predictions_all, instruction_ground_truths_all = None, None\n",
    "    token_predictions_all, token_ground_truths_all = None, None\n",
    "    \n",
    "    # activate training mode\n",
    "    model.train()\n",
    "    for N,batch in enumerate(train_loop):\n",
    "\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        next_sentence_label=next_sentence_label,\n",
    "                        labels=labels)\n",
    "\n",
    "\n",
    "        token_prediction = torch.argmax(outputs.prediction_logits, axis=-1)\n",
    "\n",
    "        \n",
    "        token_prediction = token_prediction.detach().cpu().numpy().flatten()\n",
    "        token_ground_truth = labels.detach().cpu().numpy().flatten()\n",
    "        \n",
    "        counter+=1\n",
    "        if counter%2000==0 and counter!=0:\n",
    "            \n",
    "            print(outputs.prediction_logits.shape, outputs.prediction_logits)\n",
    "            print(torch.argmax(outputs.prediction_logits, axis=-1))\n",
    "\n",
    "            print(tokenizer.batch_decode(torch.argmax(outputs.prediction_logits, axis=-1)))\n",
    "\n",
    "            print(labels.shape , labels)\n",
    "            \n",
    "        \n",
    "        \n",
    "        instruction_prediction = torch.argmax(outputs.seq_relationship_logits, axis=-1)\n",
    "        instruction_prediction   = instruction_prediction.detach().cpu().numpy().flatten()\n",
    "        instruction_ground_truth = next_sentence_label.detach().cpu().numpy().flatten()\n",
    "        \n",
    "        if N==0:\n",
    "            instruction_predictions_all   = instruction_prediction\n",
    "            instruction_ground_truths_all = instruction_ground_truth\n",
    "            \n",
    "            token_predictions_all         = token_prediction\n",
    "            token_ground_truths_all       = token_ground_truth  \n",
    "        else:\n",
    "            instruction_predictions_all   = np.concatenate((instruction_predictions_all, instruction_prediction))\n",
    "            instruction_ground_truths_all = np.concatenate((instruction_ground_truths_all, instruction_ground_truth))\n",
    "            token_predictions_all   = np.concatenate((token_predictions_all, token_prediction))\n",
    "            token_ground_truths_all = np.concatenate((token_ground_truths_all, token_ground_truth))\n",
    "            \n",
    "\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        train_loop.set_description(f'Epoch {epoch}')\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    \n",
    "    instruction_accuracy = (accuracy_score(instruction_ground_truths_all,instruction_predictions_all))\n",
    "    instruction_precision, instruction_recall, instruction_f1, _ = precision_recall_fscore_support(instruction_ground_truths_all,instruction_predictions_all, average='binary')\n",
    "    print(\"Training: \", instruction_accuracy, instruction_precision, instruction_recall, instruction_f1, _)\n",
    "    \n",
    "    \n",
    "    ### EVAL Validation\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         v_predictions_all, v_ground_truths_all = None, None\n",
    "#         validation_loop = tqdm(validation_loader, leave=True)\n",
    "#         for N,v_batch in enumerate(validation_loop):\n",
    "#             v_input_ids = v_batch['input_ids'].to(device)\n",
    "#             v_attention_mask = v_batch['attention_mask'].to(device)\n",
    "#             v_token_type_ids = v_batch['token_type_ids'].to(device)\n",
    "#             v_labels = v_batch['labels'].to(device)\n",
    "#             # process\n",
    "#             v_outputs = model(v_input_ids, attention_mask=v_attention_mask,\n",
    "#                             token_type_ids=v_token_type_ids,\n",
    "#                             labels=v_labels)\n",
    "#             v_prediction = torch.argmax(v_outputs.logits, axis=-1)\n",
    "#             v_prediction = v_prediction.detach().cpu().numpy().flatten()\n",
    "#             v_ground_truth = v_labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "#             if N==0:\n",
    "#                 v_predictions_all = v_prediction\n",
    "#                 v_ground_truths_all = v_ground_truth\n",
    "#             else:\n",
    "#                 v_predictions_all   = np.concatenate((v_predictions_all, v_prediction))\n",
    "#                 v_ground_truths_all = np.concatenate((v_ground_truths_all, v_ground_truth))\n",
    "\n",
    "#         v_accuracy = (accuracy_score(v_ground_truths_all, v_predictions_all))\n",
    "#         v_precision, v_recall, v_f1, _ = precision_recall_fscore_support(v_ground_truths_all, \n",
    "#                                                                          v_predictions_all, average='binary')\n",
    "#         print(\"VALIDATION: \",v_accuracy, v_precision, v_recall, v_f1, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the trained model weights\n",
    "# training_model.save_weights(\"weights/wghts\" + str(epoch + 1) + \".ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
