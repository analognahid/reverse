{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Instruction Prediction Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahid/anaconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gitwipe 4\n",
      "gitps 147\n",
      "gitview 140\n",
      "gitfm 341\n",
      "gitwhich 6\n",
      "gitkeys 4\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys,os\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from elftools.elf.segments import Segment\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dir_path = \"./data/binaries/\"\n",
    "dir_file_list = os.listdir(data_dir_path)\n",
    "\n",
    "with open('./data/instruction_clusters.txt', 'w') as data_file:\n",
    "    for filename in dir_file_list:\n",
    "        filePath = os.path.join(data_dir_path,filename)\n",
    "\n",
    "        fh = open(filePath, 'rb')\n",
    "        bin_bytearray = bytearray(fh.read())\n",
    "        \n",
    "        with open(filePath, 'rb') as f:\n",
    "            elf = ELFFile(f)\n",
    "            dwarfinfo = elf.get_dwarf_info()\n",
    "            aranges = dwarfinfo.get_aranges()\n",
    "            print(filename, len(aranges.entries))\n",
    "            for arange in aranges.entries:\n",
    "\n",
    "                entry = arange.begin_addr\n",
    "                exit  = arange.begin_addr + arange.length\n",
    "                ops = bin_bytearray[entry: exit]\n",
    "\n",
    "                md = Cs(CS_ARCH_X86, CS_MODE_64)\n",
    "                md.detail = True\n",
    "                for inst in md.disasm(ops, entry):\n",
    "\n",
    "                    data_file.write(inst.mnemonic+\" \"+inst.op_str+\";\")\n",
    "                data_file.write('\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction,BertForPreTraining\n",
    "import torch\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./binary-tokenizer\")\n",
    "# model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delim = ';'\n",
    "with open('./data/instruction_clusters.txt', 'r') as fp:\n",
    "    text = fp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = text[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split sentences into consecutive, and non-consecutive sequences.\n",
    "\n",
    "We have to deal with edge-cases too - for example where there is only a single sentence within a paragraph as with the three examples above (in comparison to below where we can easily split into multiple sentences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text[51].split(delim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assign a 50% probability of using the genuine next sentence, and 50% probability of using another random sentence.\n",
    "\n",
    "To make this simpler, we'll create a *'bag'* of individual sentences to pull from when selecting a random sentence B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49783\n"
     ]
    }
   ],
   "source": [
    "bag = [instruction for instruction_cluster in text for instruction in instruction_cluster.split(delim)  if instruction!= '']\n",
    "bag_size = len(bag)\n",
    "print(bag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'mov rdx, qword ptr [rip + 0x2d98]',\n",
       " 'mov rax, qword ptr [rip + 0x2d81]',\n",
       " 'lea rcx, [rip + 0xd62]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1120',\n",
       " 'mov edi, 1',\n",
       " 'call 0x1170',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov dword ptr [rbp - 0x14], edi',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'mov edx, 1',\n",
       " 'mov esi, 0',\n",
       " 'mov edi, eax',\n",
       " 'call 0x1180',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'mov edx, 2',\n",
       " 'mov esi, 0',\n",
       " 'mov edi, eax',\n",
       " 'call 0x1180',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov rcx, qword ptr [rbp - 0x10]',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'mov edx, 0',\n",
       " 'mov rsi, rcx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x1180',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x40',\n",
       " 'mov qword ptr [rbp - 0x38], rdi',\n",
       " 'mov rax, qword ptr [rbp - 0x38]',\n",
       " 'mov esi, 2',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1160',\n",
       " 'mov dword ptr [rbp - 0x2c], eax',\n",
       " 'cmp dword ptr [rbp - 0x2c], -1',\n",
       " 'jne 0x137a',\n",
       " 'mov rdx, qword ptr [rip + 0x2cdf]',\n",
       " 'mov rax, qword ptr [rip + 0x2cc8]',\n",
       " 'mov rcx, qword ptr [rbp - 0x38]',\n",
       " 'lea rsi, [rip + 0xcbd]',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1120',\n",
       " 'mov eax, 1',\n",
       " 'jmp 0x14cd',\n",
       " 'mov eax, dword ptr [rbp - 0x2c]',\n",
       " 'mov edi, eax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x12c0',\n",
       " 'mov qword ptr [rbp - 0x18], rax',\n",
       " 'cmp qword ptr [rbp - 0x18], 0',\n",
       " 'jne 0x139e',\n",
       " 'mov eax, 0',\n",
       " 'jmp 0x14cd',\n",
       " 'mov edi, 0x10000',\n",
       " 'call 0x1150',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'cmp qword ptr [rbp - 0x10], 0',\n",
       " 'jne 0x13e2',\n",
       " 'mov rdx, qword ptr [rip + 0x2c76]',\n",
       " 'mov rax, qword ptr [rip + 0x2c5f]',\n",
       " 'lea rcx, [rip + 0xc78]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1120',\n",
       " 'mov eax, 1',\n",
       " 'jmp 0x14cd',\n",
       " 'mov qword ptr [rbp - 0x28], 0',\n",
       " 'jmp 0x14ab',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'sub rax, qword ptr [rbp - 0x28]',\n",
       " 'mov edx, 0x10000',\n",
       " 'cmp rax, rdx',\n",
       " 'cmovg rax, rdx',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov qword ptr [rbp - 0x20], 0',\n",
       " 'jmp 0x1451',\n",
       " 'call 0x1190',\n",
       " 'movsxd rdx, eax',\n",
       " 'imul rdx, rdx, -0x7f7f7f7f',\n",
       " 'shr rdx, 0x20',\n",
       " 'add edx, eax',\n",
       " 'sar edx, 7',\n",
       " 'mov esi, eax',\n",
       " 'sar esi, 0x1f',\n",
       " 'mov ecx, edx',\n",
       " 'sub ecx, esi',\n",
       " 'mov edx, ecx',\n",
       " 'shl edx, 8',\n",
       " 'sub edx, ecx',\n",
       " 'sub eax, edx',\n",
       " 'mov ecx, eax',\n",
       " 'mov rdx, qword ptr [rbp - 0x20]',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'add rax, rdx',\n",
       " 'mov edx, ecx',\n",
       " 'mov byte ptr [rax], dl',\n",
       " 'add qword ptr [rbp - 0x20], 1',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'cmp rax, qword ptr [rbp - 8]',\n",
       " 'jl 0x1411',\n",
       " 'mov rdx, qword ptr [rbp - 8]',\n",
       " 'mov rcx, qword ptr [rbp - 0x10]',\n",
       " 'mov eax, dword ptr [rbp - 0x2c]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x10f0',\n",
       " 'cmp qword ptr [rbp - 8], rax',\n",
       " 'je 0x14a3',\n",
       " 'mov rdx, qword ptr [rip + 0x2bb3]',\n",
       " 'mov rax, qword ptr [rip + 0x2b9c]',\n",
       " 'mov rcx, qword ptr [rbp - 0x38]',\n",
       " 'lea rsi, [rip + 0xbd0]',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1120',\n",
       " 'mov eax, 1',\n",
       " 'jmp 0x14cd',\n",
       " 'add qword ptr [rbp - 0x28], 0x10000',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'cmp rax, qword ptr [rbp - 0x18]',\n",
       " 'jl 0x13ef',\n",
       " 'mov eax, dword ptr [rbp - 0x2c]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x1100',\n",
       " 'call 0x1140',\n",
       " 'mov eax, 0',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov dword ptr [rbp - 0x14], edi',\n",
       " 'mov qword ptr [rbp - 0x20], rsi',\n",
       " 'mov dword ptr [rbp - 4], 0',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'mov qword ptr [rip + 0x2b39], rax',\n",
       " 'cmp dword ptr [rbp - 0x14], 1',\n",
       " 'jg 0x1507',\n",
       " 'mov eax, 0',\n",
       " 'call 0x1289',\n",
       " 'mov edi, 0',\n",
       " 'call 0x1130',\n",
       " 'mov edi, eax',\n",
       " 'call 0x1110',\n",
       " 'mov dword ptr [rbp - 8], 1',\n",
       " 'jmp 0x154c',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'cdqe ',\n",
       " 'lea rdx, [rax*8]',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'add rax, rdx',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x131b',\n",
       " 'add dword ptr [rbp - 4], eax',\n",
       " 'add dword ptr [rbp - 8], 1',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'cmp eax, dword ptr [rbp - 0x14]',\n",
       " 'jl 0x1521',\n",
       " 'cmp dword ptr [rbp - 4], 0',\n",
       " 'setne al',\n",
       " 'movzx eax, al',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'mov rax, qword ptr [rip + 0xdd38]',\n",
       " 'test rax, rax',\n",
       " 'je 0x3b2c',\n",
       " 'mov rax, qword ptr [rip + 0xdd2c]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x35b0',\n",
       " 'mov rax, qword ptr [rip + 0xdd25]',\n",
       " 'test rax, rax',\n",
       " 'je 0x3b47',\n",
       " 'mov rax, qword ptr [rip + 0xdd19]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x35b0',\n",
       " 'nop ',\n",
       " 'pop rbp',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'mov eax, dword ptr [rip + 0xde08]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xdd0e]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3700',\n",
       " 'mov rax, qword ptr [rip + 0xdd32]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rip + 0xddda]',\n",
       " 'cmp edx, eax',\n",
       " 'jge 0x3b9d',\n",
       " 'mov rax, qword ptr [rip + 0xdd17]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cdqe ',\n",
       " 'jmp 0x3ba5',\n",
       " 'mov eax, dword ptr [rip + 0xddbd]',\n",
       " 'cdqe ',\n",
       " 'mov rsi, qword ptr [rip + 0xdcfc]',\n",
       " 'mov rcx, qword ptr [rip + 0xdcbd]',\n",
       " 'mov rdx, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'mov edx, dword ptr [rip + 0xc4c0]',\n",
       " 'mov ecx, dword ptr [rip + 0xc4b6]',\n",
       " 'mov eax, dword ptr [rip + 0xc4b8]',\n",
       " 'mov esi, ecx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x759a',\n",
       " 'mov rax, qword ptr [rip + 0xdca8]',\n",
       " 'mov edx, 0',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov edx, dword ptr [rip + 0xdd68]',\n",
       " 'mov rcx, qword ptr [rip + 0xdc71]',\n",
       " 'mov rax, qword ptr [rip + 0xdc82]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'nop ',\n",
       " 'pop rbp',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'push rbx',\n",
       " 'sub rsp, 8',\n",
       " 'mov eax, dword ptr [rip + 0xdd39]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xdc3f]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3700',\n",
       " 'mov eax, dword ptr [rip + 0xdd1c]',\n",
       " 'lea ebx, [rax - 2]',\n",
       " 'lea rax, [rip + 0xd3f2]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cmp ebx, eax',\n",
       " 'jg 0x3c67',\n",
       " 'mov eax, dword ptr [rip + 0xdd00]',\n",
       " 'sub eax, 2',\n",
       " 'cdqe ',\n",
       " 'jmp 0x3c78',\n",
       " 'lea rax, [rip + 0xd3d2]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cdqe ',\n",
       " 'mov rdx, qword ptr [rip + 0xdbf1]',\n",
       " 'lea rcx, [rdx + 2]',\n",
       " 'mov rdx, rax',\n",
       " 'lea rax, [rip + 0xd3b3]',\n",
       " 'mov rsi, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'mov edx, dword ptr [rip + 0xc3f2]',\n",
       " 'mov ecx, dword ptr [rip + 0xc3e8]',\n",
       " 'mov eax, dword ptr [rip + 0xc3ea]',\n",
       " 'mov esi, ecx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x759a',\n",
       " 'mov rax, qword ptr [rip + 0xdbd6]',\n",
       " 'mov edx, 0',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov edx, dword ptr [rip + 0xdc8e]',\n",
       " 'mov rcx, qword ptr [rip + 0xdb97]',\n",
       " 'mov rax, qword ptr [rip + 0xdbb0]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'nop ',\n",
       " 'mov rbx, qword ptr [rbp - 8]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x10',\n",
       " 'mov qword ptr [rbp - 8], rdi',\n",
       " 'mov eax, dword ptr [rip + 0xdc58]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xdb5e]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3700',\n",
       " 'cmp qword ptr [rbp - 8], 0',\n",
       " 'je 0x3d6e',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rip + 0xdc26]',\n",
       " 'cmp edx, eax',\n",
       " 'jge 0x3d4e',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cdqe ',\n",
       " 'jmp 0x3d56',\n",
       " 'mov eax, dword ptr [rip + 0xdc0c]',\n",
       " 'cdqe ',\n",
       " 'mov rcx, qword ptr [rip + 0xdb13]',\n",
       " 'mov rsi, qword ptr [rbp - 8]',\n",
       " 'mov rdx, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'jmp 0x3dbd',\n",
       " 'mov rax, qword ptr [rip + 0xdb3b]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rip + 0xdbdb]',\n",
       " 'cmp edx, eax',\n",
       " 'jge 0x3d9c',\n",
       " 'mov rax, qword ptr [rip + 0xdb20]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cdqe ',\n",
       " 'jmp 0x3da4',\n",
       " 'mov eax, dword ptr [rip + 0xdbbe]',\n",
       " 'cdqe ',\n",
       " 'mov rsi, qword ptr [rip + 0xdb05]',\n",
       " 'mov rcx, qword ptr [rip + 0xdabe]',\n",
       " 'mov rdx, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'mov edx, dword ptr [rip + 0xc2e5]',\n",
       " 'mov ecx, dword ptr [rip + 0xc2db]',\n",
       " 'mov eax, dword ptr [rip + 0xc2dd]',\n",
       " 'mov esi, ecx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x759a',\n",
       " 'mov rax, qword ptr [rip + 0xdac1]',\n",
       " 'mov edx, 0',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov eax, dword ptr [rip + 0xdb69]',\n",
       " 'cmp eax, 9',\n",
       " 'jg 0x3e1d',\n",
       " 'mov edx, dword ptr [rip + 0xdb5e]',\n",
       " 'mov rcx, qword ptr [rip + 0xda67]',\n",
       " 'mov rax, qword ptr [rip + 0xda90]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'jmp 0x3e5d',\n",
       " 'mov rdx, qword ptr [rip + 0xda4c]',\n",
       " 'mov eax, dword ptr [rip + 0xdb36]',\n",
       " 'sub eax, 1',\n",
       " 'cdqe ',\n",
       " 'sub rax, 0xa',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0x20',\n",
       " 'mov eax, dword ptr [rip + 0xdb21]',\n",
       " 'sub eax, 0xa',\n",
       " 'mov edx, eax',\n",
       " 'mov rcx, qword ptr [rip + 0xda25]',\n",
       " 'mov rax, qword ptr [rip + 0xda4e]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'nop ',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov dword ptr [rbp - 0x14], edi',\n",
       " 'mov dword ptr [rbp - 4], 9',\n",
       " 'cmp dword ptr [rbp - 0x14], 0',\n",
       " 'js 0x3eb5',\n",
       " 'mov dword ptr [rbp - 8], 0',\n",
       " 'jmp 0x3eaf',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 4',\n",
       " 'mov rdx, rax',\n",
       " 'lea rax, [rip + 0xc2b4]',\n",
       " 'mov eax, dword ptr [rdx + rax]',\n",
       " 'cmp dword ptr [rbp - 0x14], eax',\n",
       " 'jne 0x3eab',\n",
       " 'mov eax, dword ptr [rbp - 8]',\n",
       " 'mov dword ptr [rip + 0xda0f], eax',\n",
       " 'jmp 0x3eb5',\n",
       " 'add dword ptr [rbp - 8], 1',\n",
       " 'cmp dword ptr [rbp - 8], 0x21',\n",
       " 'jle 0x3e85',\n",
       " 'mov eax, dword ptr [rip + 0xdaa5]',\n",
       " 'cmp dword ptr [rbp - 4], eax',\n",
       " 'jge 0x3f3b',\n",
       " 'mov edx, dword ptr [rip + 0xc1e2]',\n",
       " 'mov eax, dword ptr [rip + 0xc1e0]',\n",
       " 'mov esi, 7',\n",
       " 'mov edi, eax',\n",
       " 'call 0x759a',\n",
       " 'mov eax, dword ptr [rip + 0xda82]',\n",
       " 'sub eax, dword ptr [rbp - 4]',\n",
       " 'lea edx, [rax - 1]',\n",
       " 'mov rax, qword ptr [rip + 0xd9b5]',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov eax, dword ptr [rip + 0xd9ba]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 4',\n",
       " 'mov rdx, rax',\n",
       " 'lea rax, [rip + 0xc232]',\n",
       " 'lea rcx, [rdx + rax]',\n",
       " 'mov rax, qword ptr [rip + 0xd987]',\n",
       " 'mov edx, dword ptr [rbp - 4]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'mov rax, qword ptr [rip + 0xd972]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x91cd',\n",
       " 'mov eax, dword ptr [rip + 0xda1f]',\n",
       " 'lea edx, [rax - 1]',\n",
       " 'mov rax, qword ptr [rip + 0xd955]',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'nop ',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov eax, 0',\n",
       " 'call 0x7e66',\n",
       " 'mov qword ptr [rbp - 0x20], rax',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov qword ptr [rbp - 0x18], rax',\n",
       " 'cmp qword ptr [rbp - 0x18], 0',\n",
       " 'je 0x40d6',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rax - 1]',\n",
       " 'mov rax, qword ptr [rbp - 0x20]',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'cmp al, 7',\n",
       " 'je 0x40d6',\n",
       " 'mov eax, 0',\n",
       " 'call 0x7e66',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x68d7',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'sub rax, -0x80',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xba00',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov rdx, qword ptr [rbp - 0x10]',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'lea rcx, [rip + 0x80e6]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x3980',\n",
       " 'mov eax, dword ptr [rip + 0xd95f]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xd865]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3700',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rip + 0xd934]',\n",
       " 'cmp edx, eax',\n",
       " 'jge 0x4040',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cdqe ',\n",
       " 'jmp 0x4048',\n",
       " 'mov eax, dword ptr [rip + 0xd91a]',\n",
       " 'cdqe ',\n",
       " 'mov rcx, qword ptr [rip + 0xd821]',\n",
       " 'mov rsi, qword ptr [rbp - 8]',\n",
       " 'mov rdx, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xb878',\n",
       " 'mov edx, 1',\n",
       " 'mov esi, 7',\n",
       " 'mov edi, 1',\n",
       " 'call 0x759a',\n",
       " 'mov rax, qword ptr [rip + 0xd81b]',\n",
       " 'mov edx, 0',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov edx, dword ptr [rip + 0xd8c3]',\n",
       " 'mov rcx, qword ptr [rip + 0xd7cc]',\n",
       " 'mov rax, qword ptr [rip + 0xd7f5]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'mov eax, 0',\n",
       " 'call 0x75d0',\n",
       " 'mov eax, 0',\n",
       " 'call 0x6ac8',\n",
       " 'mov edi, 1',\n",
       " 'call 0x39d0',\n",
       " 'jmp 0x40e0',\n",
       " 'mov eax, 0',\n",
       " 'call 0x75d0',\n",
       " 'mov edi, 0',\n",
       " 'mov eax, 0',\n",
       " 'call 0x3cf2',\n",
       " 'mov edi, 0xffffffff',\n",
       " 'mov eax, 0',\n",
       " 'call 0x3e60',\n",
       " 'mov eax, 0',\n",
       " 'call 0x6ac8',\n",
       " 'nop ',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x10',\n",
       " 'mov dword ptr [rbp - 4], 0',\n",
       " 'jmp 0x415c',\n",
       " 'mov rdx, qword ptr [rip + 0xd739]',\n",
       " 'mov eax, dword ptr [rbp - 4]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xb878',\n",
       " 'mov rdx, qword ptr [rip + 0xd71b]',\n",
       " 'mov eax, dword ptr [rbp - 4]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov qword ptr [rax], 0',\n",
       " 'add dword ptr [rbp - 4], 1',\n",
       " 'mov eax, dword ptr [rip + 0xceaa]',\n",
       " 'cmp dword ptr [rbp - 4], eax',\n",
       " 'jl 0x4120',\n",
       " 'nop ',\n",
       " 'nop ',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x30',\n",
       " 'mov qword ptr [rbp - 0x28], rdi',\n",
       " 'mov qword ptr [rbp - 0x30], rsi',\n",
       " 'mov rdx, qword ptr [rbp - 0x28]',\n",
       " 'mov rax, qword ptr [rbp - 0x30]',\n",
       " 'mov esi, 0x7ff',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x37a0',\n",
       " 'mov qword ptr [rbp - 0x10], rax',\n",
       " 'cmp qword ptr [rbp - 0x10], 0',\n",
       " 'jne 0x41a6',\n",
       " 'mov eax, 0',\n",
       " 'jmp 0x41fc',\n",
       " 'mov rax, qword ptr [rbp - 0x30]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'sub rax, 1',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov rdx, qword ptr [rbp - 0x30]',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'cmp al, 0xa',\n",
       " 'jne 0x41dc',\n",
       " 'mov rdx, qword ptr [rbp - 0x30]',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'add rax, rdx',\n",
       " 'mov byte ptr [rax], 0',\n",
       " 'jmp 0x41f8',\n",
       " 'nop ',\n",
       " 'mov rax, qword ptr [rbp - 0x28]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3740',\n",
       " 'mov dword ptr [rbp - 0x14], eax',\n",
       " 'cmp dword ptr [rbp - 0x14], 0xa',\n",
       " 'je 0x41f8',\n",
       " 'cmp dword ptr [rbp - 0x14], -1',\n",
       " 'jne 0x41dd',\n",
       " 'mov rax, qword ptr [rbp - 0x10]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'sub rsp, 0x20',\n",
       " 'mov qword ptr [rbp - 0x18], rdi',\n",
       " 'lea rax, [rip + 0xce2b]',\n",
       " 'mov qword ptr [rbp - 8], rax',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'lea rdx, [rip + 0xce1c]',\n",
       " 'mov rsi, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x416b',\n",
       " 'test rax, rax',\n",
       " 'jne 0x4243',\n",
       " 'mov eax, 0xffffffff',\n",
       " 'jmp 0x42f8',\n",
       " 'lea rax, [rip + 0x7e98]',\n",
       " 'mov rsi, rax',\n",
       " 'lea rax, [rip + 0xcdec]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x39f0',\n",
       " 'test rax, rax',\n",
       " 'jne 0x426b',\n",
       " 'mov eax, 0xffffffff',\n",
       " 'jmp 0x42f8',\n",
       " 'mov dword ptr [rbp - 0xc], 0',\n",
       " 'jmp 0x4279',\n",
       " 'add qword ptr [rbp - 8], 1',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'jne 0x4274',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'mov edx, 3',\n",
       " 'lea rcx, [rip + 0x7e31]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3790',\n",
       " 'test eax, eax',\n",
       " 'jne 0x42ca',\n",
       " 'mov eax, dword ptr [rbp - 0xc]',\n",
       " 'jmp 0x42f8',\n",
       " 'add qword ptr [rbp - 8], 1',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'je 0x42c5',\n",
       " 'add dword ptr [rbp - 0xc], 1',\n",
       " 'jmp 0x4279',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'push rbx',\n",
       " 'sub rsp, 0xb8',\n",
       " 'mov dword ptr [rbp - 0xb4], edi',\n",
       " 'mov rax, qword ptr fs:[0x28]',\n",
       " 'mov qword ptr [rbp - 0x18], rax',\n",
       " 'xor eax, eax',\n",
       " 'mov rdx, qword ptr [rip + 0xd53a]',\n",
       " 'mov eax, dword ptr [rbp - 0xb4]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'mov qword ptr [rbp - 0xa8], rax',\n",
       " 'mov dword ptr [rbp - 0xb0], 0',\n",
       " 'jmp 0x43ba',\n",
       " 'add qword ptr [rbp - 0xa8], 1',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 0xa8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'jne 0x434b',\n",
       " 'jmp 0x4388',\n",
       " 'add qword ptr [rbp - 0xa8], 1',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 0xa8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'je 0x4380',\n",
       " 'add dword ptr [rbp - 0xb0], 1',\n",
       " 'mov eax, dword ptr [rip + 0xcc50]',\n",
       " 'cmp dword ptr [rbp - 0xb0], eax',\n",
       " 'jl 0x4353',\n",
       " 'mov dword ptr [rbp - 0xb0], 0',\n",
       " 'jmp 0x43dc',\n",
       " 'add qword ptr [rbp - 0xa8], 1',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 0xa8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'jne 0x43d4',\n",
       " 'jmp 0x4437',\n",
       " 'mov rax, qword ptr [rbp - 0xa8]',\n",
       " 'lea rdx, [rax + 1]',\n",
       " 'mov qword ptr [rbp - 0xa8], rdx',\n",
       " 'mov edx, dword ptr [rbp - 0xb0]',\n",
       " 'lea ecx, [rdx + 1]',\n",
       " 'mov dword ptr [rbp - 0xb0], ecx',\n",
       " 'movzx ecx, byte ptr [rax]',\n",
       " 'movsxd rax, edx',\n",
       " 'mov byte ptr [rbp + rax - 0xa0], cl',\n",
       " 'call 0x3a10',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov rax, qword ptr [rbp - 0xa8]',\n",
       " 'movzx eax, byte ptr [rax]',\n",
       " 'movsx rax, al',\n",
       " 'add rax, rax',\n",
       " 'add rax, rdx',\n",
       " 'movzx eax, word ptr [rax]',\n",
       " 'movzx eax, ax',\n",
       " 'and eax, 0x2000',\n",
       " 'test eax, eax',\n",
       " 'je 0x4409',\n",
       " 'mov eax, dword ptr [rbp - 0xb0]',\n",
       " 'cdqe ',\n",
       " 'mov byte ptr [rbp + rax - 0xa0], 0',\n",
       " 'lea rax, [rbp - 0xa0]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3960',\n",
       " 'mov dword ptr [rbp - 0xac], eax',\n",
       " 'cmp dword ptr [rbp - 0xac], 0',\n",
       " 'je 0x44cb',\n",
       " 'mov eax, dword ptr [rip + 0xd422]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 4',\n",
       " 'mov rdx, rax',\n",
       " 'lea rax, [rip + 0xbca6]',\n",
       " 'mov ebx, dword ptr [rdx + rax]',\n",
       " 'lea rax, [rbp - 0xa0]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3960',\n",
       " 'mov esi, ebx',\n",
       " 'mov edi, eax',\n",
       " 'call 0x3830',\n",
       " 'test eax, eax',\n",
       " 'sete al',\n",
       " 'movzx eax, al',\n",
       " 'jmp 0x44d0',\n",
       " 'mov eax, 0xffffffff',\n",
       " 'mov rdx, qword ptr [rbp - 0x18]',\n",
       " 'sub rdx, qword ptr fs:[0x28]',\n",
       " 'je 0x44e4',\n",
       " 'call 0x3680',\n",
       " 'mov rbx, qword ptr [rbp - 8]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'push rbx',\n",
       " 'sub rsp, 0x838',\n",
       " 'mov qword ptr [rbp - 0x838], rdi',\n",
       " 'mov rax, qword ptr fs:[0x28]',\n",
       " 'mov qword ptr [rbp - 0x18], rax',\n",
       " 'xor eax, eax',\n",
       " 'mov dword ptr [rbp - 0x824], 0',\n",
       " 'jmp 0x4578',\n",
       " 'mov eax, dword ptr [rbp - 0x824]',\n",
       " 'add eax, 1',\n",
       " 'cdqe ',\n",
       " 'lea rdx, [rax*8]',\n",
       " 'mov rax, qword ptr [rip + 0xd32a]',\n",
       " 'mov rsi, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xba20',\n",
       " 'mov qword ptr [rip + 0xd318], rax',\n",
       " 'mov rdx, qword ptr [rip + 0xd311]',\n",
       " 'mov eax, dword ptr [rbp - 0x824]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'lea rbx, [rdx + rax]',\n",
       " 'lea rax, [rbp - 0x820]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0xbb30',\n",
       " 'mov qword ptr [rbx], rax',\n",
       " 'add dword ptr [rbp - 0x824], 1',\n",
       " 'lea rdx, [rbp - 0x820]',\n",
       " 'mov rax, qword ptr [rbp - 0x838]',\n",
       " 'mov rsi, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'mov eax, 0',\n",
       " 'call 0x416b',\n",
       " 'test rax, rax',\n",
       " 'jne 0x451c',\n",
       " 'mov eax, dword ptr [rbp - 0x824]',\n",
       " 'mov dword ptr [rip + 0xca65], eax',\n",
       " 'nop ',\n",
       " 'mov rax, qword ptr [rbp - 0x18]',\n",
       " 'sub rax, qword ptr fs:[0x28]',\n",
       " 'je 0x45bc',\n",
       " 'call 0x3680',\n",
       " 'mov rbx, qword ptr [rbp - 8]',\n",
       " 'leave ',\n",
       " 'ret ',\n",
       " 'endbr64 ',\n",
       " 'push rbp',\n",
       " 'mov rbp, rsp',\n",
       " 'push rbx',\n",
       " 'sub rsp, 0x28',\n",
       " 'mov dword ptr [rbp - 0x24], edi',\n",
       " 'mov dword ptr [rbp - 0x28], esi',\n",
       " 'mov rdx, qword ptr [rip + 0xd284]',\n",
       " 'mov eax, dword ptr [rbp - 0x24]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov rax, qword ptr [rax]',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov dword ptr [rbp - 0x18], eax',\n",
       " 'mov eax, dword ptr [rip + 0xd364]',\n",
       " 'sub eax, 2',\n",
       " 'mov dword ptr [rbp - 0x14], eax',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'cmp eax, dword ptr [rbp - 0x18]',\n",
       " 'jl 0x4613',\n",
       " 'mov dword ptr [rbp - 0x1c], 0',\n",
       " 'jmp 0x4629',\n",
       " 'mov eax, dword ptr [rbp - 0x18]',\n",
       " 'sub eax, dword ptr [rbp - 0x14]',\n",
       " 'mov edx, eax',\n",
       " 'mov eax, dword ptr [rip + 0xd263]',\n",
       " 'cmp edx, eax',\n",
       " 'cmovle eax, edx',\n",
       " 'mov dword ptr [rbp - 0x1c], eax',\n",
       " 'mov eax, dword ptr [rip + 0xd331]',\n",
       " 'movsxd rdx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xd237]',\n",
       " 'mov esi, 0x20',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3700',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'movsxd rbx, eax',\n",
       " 'mov rdx, qword ptr [rip + 0xd20d]',\n",
       " 'mov eax, dword ptr [rbp - 0x24]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov eax, dword ptr [rbp - 0x1c]',\n",
       " 'cdqe ',\n",
       " 'add rax, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'cmp rbx, rax',\n",
       " 'ja 0x467e',\n",
       " 'mov eax, dword ptr [rbp - 0x14]',\n",
       " 'cdqe ',\n",
       " 'jmp 0x46a4',\n",
       " 'mov rdx, qword ptr [rip + 0xd1db]',\n",
       " 'mov eax, dword ptr [rbp - 0x24]',\n",
       " 'cdqe ',\n",
       " 'shl rax, 3',\n",
       " 'add rax, rdx',\n",
       " 'mov rdx, qword ptr [rax]',\n",
       " 'mov eax, dword ptr [rbp - 0x1c]',\n",
       " 'cdqe ',\n",
       " 'add rax, rdx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x3670',\n",
       " 'mov rcx, qword ptr [rip + 0xd1b5]',\n",
       " 'mov edx, dword ptr [rbp - 0x24]',\n",
       " 'movsxd rdx, edx',\n",
       " 'shl rdx, 3',\n",
       " 'add rdx, rcx',\n",
       " 'mov rcx, qword ptr [rdx]',\n",
       " 'mov edx, dword ptr [rbp - 0x1c]',\n",
       " 'movsxd rdx, edx',\n",
       " 'lea rsi, [rcx + rdx]',\n",
       " 'mov rdx, qword ptr [rip + 0xd1a4]',\n",
       " 'lea rcx, [rdx + 2]',\n",
       " 'mov rdx, rax',\n",
       " 'mov rdi, rcx',\n",
       " 'call 0x3820',\n",
       " 'mov eax, dword ptr [rip + 0xd19b]',\n",
       " 'cmp dword ptr [rbp - 0x24], eax',\n",
       " 'jne 0x46ed',\n",
       " 'mov edx, 0x3e',\n",
       " 'jmp 0x46f2',\n",
       " 'mov edx, 0x20',\n",
       " 'mov rax, qword ptr [rip + 0xd177]',\n",
       " 'mov byte ptr [rax], dl',\n",
       " 'mov rax, qword ptr [rip + 0xd16e]',\n",
       " 'add rax, 1',\n",
       " 'mov byte ptr [rax], 0x20',\n",
       " 'cmp dword ptr [rbp - 0x28], 0',\n",
       " 'je 0x475d',\n",
       " 'mov eax, dword ptr [rip + 0xb98b]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x7547',\n",
       " 'mov eax, dword ptr [rip + 0xd15a]',\n",
       " 'cmp dword ptr [rbp - 0x24], eax',\n",
       " 'jne 0x4743',\n",
       " 'mov eax, dword ptr [rip + 0xb96f]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x74f4',\n",
       " 'mov eax, dword ptr [rip + 0xb95e]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x751c',\n",
       " 'jmp 0x475d',\n",
       " 'mov eax, dword ptr [rip + 0xb94f]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x74f4',\n",
       " 'mov eax, dword ptr [rip + 0xb946]',\n",
       " 'mov edi, eax',\n",
       " 'call 0x751c',\n",
       " 'mov edx, dword ptr [rip + 0xd115]',\n",
       " 'mov eax, dword ptr [rbp - 0x24]',\n",
       " 'sub eax, edx',\n",
       " 'mov ecx, eax',\n",
       " 'mov rax, qword ptr [rip + 0xd127]',\n",
       " 'mov edx, 0',\n",
       " 'mov esi, ecx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " 'mov edx, dword ptr [rip + 0xd1da]',\n",
       " 'mov rcx, qword ptr [rip + 0xd0e3]',\n",
       " 'mov rax, qword ptr [rip + 0xd104]',\n",
       " 'mov rsi, rcx',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x912b',\n",
       " 'mov eax, dword ptr [rip + 0xd1bb]',\n",
       " 'lea edx, [rax - 1]',\n",
       " 'mov rax, qword ptr [rip + 0xd0f1]',\n",
       " 'mov esi, 0',\n",
       " 'mov rdi, rax',\n",
       " 'call 0x922f',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we create our 50/50 NIP training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10221\n",
      "['endbr64 ', 'push rbp', 'mov rbp, rsp', 'mov rdx, qword ptr [rip + 0x2d98]', 'mov rax, qword ptr [rip + 0x2d81]']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "history = []\n",
    "next_instruction = []\n",
    "label = []\n",
    "\n",
    "page_len = 5\n",
    "instruction_pages = []\n",
    "for instruction_cluster in text:\n",
    "    instructions = [\n",
    "        instruction for instruction in instruction_cluster.split(delim) if instruction != ''\n",
    "    ]\n",
    "    if len(instructions)>page_len:\n",
    "        \n",
    "        for i in range(0,len(instructions),page_len):\n",
    "            instruction_pages.append(instructions[i:i+page_len])\n",
    "        \n",
    "print(len(instruction_pages))\n",
    "print(instruction_pages[0])\n",
    "\n",
    "for instruction_page in instruction_pages:\n",
    "    \n",
    "#     instructions = [\n",
    "#         instruction for instruction in instruction_page.split(';') if instruction != ''\n",
    "#     ]\n",
    "    \n",
    "    \n",
    "#     num_instructions = len(instruction_page)\n",
    "    \n",
    "    \n",
    "\n",
    "#     start = random.randint(0, num_instructions-2)\n",
    "    # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "    if random.random() >= 0.5:\n",
    "        # this is IsNextSentence\n",
    "        history.append(delim.join(instruction_page[:-1]))\n",
    "        next_instruction.append(instruction_page[-1])\n",
    "        label.append(0)\n",
    "    else:\n",
    "        index = random.randint(0, bag_size-1)\n",
    "        # this is NotNextSentence\n",
    "        history.append(delim.join(instruction_page[:-1]))\n",
    "        next_instruction.append(bag[index])\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10221\n",
      "1\n",
      "-> endbr64 ;push rbp;mov rbp, rsp;mov rdx, qword ptr [rip + 0x2d98] \n",
      "\n",
      "#  call 0xe319 \n",
      "\n",
      "0\n",
      "-> lea rcx, [rip + 0xd62];mov rsi, rcx;mov rdi, rax;mov eax, 0 \n",
      "\n",
      "#  call 0x1120 \n",
      "\n",
      "0\n",
      "-> mov edi, 1 \n",
      "\n",
      "#  call 0x1170 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(label))\n",
    "for i in range(3):\n",
    "    print(label[i])\n",
    "    print('->',history[i] , '\\n')\n",
    "    print('# ',next_instruction[i] , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready for tokenization, this time we truncate/pad each token to the same length of *512* tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(history, next_instruction, return_tensors='pt', \n",
    "                   max_length=64, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the *token_type_ids* tensors have been built correctly (eg **1** indicating sentence B tokens) by checking the first instance of *token_type_ids*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.token_type_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **0** tokens following our sentence B tokens correspond to *PAD* tokens.\n",
    "\n",
    "Alongside this, we need to create a *labels* tensor too - which corresponds to the values contained within our `label` variable. Our *labels* tensor must be a *LongTensor*, and we will need to transpose the tensor so that it matches our other tensors' dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the labels tensor is simply a clone of the input_ids tensor before masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2, 180,   1, 162,  94,   1,  86,  94,   9, 122,   1,  86, 101,   9,\n",
       "         95,  89,  22, 107,   8, 469, 255,  23,   3, 104, 755,   3,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we mask tokens in the input_ids tensor using the 15% probability for MLM - ensuring we don't mask CLS, SEP, or PAD tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True, False, False, False, False,  True, False, False, False,\n",
       "        False, False, False, False, False, False,  True, False,  True,  True,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr[0]\n",
    "# inputs.input_ids.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now take the indices of each True value within each vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6, 16, 18, 19]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then apply these indices to each row in input_ids, assigning each value at these indices a value of 103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inputs` tensors are now ready, and we can begin building the model input pipeline for training. We first create a PyTorch dataset from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize our data using the `MeditationDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeditationsDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "validation_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And initialize the dataloader, which we'll be using to load our data into the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto setting up the training loop. First we setup GPU/CPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the training mode of our model, and initialize our optimizer (Adam with weighted decay - reduces chance of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto the training loop, we'll train for a couple of epochs (change `epochs` to modify this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odict_keys(['loss', 'prediction_logits', 'seq_relationship_logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|███████████████████| 1022/1022 [02:44<00:00,  6.21it/s, loss=3.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.5100293542074364 0.5079513564078578 0.5331369661266568 0.5202395209580838 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 1:  96%|███████████████████▏| 978/1022 [02:35<00:07,  6.02it/s, loss=2.52]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 30522]) tensor([[[ 8.2182e+00,  8.3281e+00,  8.6531e+00,  ..., -1.8650e+00,\n",
      "          -8.1123e-01, -3.0827e+00],\n",
      "         [ 7.1044e+00,  8.3823e+00,  6.9689e+00,  ..., -1.7266e+00,\n",
      "           1.2043e-01, -3.9926e+00],\n",
      "         [ 2.9552e+00,  4.2867e+00,  3.3036e+00,  ..., -5.6875e+00,\n",
      "          -4.5578e+00, -7.1035e+00],\n",
      "         ...,\n",
      "         [ 1.5857e+01,  8.5598e+00,  8.4537e+00,  ...,  1.7169e+00,\n",
      "           2.3162e+00, -1.2559e+00],\n",
      "         [ 1.6430e+01,  9.4550e+00,  9.5399e+00,  ...,  1.3539e+00,\n",
      "           2.2787e+00,  4.2687e-01],\n",
      "         [ 1.4751e+01,  7.7021e+00,  7.6795e+00,  ..., -1.7905e-01,\n",
      "           1.0883e+00, -1.9829e+00]],\n",
      "\n",
      "        [[ 1.0502e+01,  1.0775e+01,  1.0563e+01,  ...,  3.5160e-01,\n",
      "           3.5340e-01, -1.1113e+00],\n",
      "         [ 1.1889e+01,  1.3569e+01,  1.1991e+01,  ...,  2.7444e+00,\n",
      "           1.7586e+00,  6.1909e-01],\n",
      "         [ 1.4836e+01,  1.6090e+01,  1.4027e+01,  ...,  3.9560e+00,\n",
      "           3.3064e+00,  2.2776e+00],\n",
      "         ...,\n",
      "         [ 1.7840e+01,  1.1025e+01,  1.0753e+01,  ...,  2.9854e+00,\n",
      "           3.0605e+00,  1.1008e+00],\n",
      "         [ 1.7669e+01,  1.1135e+01,  1.1003e+01,  ...,  3.6644e+00,\n",
      "           4.1202e+00,  8.5491e-01],\n",
      "         [ 1.9242e+01,  1.3112e+01,  1.2652e+01,  ...,  4.5115e+00,\n",
      "           4.2047e+00,  1.9154e+00]],\n",
      "\n",
      "        [[ 9.6515e+00,  6.3862e+00,  6.7445e+00,  ..., -2.7921e+00,\n",
      "          -2.4787e+00, -4.1479e+00],\n",
      "         [ 1.2270e+01,  1.3930e+01,  1.2335e+01,  ...,  2.6397e+00,\n",
      "           1.4790e+00,  1.9475e+00],\n",
      "         [ 1.1780e+01,  1.3579e+01,  1.1718e+01,  ...,  2.1667e+00,\n",
      "           8.2421e-01,  2.0487e-01],\n",
      "         ...,\n",
      "         [ 1.5259e+01,  8.1125e+00,  8.4761e+00,  ...,  8.9727e-01,\n",
      "           8.3945e-01, -1.2856e+00],\n",
      "         [ 1.5354e+01,  8.1274e+00,  8.3604e+00,  ...,  4.3282e-01,\n",
      "           8.9196e-02, -7.3308e-01],\n",
      "         [ 1.5865e+01,  8.9801e+00,  8.9370e+00,  ...,  1.9528e+00,\n",
      "           1.9578e+00, -8.2710e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.1892e+00,  6.6828e+00,  7.1785e+00,  ..., -3.4707e+00,\n",
      "          -3.0981e+00, -4.8738e+00],\n",
      "         [ 1.2163e+01,  1.4670e+01,  1.2443e+01,  ...,  2.9846e+00,\n",
      "           1.7703e+00,  2.6724e-01],\n",
      "         [ 7.8660e+00,  1.1691e+01,  9.4363e+00,  ...,  6.3306e-01,\n",
      "          -7.4702e-01, -2.6577e-01],\n",
      "         ...,\n",
      "         [ 1.5867e+01,  8.9318e+00,  9.1375e+00,  ..., -1.3774e-02,\n",
      "           6.4586e-01, -1.6177e+00],\n",
      "         [ 1.5780e+01,  9.0651e+00,  9.4073e+00,  ...,  9.3638e-01,\n",
      "           1.0453e+00, -1.1821e+00],\n",
      "         [ 1.5686e+01,  8.8125e+00,  8.9378e+00,  ...,  6.9136e-01,\n",
      "           1.6856e+00, -1.4365e+00]],\n",
      "\n",
      "        [[ 8.0188e+00,  6.0680e+00,  6.7955e+00,  ..., -1.5465e+00,\n",
      "          -2.8942e+00, -4.7237e+00],\n",
      "         [ 1.1562e+01,  1.3271e+01,  1.1423e+01,  ...,  2.7722e+00,\n",
      "           1.6199e+00,  2.1488e+00],\n",
      "         [ 9.7801e+00,  1.2636e+01,  1.0184e+01,  ...,  2.0217e+00,\n",
      "           8.5390e-01,  1.1753e+00],\n",
      "         ...,\n",
      "         [ 1.5144e+01,  7.2416e+00,  7.6030e+00,  ...,  1.9126e+00,\n",
      "           1.2842e+00,  2.6606e-01],\n",
      "         [ 1.5465e+01,  7.6616e+00,  7.9439e+00,  ...,  3.0488e+00,\n",
      "           1.3161e+00, -5.5387e-01],\n",
      "         [ 1.5591e+01,  7.8884e+00,  8.1342e+00,  ...,  2.7884e+00,\n",
      "           1.6829e+00, -3.5649e-01]],\n",
      "\n",
      "        [[ 8.1939e+00,  7.3625e+00,  7.5746e+00,  ..., -2.7300e+00,\n",
      "          -2.2141e+00, -3.9471e+00],\n",
      "         [ 1.3656e+01,  1.4950e+01,  1.3029e+01,  ...,  3.0949e+00,\n",
      "           2.8887e+00,  1.4157e+00],\n",
      "         [ 9.5608e+00,  1.2293e+01,  1.0077e+01,  ...,  8.5961e-01,\n",
      "           6.4885e-01, -8.3968e-01],\n",
      "         ...,\n",
      "         [ 1.5279e+01,  8.2622e+00,  8.4131e+00,  ...,  7.8839e-01,\n",
      "           1.0657e+00, -1.2171e+00],\n",
      "         [ 1.7111e+01,  1.0192e+01,  1.0087e+01,  ...,  1.4701e+00,\n",
      "           2.1765e+00,  4.3021e-01],\n",
      "         [ 1.6078e+01,  8.9370e+00,  9.3464e+00,  ...,  5.7596e-01,\n",
      "           1.6054e+00, -9.9951e-02]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[ 101,   86, 2034,    1,    9,    1,    1,  100,   89,    9,    9,    1,\n",
      "            1,    1,    1,    9,    9,    9,    9,    9,    9,    9,    1,    3,\n",
      "            3,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   9,    9,    1,    9,    1,    1,    1,    1, 1284,    1,    1,    1,\n",
      "            1,    9,    9,    9,    9,    9, 1285,    3,    3,    9,    9,    9,\n",
      "            9,    9,    3,    9,    9,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   0,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    0,    9,    9,    9,    9,    9,    9,   23,   23,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [ 101,    9,  101,    9,    9,    9,    9,    9,    9,    9,    9,    1,\n",
      "            9,    9,  101,    9,    9,    9,    1,    9,    9,    9,    9,    9,\n",
      "            9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    0,    9,\n",
      "            9,    9,  101,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [ 101,    9,    9,    9,    9,    9,  101,    9,    9,    9,    9,    9,\n",
      "            9,    1,    9,    9,    9,    9,    1,    1,    9,    9,  100,    1,\n",
      "            9,    9,    9,    9,    9,    9,    9,    9,    0,    9,    9,    9,\n",
      "            9,    9,    9,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [ 101,    9,    1,    9,    1,    9,    9,    1,    1,    9,    9,    9,\n",
      "            1,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,    9,\n",
      "            9,    9,  100,    9,    9,    9,    9,    9,    9,    9,    9,  101,\n",
      "            9,    9,    3,    9,    9,    9,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [ 101,    9,    1,    1,    1,    1,    1, 2047,    1,    1,    1, 1288,\n",
      "            1,    1,    1,    9,  100,    1,    1,    0, 2047, 1999, 2735,    9,\n",
      "            0,    9,    9,    9,    3,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   0,    9,    1,    9,    9,    9,    1,    9,    9,    9,    9,    9,\n",
      "            9,    9,    3,    0,    3,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n",
      "['rdx mov 0x22d05 [UNK], [UNK] [UNK] dword ptr,, [UNK] [UNK] [UNK] [UNK],,,,,,, [UNK] [SEP] [SEP],,,,,,,,,,, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', ',, [UNK], [UNK] [UNK] [UNK] [UNK]b1 [UNK] [UNK] [UNK] [UNK],,,,,b2 [SEP] [SEP],,,,, [SEP],, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[PAD] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [PAD],,,,,, ] ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'rdx, rdx,,,,,,,, [UNK],, rdx,,, [UNK],,,,,,,,,,,,,,, [PAD],,, rdx [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'rdx,,,,, rdx,,,,,, [UNK],,,, [UNK] [UNK],, dword [UNK],,,,,,,, [PAD],,,,,, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'rdx, [UNK], [UNK],, [UNK] [UNK],,, [UNK],,,,,,,,,,,,, dword,,,,,,,, rdx,, [SEP],,, [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'rdx, [UNK] [UNK] [UNK] [UNK] [UNK] 0x49d0 [UNK] [UNK] [UNK]c1 [UNK] [UNK] [UNK], dword [UNK] [UNK] [PAD] 0x49d0 0x14bb8d, [PAD],,, [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[PAD], [UNK],,, [UNK],,,,,,, [SEP] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "torch.Size([8, 64]) tensor([[   2,  119, 2034,    1,   86,  120,    9,  100,   89,   22,   94,   10,\n",
      "          134,   23,    1,   86,   96,    9,  120,    1,  159,   96,    9,   13,\n",
      "            3,   86,   87,    9,   95,   89,   22,  107,    8,  870, 1517,   23,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  133,   87,    9,   87,    1,  139,  167, 1284,   63,    1,  133,\n",
      "          189,    9,  189,    1,  139,  167, 1285,   52,    3,  116,   87,    9,\n",
      "           22,  107,    8, 3211,   23,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  180,    1,  162,   94,    1,   86,   94,    9,  122,    1,  149,\n",
      "          122,    9,  127,    3,   86,   87,    9,   95,   89,   22,   87,   23,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  116,  101,    9,   22,   87,    8,   13,   23,    1,   86,  129,\n",
      "           89,   22,  101,   23,    9,  134,    1,   86,   87,    9,   95,   89,\n",
      "           22,   94,   10,  134,   23,    1,  115,   87,    9,   12,    3,  115,\n",
      "           87,    9,  101,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  104,  915,  244,    1,   86,  101,    9,   95,   89,   22,   87,\n",
      "           23,    1,   86,   87,    9,   95,   89,   22,   94,   10, 1128,   23,\n",
      "            1,  153,   96,    9,  129,   89,   22,   87,   23,    3,   86,  229,\n",
      "            9,  174,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  117,    9,   95,   89,   22,   87,    8,  146,   23,    1,\n",
      "           86,   87,    9,   95,   89,   22,   94,   10,  281,   23,    1,   86,\n",
      "           96,    9,  100,   89,   22,   87,    8,  135,   23,    1,  154,  101,\n",
      "            9,   96,    3,  104,  875,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   96,    9,   11,    1,  104, 2047,    1,  119,  211, 1288,\n",
      "            1,   86,   96,    9,  100,   89,   22,  107,    8, 1322, 2735,   23,\n",
      "            3,   86,  164,    9,  163,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   96,    9,   11,    1,  104,  659,  330,    1,  165,    1,\n",
      "          200,   94,    3,  183,    3,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████| 1022/1022 [02:42<00:00,  6.27it/s, loss=2.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.5204256360078278 0.5182534001431639 0.5331369661266568 0.525589836660617 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 2: 100%|███████████████████| 1022/1022 [02:45<00:00,  6.18it/s, loss=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.5299657534246576 0.5270808909730363 0.551791850760923 0.539153375704521 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 3:  91%|███████████████████▏ | 934/1022 [02:27<00:14,  5.98it/s, loss=1.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 30522]) tensor([[[ 4.8569,  3.0642,  8.4831,  ..., -4.2121, -4.6648, -5.0275],\n",
      "         [ 9.7800,  9.8827,  9.9903,  ...,  1.0099, -0.2144, -4.0216],\n",
      "         [ 5.3497,  8.5034,  7.5117,  ..., -2.1596, -1.1514, -6.4077],\n",
      "         ...,\n",
      "         [16.8085,  7.3693,  8.0538,  ...,  0.1898, -0.7422,  1.1627],\n",
      "         [16.6647,  6.4952,  8.0178,  ...,  0.8615, -0.0357, -0.6246],\n",
      "         [18.3609,  8.9514,  9.6482,  ...,  1.0330,  0.5950, -0.6513]],\n",
      "\n",
      "        [[ 6.1671,  6.3186, 10.5674,  ..., -3.3194, -3.6099, -3.7328],\n",
      "         [ 8.6013,  8.6139,  8.2121,  ..., -0.5204, -1.6258, -2.3219],\n",
      "         [ 3.4770,  3.3306,  4.3195,  ..., -1.3236, -3.0779, -5.6692],\n",
      "         ...,\n",
      "         [16.2036,  7.2324,  7.9815,  ..., -0.2070, -0.8587, -2.5573],\n",
      "         [16.1823,  6.9145,  7.9099,  ..., -0.2690, -1.0871, -2.1080],\n",
      "         [17.1722,  8.5498,  8.7344,  ...,  0.3369, -0.3548, -2.0142]],\n",
      "\n",
      "        [[ 4.4646,  4.2612,  9.1370,  ..., -3.9766, -3.8175, -4.8614],\n",
      "         [ 8.3902,  9.4574,  8.4137,  ...,  0.7143, -1.9812,  0.0530],\n",
      "         [ 8.8044, 10.7137,  9.7918,  ...,  2.4843,  0.3533,  0.2466],\n",
      "         ...,\n",
      "         [17.7453,  9.0142,  8.8533,  ...,  0.6477, -0.2150, -0.9744],\n",
      "         [17.9966,  8.4112,  9.4904,  ...,  0.7288, -0.1488, -0.8990],\n",
      "         [17.8751,  9.3322,  8.9670,  ...,  1.4426,  1.0848, -1.4581]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.6020,  6.3154, 10.8403,  ..., -3.6045, -3.0512, -2.9219],\n",
      "         [ 8.4923, 10.4137,  9.6221,  ...,  2.4188, -0.0357,  0.4587],\n",
      "         [ 8.2500,  7.8188,  6.6913,  ...,  0.4960, -0.0718, -5.3230],\n",
      "         ...,\n",
      "         [16.2702,  6.1752,  7.8575,  ..., -1.6697, -1.0220, -0.8998],\n",
      "         [17.4455,  8.1094,  9.2635,  ...,  0.1532,  0.2157, -0.8840],\n",
      "         [17.2268,  7.7346,  8.6012,  ...,  0.1502, -0.6300, -0.4391]],\n",
      "\n",
      "        [[ 5.5575,  4.2739,  9.7104,  ..., -4.3670, -4.0125, -6.0764],\n",
      "         [ 7.2524,  9.1032,  7.9240,  ...,  1.2665, -1.6392, -0.7758],\n",
      "         [ 9.0033,  7.9663,  7.7369,  ...,  0.8603, -0.4783, -2.4101],\n",
      "         ...,\n",
      "         [17.6549,  7.9421,  8.8398,  ...,  0.8183,  0.5038, -1.6011],\n",
      "         [17.3917,  7.8492,  8.6796,  ...,  0.4049, -0.4155, -0.5810],\n",
      "         [17.9481,  8.3115,  9.0427,  ...,  0.4565,  0.5320, -0.5646]],\n",
      "\n",
      "        [[ 8.3844,  7.5660, 12.4513,  ..., -1.4979, -1.6329, -3.1932],\n",
      "         [12.1152, 15.3984, 12.6425,  ...,  4.1624,  1.8320,  2.1036],\n",
      "         [11.8635, 14.4507, 12.8268,  ...,  5.8464,  2.4336,  2.3303],\n",
      "         ...,\n",
      "         [18.3585,  9.4376,  9.6349,  ...,  1.3786,  1.0767, -0.5872],\n",
      "         [18.4311, 10.3139,  9.6790,  ...,  1.9335,  0.7542, -0.4823],\n",
      "         [18.0470,  8.9850,  9.3636,  ...,  0.3665,  0.3306, -1.4163]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([[  101,    86,    96,     1,   104,    96,     9,    96,     1,    86,\n",
      "            96,     9,    96,     1,    86,   101,     9,   104,     3,    86,\n",
      "            96,     9,   100,    89,    22,    87,    23,     3,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,    86,   100,    89,    22,    87,    23,     9,     9,     1,\n",
      "            86,    96,     9,   100,    89,    22,   107,     8,     8,     8,\n",
      "            23,     1,    86,   100,    89,    22,    94,    10,    23,    23,\n",
      "             9,    96,     1,     1, 23464,     3,     3,   104,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  101,    86,    87,     9,    95,    89,    22,     8,     8,  5562,\n",
      "            23,     1,    86,    87,     9,    95,    89,    22,    87,     8,\n",
      "             8,    23,     1,    86,    87,     9,   101,     1,    86,    87,\n",
      "             9,    87,     3,   104,     9,   104,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,    96,     1,     1,   104,     1,     1,     1,     1,     3,\n",
      "             3,    86,    96,     9,     9,    89,    22,    94,    10,    10,\n",
      "            23,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,    86,   100,    89,    22,    94,    10,    10,    23,     9,\n",
      "            11,     1,   104,  5530,     1,    86,    96,     9,   100,    89,\n",
      "            22,    94,    10,    10,    23,     1,   116,    96,     9,    22,\n",
      "            87,    10,     9,     9,     3,    86,   100,    89,    22,    94,\n",
      "            10,    10,    23,     9,     3,     3,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,   116,    87,     9,    22,    94,    94,    23,    23,     1,\n",
      "            86,     1,     9,    87,     1,     1,  1295,    87,     1,    86,\n",
      "           101,     9,    95,    89,    22,    94,    10,    23,    23,     3,\n",
      "            86,    87,     9,    87,     3,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,    86,    87,     9,    95,    89,    22,    94,    10,    23,\n",
      "            23,     1,    86,    96,     9,    95,    89,    22,    87,     8,\n",
      "             8,    23,     1,    86,    96,     9,   100,    89,    22,    94,\n",
      "            10,    10,    23,     1,    86,   101,     9,    96,     3,    86,\n",
      "            87,     9,   101,     3,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [    2,    86,   104,     9,    96,     1,   104,     1,   104,     1,\n",
      "            86,    96,     9,   100,    89,    22,   107,     8,     8,     8,\n",
      "            23,     1,    86,    96,     9,    96,     3,    86,    87,     9,\n",
      "            87,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]], device='cuda:0')\n",
      "['rdx mov eax [UNK] call eax, eax [UNK] mov eax, eax [UNK] mov rdx, call [SEP] mov eax, dword ptr [ rax ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov dword ptr [ rax ],, [UNK] mov eax, dword ptr [ rip + + + ] [UNK] mov dword ptr [ rbp - ] ], eax [UNK] [UNK] [UNK] [SEP] [SEP] call [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', 'rdx mov rax, qword ptr [ + + 0x225cc ] [UNK] mov rax, qword ptr [ rax + + ] [UNK] mov rax, rdx [UNK] mov rax, rax [SEP] call, call [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] eax [UNK] [UNK] call [UNK] [UNK] [UNK] [UNK] [SEP] [SEP] mov eax,, ptr [ rbp - - ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov dword ptr [ rbp - - ], 0 [UNK] call 0x20e00 [UNK] mov eax, dword ptr [ rbp - - ] [UNK] lea eax, [ rax -,, [SEP] mov dword ptr [ rbp - - ], [SEP] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] lea rax, [ rbp rbp ] ] [UNK] mov [UNK], rax [UNK] [UNK] 0x35 rax [UNK] mov rdx, qword ptr [ rbp - ] ] [SEP] mov rax, rax [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rax, qword ptr [ rbp - ] ] [UNK] mov eax, qword ptr [ rax + + ] [UNK] mov eax, dword ptr [ rbp - - ] [UNK] mov rdx, eax [SEP] mov rax, rdx [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov call, eax [UNK] call [UNK] call [UNK] mov eax, dword ptr [ rip + + + ] [UNK] mov eax, eax [SEP] mov rax, rax [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "torch.Size([8, 64]) tensor([[   2,  104,  450,    1,  133,  151,    9,  151,    1,   86,  117,    9,\n",
      "          259,    1,   86,  101,    9,  260,    3,   86,  249,    9,  100,   89,\n",
      "           22,   87,   23,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  100,   89,   22,   87,   23,    9,  120,    1,   86,   96,\n",
      "            9,  100,   89,   22,  107,    8,  367,  361,   23,    1,  118,  100,\n",
      "           89,   22,   94,   10,  127,   23,    9,   96,    1,  512,  734,  316,\n",
      "            3,  209,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,  107,    8, 5562,   23,    1,\n",
      "           86,  117,    9,   95,   89,   22,   87,    8,  124,   23,    1,   86,\n",
      "           87,    9,  101,    1,  149,   87,    9,  117,    3,  104,  146,  239,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  165,    1,  119,  850,    1,  165,    1,  119,  850,    3,   86,\n",
      "          123,    9,   95,   89,   22,   94,   10,  135,   23,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  118,  100,   89,   22,   94,   10,  494,   23,    9,   11,    1,\n",
      "          274, 5530,    1,   86,   96,    9,  100,   89,   22,   94,   10,  494,\n",
      "           23,    1,  116,  194,    9,   22,   87,   10,   12,   23,    3,  118,\n",
      "          100,   89,   22,   94,   10,  437,   23,    9,   11,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  116,   87,    9,   22,   94,   10,  127,   23,    1,   86,  108,\n",
      "            9,   87,    1,  104, 1295,  186,    1,   86,  101,    9,   95,   89,\n",
      "           22,   94,   10,   19,   23,    3,   86,  123,    9,  117,    3,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   94,   10,  135,   23,    1,\n",
      "           86,  117,    9,   95,   89,   22,   87,    8,  146,   23,    1,   86,\n",
      "           96,    9,  100,   89,   22,   94,   10,  163,   23,    1,  154,  101,\n",
      "            9,   96,    3,   86,   87,    9,  101,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  164,    9,   12,    1,  104,  915,  263,    1,   86,   96,\n",
      "            9,  100,   89,   22,  107,    8,  870,  991,   23,    1,   86,  164,\n",
      "            9,   96,    3,   86,  108,    9,   87,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|███████████████████| 1022/1022 [02:40<00:00,  6.35it/s, loss=1.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.5434197651663405 0.5409757269887047 0.5525282277859598 0.5466909532483304 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 4: 100%|███████████████████| 1022/1022 [02:43<00:00,  6.24it/s, loss=1.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.5593199608610567 0.5576499388004896 0.5591556210112911 0.5584017649221719 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 5:  87%|█████████████████▍  | 890/1022 [02:22<00:23,  5.71it/s, loss=1.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 30522]) tensor([[[ 7.2367e+00,  9.6140e+00,  1.4405e+01,  ..., -3.7860e-01,\n",
      "          -2.1508e+00,  6.1996e-01],\n",
      "         [ 5.4465e+00,  7.6073e+00,  6.8403e+00,  ..., -5.0868e-01,\n",
      "          -1.6260e+00, -7.1499e-01],\n",
      "         [ 8.0273e+00,  8.6460e+00,  7.5630e+00,  ..., -1.0702e+00,\n",
      "          -1.4359e+00, -5.6456e+00],\n",
      "         ...,\n",
      "         [ 1.9372e+01,  9.3230e+00,  9.6650e+00,  ...,  1.5249e+00,\n",
      "           3.6203e-01, -1.1098e+00],\n",
      "         [ 1.9628e+01,  1.0529e+01,  1.0221e+01,  ...,  1.2275e+00,\n",
      "           4.2393e-02, -4.4877e-01],\n",
      "         [ 1.9168e+01,  9.7940e+00,  9.5270e+00,  ...,  5.7744e-01,\n",
      "           2.2575e-01,  1.5923e-01]],\n",
      "\n",
      "        [[ 6.1535e+00,  6.9113e+00,  1.2495e+01,  ..., -2.9739e+00,\n",
      "          -3.8914e+00, -2.3382e+00],\n",
      "         [ 9.5945e+00,  1.0114e+01,  1.0367e+01,  ...,  3.0028e+00,\n",
      "           1.4632e+00,  3.2904e+00],\n",
      "         [ 2.2412e+00,  2.9328e+00,  2.3903e+00,  ..., -3.5931e+00,\n",
      "          -4.3061e+00, -6.4464e+00],\n",
      "         ...,\n",
      "         [ 1.8696e+01,  9.2954e+00,  7.8926e+00,  ...,  8.1059e-01,\n",
      "          -2.5497e-01, -1.7764e+00],\n",
      "         [ 1.8259e+01,  8.5071e+00,  7.9529e+00,  ...,  8.4214e-01,\n",
      "          -6.9458e-01, -9.8381e-01],\n",
      "         [ 1.9500e+01,  9.2035e+00,  9.8049e+00,  ...,  1.0791e+00,\n",
      "          -3.5369e-01, -1.1344e+00]],\n",
      "\n",
      "        [[ 7.8090e+00,  8.5844e+00,  1.3296e+01,  ..., -1.1828e+00,\n",
      "          -1.0632e+00, -1.4298e+00],\n",
      "         [ 6.5314e+00,  7.2580e+00,  6.6723e+00,  ..., -1.1014e+00,\n",
      "          -2.3066e+00, -1.1547e+00],\n",
      "         [ 1.0101e+01,  9.5748e+00,  8.8438e+00,  ..., -6.2529e-01,\n",
      "          -7.9729e-01, -1.9687e+00],\n",
      "         ...,\n",
      "         [ 1.7449e+01,  9.2291e+00,  8.2569e+00,  ..., -7.1532e-01,\n",
      "           4.8776e-01, -3.2772e-01],\n",
      "         [ 1.9158e+01,  9.7094e+00,  9.9233e+00,  ...,  4.8552e-01,\n",
      "           2.0555e-02, -3.5938e-02],\n",
      "         [ 1.8958e+01,  1.0390e+01,  9.5182e+00,  ...,  9.4767e-01,\n",
      "           4.1370e-01, -3.9520e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.5793e+00,  7.6016e+00,  1.2578e+01,  ..., -2.4205e+00,\n",
      "          -2.0392e+00, -2.1950e+00],\n",
      "         [ 9.0858e+00,  1.0719e+01,  9.5409e+00,  ...,  1.8633e+00,\n",
      "           5.6678e-01, -2.8405e-01],\n",
      "         [ 9.1608e+00,  9.1097e+00,  9.7975e+00,  ...,  1.9084e+00,\n",
      "           2.1625e+00, -3.2156e+00],\n",
      "         ...,\n",
      "         [ 1.8439e+01,  8.3624e+00,  8.6325e+00,  ...,  9.1332e-01,\n",
      "           3.3117e-02, -8.2835e-01],\n",
      "         [ 1.8640e+01,  9.0669e+00,  8.9547e+00,  ...,  1.0557e+00,\n",
      "           1.2981e-01, -5.0912e-01],\n",
      "         [ 1.8328e+01,  8.3147e+00,  8.0085e+00,  ...,  6.7873e-01,\n",
      "          -7.1949e-01,  6.2955e-01]],\n",
      "\n",
      "        [[ 4.6178e+00,  5.9987e+00,  1.1293e+01,  ..., -3.5103e+00,\n",
      "          -4.2437e+00, -2.3667e+00],\n",
      "         [ 7.0942e+00,  7.9997e+00,  8.1932e+00,  ...,  3.3589e-01,\n",
      "          -1.8916e+00,  8.5460e-01],\n",
      "         [ 5.4287e+00,  5.7820e+00,  7.3362e+00,  ..., -1.5422e+00,\n",
      "          -3.7573e+00, -2.8456e+00],\n",
      "         ...,\n",
      "         [ 1.9036e+01,  9.6017e+00,  9.2488e+00,  ...,  1.6258e+00,\n",
      "           9.6344e-02, -3.0363e-01],\n",
      "         [ 1.8527e+01,  8.2861e+00,  8.6504e+00,  ...,  1.3726e+00,\n",
      "          -3.6093e-01, -7.3323e-01],\n",
      "         [ 1.7870e+01,  8.4532e+00,  8.0192e+00,  ...,  1.7761e-02,\n",
      "          -1.5824e+00, -5.5673e-01]],\n",
      "\n",
      "        [[ 8.0733e+00,  7.7383e+00,  1.3564e+01,  ...,  4.2814e-01,\n",
      "           6.0303e-01, -4.5691e-01],\n",
      "         [ 1.1231e+01,  1.2589e+01,  1.1290e+01,  ...,  3.8953e+00,\n",
      "           3.4282e+00, -9.2074e-01],\n",
      "         [ 8.2281e+00,  1.0794e+01,  1.0172e+01,  ...,  3.0083e+00,\n",
      "           3.7965e-01,  3.0557e-01],\n",
      "         ...,\n",
      "         [ 1.9254e+01,  9.5327e+00,  9.3420e+00,  ...,  1.0553e+00,\n",
      "          -3.7959e-01, -2.9251e-01],\n",
      "         [ 1.9175e+01,  9.1099e+00,  9.7285e+00,  ...,  1.8003e+00,\n",
      "           7.5079e-01,  9.7409e-02],\n",
      "         [ 1.9715e+01,  9.5850e+00,  1.0285e+01,  ...,  2.4864e+00,\n",
      "           8.4464e-01,  2.1761e-01]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[   2,   86,   87,    9,   95,   89,   22,   10,   10,  124,   23,    1,\n",
      "           86,  108,    9,   87,    1,  104,  104,  122,    1,   86,  100,   89,\n",
      "           22,   94,   10,  124,   23,    9,   96,    3,  104, 1890,  141,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  125, 1832,    1,   86,   96,    9,   11,    1,  104, 1833,    1,\n",
      "           86,   87,    9,   95,   89,   22,   94,   10,   19,   23,    3,  153,\n",
      "           87,    9,  129,   89,   22,   87,   23,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   96,    9,  100,   89,   22,   94,   10,   10,   23,    1,\n",
      "            3,    3,    3,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   95,   89,   22,   94,   10,   19,   23,    9,   11,    1,\n",
      "           86,  100,   89,   22,   94,   10,   19,   23,    9,   11,    1,   86,\n",
      "           95,   89,   22,   94,   10,   15,   23,    9,   11,    1,   86,  100,\n",
      "           89,   22,   94,   10,   15,   23,    9,   12,    3,   86,  100,   89,\n",
      "           22,   94,   10,   15,   23,    9,   12,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  164,    9,   12,    1,  104, 1896,  125,    1,   86,  100,\n",
      "           89,   22,  107,    8, 3106,  127,   23,    9,   96,    1,   86,   96,\n",
      "            9,   11,    3,  119,  104,   23,    3,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  104,  146,    1,    1,   86,  164,    9,   96,    1,  104, 1896,\n",
      "           23,    1,  104,  125,   15,    3,  153,   96,    9,  129,   89,   22,\n",
      "           87,   23,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  100,   89,   22,   94,   10,  134,   23,    9,   96,    1,\n",
      "           86, 1918, 2734,    1,   86,   96,    9,  100,   89,   22,  107,    8,\n",
      "         1161,  134,   23,    1,  116,   96,    9,   89,   94,   10,   19,   23,\n",
      "            3,   86,  123,    9,  101,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  119,  104,  141,    1,  118,  100,   89,   22,   94,   10,  124,\n",
      "           23,    9,  141,    1,  125,  125,  125,    1,  118,  100,   89,   22,\n",
      "           94,   10,  124,   23,    9,  122,    3,  104,  133,  139,    3,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n",
      "['[CLS] mov rax, qword ptr [ - - 0x18 ] [UNK] mov rdi, rax [UNK] call call rsp [UNK] mov dword ptr [ rbp - 0x18 ], eax [SEP] call 0x45 al [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] je 0xb2aa [UNK] mov eax, 0 [UNK] call 0xb2c4 [UNK] mov rax, qword ptr [ rbp - 8 ] [SEP] movzx rax, byte ptr [ rax ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov eax, dword ptr [ rbp - - ] [UNK] [SEP] [SEP] [SEP] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov qword ptr [ rbp - 8 ], 0 [UNK] mov dword ptr [ rbp - 8 ], 0 [UNK] mov qword ptr [ rbp - 4 ], 0 [UNK] mov dword ptr [ rbp - 4 ], 1 [SEP] mov dword ptr [ rbp - 4 ], 1 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov edi, 1 [UNK] call 0x37 je [UNK] mov dword ptr [ rip + 0xa65 0x10 ], eax [UNK] mov eax, 0 [SEP] jmp call ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] call 0x38 [UNK] [UNK] mov edi, eax [UNK] call 0x37 ] [UNK] call je 4 [SEP] movzx eax, byte ptr [ rax ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov dword ptr [ rbp - 0x20 ], eax [UNK] mov 0x5b88 [UNK] mov eax, dword ptr [ rip + 0xb5 0x20 ] [UNK] lea eax, ptr rbp - 8 ] [SEP] mov rsi, rdx [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] jmp call al [UNK] cmp dword ptr [ rbp - 0x18 ], al [UNK] je je je [UNK] cmp dword ptr [ rbp - 0x18 ], rsp [SEP] call test jne [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "torch.Size([8, 64]) tensor([[   2,   86,   87,    9,   95,   89,   22,   94,   10,  124,   23,    1,\n",
      "           86,  108,    9,   87,    1,  104, 1295,  300,    1,   86,  100,   89,\n",
      "           22,   94,   10,   15,   23,    9,   96,    3,  119, 1890,  262,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  125, 1832,    1,   86,   96,    9,   11,    1,  119, 1833,    1,\n",
      "           86,   87,    9,   95,   89,   22,   94,   10,   19,   23,    3,  153,\n",
      "           96,    9,  129,   89,   22,   87,   23,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   96,    9,  100,   89,   22,   94,   10,   15,   23,    1,\n",
      "          209,    3,  183,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   95,   89,   22,   94,   10,  497,   23,    9,   11,    1,\n",
      "           86,  100,   89,   22,   94,   10,  425,   23,    9,   11,    1,   86,\n",
      "           95,   89,   22,   94,   10,  228,   23,    9,   11,    1,   86,  100,\n",
      "           89,   22,   94,   10,  522,   23,    9,  335,    3,   86,  100,   89,\n",
      "           22,   94,   10,  436,   23,    9,   12,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  164,    9,   12,    1,  104, 1896,  191,    1,   86,  100,\n",
      "           89,   22,  107,    8, 3106,   64,   23,    9,   11,    1,   86,   96,\n",
      "            9,   11,    3,  119,  734,  725,    3,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  104,  146,  263,    1,   86,  164,    9,   96,    1,  104, 1896,\n",
      "          225,    1,  104,  815,  186,    3,  153,   96,    9,  129,   89,   22,\n",
      "           87,   23,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  100,   89,   22,   94,   10,  358,   23,    9,   96,    1,\n",
      "          119, 1918, 2734,    1,   86,   96,    9,  100,   89,   22,  107,    8,\n",
      "         1161,  282,   23,    1,  116,  120,    9,   22,   87,   10,   12,   23,\n",
      "            3,   86,  123,    9,  101,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  119,  307,  525,    1,  118,  100,   89,   22,   94,   10,  303,\n",
      "           23,    9,  447,    1,  125,  307,  422,    1,  118,  100,   89,   22,\n",
      "           94,   10,  303,   23,    9,  447,    3,  223,  307,  859,    3,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████████████| 1022/1022 [02:43<00:00,  6.26it/s, loss=0.797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.5798679060665362 0.57715527650326 0.586647029945999 0.5818624467437614 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 6: 100%|███████████████████| 1022/1022 [02:43<00:00,  6.26it/s, loss=1.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.6121575342465754 0.6119514009422267 0.6057928325969563 0.6088565437276428 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 7:  83%|███████████████▋   | 846/1022 [02:18<00:29,  5.97it/s, loss=0.921]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 30522]) tensor([[[  4.1424,   4.5533,  11.7281,  ...,  -4.3919,  -5.0579,  -5.4246],\n",
      "         [  5.5042,   6.7514,   6.0260,  ...,  -1.8720,  -3.3585,  -4.2302],\n",
      "         [ -2.4287,  -2.0654,   5.9629,  ...,  -9.1203,  -8.2882, -10.2356],\n",
      "         ...,\n",
      "         [ 19.4217,   7.7373,   8.7010,  ...,   0.3701,  -1.0872,  -1.7759],\n",
      "         [ 20.0670,   7.5697,   8.8537,  ...,   1.1417,   0.2217,  -1.8466],\n",
      "         [ 19.4400,   7.4982,   7.7865,  ...,   0.2047,  -0.4002,  -0.3591]],\n",
      "\n",
      "        [[  9.1899,  10.2686,  14.0625,  ...,  -3.9938,  -1.9636,   0.0339],\n",
      "         [ 10.7595,   9.7533,   9.8594,  ...,  -0.7128,   0.1037,  -0.4242],\n",
      "         [ 11.3194,  17.5215,   8.9193,  ...,   0.1410,   0.2254,   1.6356],\n",
      "         ...,\n",
      "         [ 20.0671,   9.3642,   9.8230,  ...,  -0.9108,  -0.8684,  -0.4978],\n",
      "         [ 20.1018,   9.9186,  10.0199,  ...,  -0.3380,  -0.2224,  -0.2030],\n",
      "         [ 20.2856,   9.4871,   9.4389,  ...,  -0.0267,   0.1887,  -1.2321]],\n",
      "\n",
      "        [[  7.9016,   7.1065,  14.5603,  ...,  -2.5256,  -1.9621,  -3.2696],\n",
      "         [  5.1279,   5.4015,   5.0368,  ...,  -1.5449,  -1.9150,  -0.8990],\n",
      "         [  7.8502,   8.0548,   6.0719,  ...,  -0.5998,  -0.2958,  -4.8950],\n",
      "         ...,\n",
      "         [ 18.9532,   6.3279,   7.8493,  ...,   0.2452,  -0.9124,  -1.4452],\n",
      "         [ 19.3329,   6.8496,   7.9576,  ...,   0.0794,  -0.7017,  -1.3282],\n",
      "         [ 19.7787,   7.7754,   9.4052,  ...,   0.1363,  -0.2085,  -1.6586]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  5.1140,   4.2655,  11.6171,  ...,  -3.5779,  -4.0170,  -5.3195],\n",
      "         [  6.9256,   6.1598,   6.4378,  ...,  -1.5197,  -2.3893,  -2.7626],\n",
      "         [  4.0778,   3.3874,  11.1255,  ...,  -4.8645,  -4.2297,  -5.9443],\n",
      "         ...,\n",
      "         [ 19.3116,   7.6198,   8.2835,  ...,   0.2000,  -0.4781,  -0.0431],\n",
      "         [ 19.4752,   6.9734,   8.2434,  ...,   0.2792,  -0.8744,  -0.2481],\n",
      "         [ 20.1237,   8.3825,   9.1908,  ...,   1.3557,   0.0462,  -0.7116]],\n",
      "\n",
      "        [[ 12.1167,   9.9933,  17.3701,  ...,   0.6040,   0.5915,  -0.4876],\n",
      "         [  4.5355,   6.6510,   6.4014,  ...,  -1.5151,  -2.9609,  -3.0619],\n",
      "         [  8.1396,  10.6474,   8.7354,  ...,   0.1077,  -0.9142,   0.7925],\n",
      "         ...,\n",
      "         [ 19.9983,   8.2135,   9.8665,  ...,   0.8924,  -0.0329,  -1.4247],\n",
      "         [ 19.5187,   7.1052,   9.2256,  ...,   1.3921,   0.0230,   0.2999],\n",
      "         [ 19.7409,   7.8265,   9.3744,  ...,   1.3028,   0.4518,  -1.0526]],\n",
      "\n",
      "        [[  6.2065,   6.3317,  13.4971,  ...,  -3.6776,  -3.1655,  -1.7385],\n",
      "         [  5.0423,   6.6993,   6.0287,  ...,  -1.0766,  -2.0797,  -1.8869],\n",
      "         [ 10.9130,   9.0297,   9.4043,  ...,  -0.2505,  -0.0382,  -4.7679],\n",
      "         ...,\n",
      "         [ 20.8948,   9.2015,  10.0014,  ...,   1.4998,  -0.0628,   0.8910],\n",
      "         [ 20.6860,   8.9783,  10.1619,  ...,   0.6490,  -0.4887,   1.0976],\n",
      "         [ 20.3562,   8.8603,   9.4427,  ...,   1.0633,  -0.5149,   0.1283]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([[   2,   86,  101,    9,   95,   89,   22,   94,   10,  124,   23,    1,\n",
      "           86,   87,    9,   95,   89,   22,   94,   10,   19,   23,    1,  115,\n",
      "           96,    9,  101,    1,  153,   96,    9,  129,   89,   22,   87,   23,\n",
      "            3,    3,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  180,    1,  162,   94,    1,   86,   94,    9,  122,    1,   86,\n",
      "          122,    9,  134,    3,   86,  108,    9,   87,    3,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   87,    8,   19,   23,    1,\n",
      "           89,   94,    3,  119, 1804,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,  122,    8,  202,   23,    1,\n",
      "           86,   95,   89,   22,   94,    8,  202,   23,    9,   87,    1,  125,\n",
      "           87,    9,   87,    1,   86,  101,    9,   95,   89,   22,  122,    8,\n",
      "          146,   23,    3,  149,  101,    9,   95,   89,   21,   21,   22,  135,\n",
      "           23,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  104,  104,    1,   86,  108,    9,   95,   89,   22,   94,   10,\n",
      "           19,   23,    1,   19,    3,   86,   87,    9,   95,   89,   22,   94,\n",
      "           10,   19,   23,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,    2,    9,   95,   89,   22,  107,    8,  134,   23,    1,\n",
      "           86,   87,    9,   95,   89,   22,  107,    8,   87,   23,    1,   86,\n",
      "           87,    9,   95,   89,   22,   87,    8,  124,   23,    1,  118,  101,\n",
      "            9,   87,    3,  104,   23,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  108,    9,   87,    1,  104,  104,   23,    9,  100,   89,\n",
      "           22,  107,    8, 4577,   23,    9,   11,    1,   86,  100,   89,   22,\n",
      "          107,    8, 4574,   23,    9,   11,    3,  119,  139, 1872,    3,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,  107,    8, 1158,  153,   23,\n",
      "            1,  116,  101,    9,   89,   94,   10,  269,   23,    1,   86,  123,\n",
      "            9,  101,    1,   86,  108,    9,   87,    3,   86,   96,    9,   11,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n",
      "['[CLS] mov rdx, qword ptr [ rbp - 0x18 ] [UNK] mov rax, qword ptr [ rbp - 8 ] [UNK] add eax, rdx [UNK] movzx eax, byte ptr [ rax ] [SEP] [SEP] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] endbr64 [UNK] push rbp [UNK] mov rbp, rsp [UNK] mov rsp, 0x20 [SEP] mov rdi, rax [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rax, qword ptr [ rax + 8 ] [UNK] ptr rbp [SEP] jmp 0x20079 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rax, qword ptr [ rsp + 0x30 ] [UNK] mov qword ptr [ rbp + 0x30 ], rax [UNK] je rax, rax [UNK] mov rdx, qword ptr [ rsp + 0x38 ] [SEP] sub rdx, qword ptr : : [ 0x28 ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] call call [UNK] mov rdi, qword ptr [ rbp - 8 ] [UNK] 8 [SEP] mov rax, qword ptr [ rbp - 8 ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov [CLS], qword ptr [ rip + 0x20 ] [UNK] mov rax, qword ptr [ rip + rax ] [UNK] mov rax, qword ptr [ rax + 0x18 ] [UNK] cmp rdx, rax [SEP] call ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rdi, rax [UNK] call call ], dword ptr [ rip + 0x250a7 ], 0 [UNK] mov dword ptr [ rip + 0x250a1 ], 0 [SEP] jmp jne4a [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rax, qword ptr [ rip + 0x72 movzx ] [UNK] lea rdx, ptr rbp - 0xb8 ] [UNK] mov rsi, rdx [UNK] mov rdi, rax [SEP] mov eax, 0 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "torch.Size([8, 64]) tensor([[   2,   86,  101,    9,   95,   89,   22,   94,   10,  124,   23,    1,\n",
      "           86,   87,    9,   95,   89,   22,   94,   10,   19,   23,    1,  115,\n",
      "           87,    9,  101,    1,  153,   96,    9,  129,   89,   22,   87,   23,\n",
      "            3,  183,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  180,    1,  162,   94,    1,   86,   94,    9,  122,    1,  149,\n",
      "          122,    9,  134,    3,   86,  108,    9,   87,    3,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   87,    8,   19,   23,    1,\n",
      "          200,   94,    3,  119, 1804,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,  122,    8,  202,   23,    1,\n",
      "           86,   95,   89,   22,  151,    8,  202,   23,    9,   87,    1,  233,\n",
      "           96,    9,   96,    1,   86,  101,    9,   95,   89,   22,  122,    8,\n",
      "          281,   23,    3,  149,  101,    9,   95,   89,  235,   21,   22,  135,\n",
      "           23,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  104,  304,    1,   86,  151,    9,   95,   89,   22,   94,   10,\n",
      "           19,   23,    1,  209,    3,   86,   87,    9,   95,   89,   22,   94,\n",
      "           10,  124,   23,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  101,    9,   95,   89,   22,   87,    8,  134,   23,    1,\n",
      "           86,   87,    9,   95,   89,   22,  107,    8, 2549,   23,    1,   86,\n",
      "           87,    9,   95,   89,   22,   87,    8,  124,   23,    1,  118,  101,\n",
      "            9,   87,    3,  381, 7590,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  108,    9,   87,    1,  104,  472,    1,   86,  100,   89,\n",
      "           22,  107,    8, 4577,   23,    9,   11,    1,   86,  100,   89,   22,\n",
      "          107,    8, 4574,   23,    9,   11,    3,  119,  367, 1872,    3,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,  107,    8, 1158,  227,   23,\n",
      "            1,  116,  101,    9,   22,   94,   10,  269,   23,    1,   86,  123,\n",
      "            9,  101,    1,   86,  108,    9,   87,    3,   86,   96,    9,   11,\n",
      "            3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|███████████████████| 1022/1022 [02:46<00:00,  6.14it/s, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.6556996086105675 0.6700891650905161 0.6087383406971035 0.6379421221864953 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 8: 100%|██████████████████| 1022/1022 [02:43<00:00,  6.26it/s, loss=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.6954500978473581 0.7125603864734299 0.6516936671575847 0.6807692307692308 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 9:  78%|██████████████▉    | 802/1022 [02:11<00:36,  6.09it/s, loss=0.828]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 30522]) tensor([[[ 5.6304e+00,  6.4579e+00,  1.3290e+01,  ..., -4.9492e+00,\n",
      "          -5.0249e+00, -3.8997e+00],\n",
      "         [ 6.1365e+00,  6.2229e+00,  6.6393e+00,  ..., -1.6513e+00,\n",
      "          -2.5229e+00, -2.2981e+00],\n",
      "         [ 2.0287e+00,  3.1292e+00,  4.6756e+00,  ..., -1.1575e+00,\n",
      "          -2.5772e+00, -1.4355e-01],\n",
      "         ...,\n",
      "         [ 2.1484e+01,  8.8481e+00,  9.8984e+00,  ...,  1.2335e+00,\n",
      "           2.3470e-01, -1.2952e+00],\n",
      "         [ 2.1613e+01,  8.6066e+00,  9.3327e+00,  ...,  1.0923e+00,\n",
      "           9.6563e-02, -1.2928e+00],\n",
      "         [ 2.0714e+01,  7.2457e+00,  8.0363e+00,  ..., -1.6116e-02,\n",
      "          -1.2907e+00, -1.4470e+00]],\n",
      "\n",
      "        [[ 5.5991e+00,  6.9773e+00,  1.3939e+01,  ..., -5.1234e+00,\n",
      "          -4.3282e+00, -4.1649e+00],\n",
      "         [ 7.9577e+00,  1.0550e+01,  8.4853e+00,  ...,  6.3294e-01,\n",
      "           4.6863e-01, -3.0525e+00],\n",
      "         [ 3.5847e+00,  7.2650e+00,  7.0779e+00,  ..., -1.8056e-02,\n",
      "          -1.2209e-01, -1.7025e+00],\n",
      "         ...,\n",
      "         [ 2.0704e+01,  7.6791e+00,  9.3849e+00,  ..., -8.2072e-01,\n",
      "          -7.0887e-01, -9.5427e-01],\n",
      "         [ 2.0000e+01,  6.6820e+00,  8.3965e+00,  ..., -2.4294e-01,\n",
      "          -1.7719e+00, -1.8540e+00],\n",
      "         [ 2.1030e+01,  9.2666e+00,  9.9729e+00,  ..., -8.5489e-01,\n",
      "          -1.6850e+00, -1.4884e+00]],\n",
      "\n",
      "        [[ 6.4462e+00,  7.4834e+00,  1.4087e+01,  ..., -4.8219e+00,\n",
      "          -4.2890e+00, -6.4963e+00],\n",
      "         [ 7.3390e+00,  8.4165e+00,  7.2923e+00,  ..., -2.0848e+00,\n",
      "          -2.5020e+00, -3.0800e+00],\n",
      "         [ 7.9436e+00,  5.6727e+00,  6.8667e+00,  ...,  6.3127e-01,\n",
      "          -1.0050e+00,  1.4592e-01],\n",
      "         ...,\n",
      "         [ 2.1027e+01,  8.7208e+00,  9.4927e+00,  ..., -2.4202e-01,\n",
      "           1.0618e-01, -1.8332e+00],\n",
      "         [ 2.1535e+01,  8.4950e+00,  9.4649e+00,  ...,  2.9565e-01,\n",
      "           4.0137e-01, -1.5986e+00],\n",
      "         [ 2.1366e+01,  8.7342e+00,  9.7781e+00,  ...,  3.0549e-01,\n",
      "          -4.9078e-01, -1.2456e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.7440e+00,  9.0221e+00,  1.4461e+01,  ..., -3.5858e+00,\n",
      "          -3.3624e+00, -4.7731e+00],\n",
      "         [ 5.1304e+00,  6.2084e+00,  6.3324e+00,  ..., -1.4159e+00,\n",
      "          -2.4579e+00, -1.4276e+00],\n",
      "         [ 8.1753e+00,  7.3698e+00,  6.0077e+00,  ..., -1.1117e+00,\n",
      "          -2.3813e+00, -5.5199e+00],\n",
      "         ...,\n",
      "         [ 2.0600e+01,  8.5002e+00,  9.5969e+00,  ..., -7.1801e-01,\n",
      "          -1.2661e+00, -2.5714e+00],\n",
      "         [ 1.9661e+01,  7.1947e+00,  8.6857e+00,  ..., -1.4754e+00,\n",
      "          -1.4534e+00, -2.4543e+00],\n",
      "         [ 2.0821e+01,  9.8840e+00,  9.1812e+00,  ...,  1.4865e-02,\n",
      "          -4.5161e-01, -6.8441e-01]],\n",
      "\n",
      "        [[ 6.9304e+00,  7.1351e+00,  1.3016e+01,  ..., -5.3498e+00,\n",
      "          -3.9735e+00, -1.4527e+00],\n",
      "         [ 8.8680e+00,  8.8643e+00,  9.8221e+00,  ..., -2.0234e+00,\n",
      "          -2.1013e+00,  1.2338e+00],\n",
      "         [ 8.5030e+00,  1.7542e+01,  7.7119e+00,  ..., -1.1142e+00,\n",
      "           4.0202e-01,  4.1020e-01],\n",
      "         ...,\n",
      "         [ 2.0872e+01,  9.9365e+00,  9.1670e+00,  ..., -1.0192e-01,\n",
      "          -1.0500e-01, -1.0220e+00],\n",
      "         [ 2.0124e+01,  7.7606e+00,  8.3191e+00,  ..., -2.8442e-01,\n",
      "          -2.9418e-01, -2.2129e-01],\n",
      "         [ 2.0678e+01,  9.8452e+00,  8.8173e+00,  ...,  6.7249e-01,\n",
      "          -3.2057e-01, -6.9397e-01]],\n",
      "\n",
      "        [[ 4.4537e+00,  5.3682e+00,  1.3620e+01,  ..., -4.8884e+00,\n",
      "          -3.6819e+00, -4.4732e+00],\n",
      "         [ 5.0790e+00,  6.6304e+00,  6.5076e+00,  ..., -3.2532e-01,\n",
      "          -1.5867e+00, -1.5496e+00],\n",
      "         [ 7.9248e+00,  8.6083e+00,  9.6733e+00,  ...,  1.0100e+00,\n",
      "           3.5013e-01,  4.7645e+00],\n",
      "         ...,\n",
      "         [ 2.0955e+01,  7.9434e+00,  9.3689e+00,  ...,  2.7219e-01,\n",
      "          -8.1581e-01, -2.0808e+00],\n",
      "         [ 2.1391e+01,  8.5958e+00,  9.9651e+00,  ...,  5.6379e-01,\n",
      "           2.8297e-02, -1.5899e+00],\n",
      "         [ 2.1315e+01,  9.2872e+00,  1.0110e+01,  ...,  1.0515e+00,\n",
      "          -2.3754e-01, -1.7670e+00]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[   2,   86,   95,   89,   22,   94,   10,  124,   23,    9,   87,    1,\n",
      "           86,  101,    9,   95,   89,   22,  107,    8, 2007,  124,   23,    1,\n",
      "           86,   86,   95,   95,   89,   22,   94,   10,  124,   23,    1,   86,\n",
      "          123,    9,  101,    3,   86,  108,    9,   87,    3,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  119,  119, 1286,    1,   86,   96,    9,  100,   89,   22,  107,\n",
      "            8, 1965,  127,   23,    1,  118,   96,    9,  180,    1,  139, 1543,\n",
      "          188,    3,   86,  108,    9,  108,    3,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   95,   89,   22,   94,   10,   19,   23,    9,   87,    1,\n",
      "          118,   95,   89,   22,   94,   10,   19,   23,    9,   87,    1,  104,\n",
      "          148,  125,    1,   86,   87,    9,   95,   89,   22,   94,   10,   19,\n",
      "           23,    3,  115,   87,    9,   12,    3,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  116,   87,    9,   22,  107,    8, 1294,  148,   23,    1,   86,\n",
      "          108,    9,   87,   22,  107,  104,  148,    1,   86,  120,    9,  100,\n",
      "           89,   22,  107,    8,   21, 2731,   23,    3,  116,   87,    9,   22,\n",
      "           94,   10,  202,   23,    3,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   94,   10,   19,   23,    1,\n",
      "           86,   95,   89,   22,   94,   10,   19,   23,    9,   87,    1,   86,\n",
      "           87,    9,   95,   89,   22,   94,   10,   19,   23,    1,   86,   95,\n",
      "           89,   22,   94,   10,  127,   23,    9,   87,    3,   86,   96,    9,\n",
      "          100,   89,   22,  107,    8, 5588,   23,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   96,    9,  100,   89,   22,   94,   10,  172,   23,    1,\n",
      "           86,  164,    9,   87,    1,  104,   12,    1,   86,   87,    9,   95,\n",
      "           89,   22,   94,   10,   15,   23,    3,  115,   87,    9,   12,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  180,    1,  162,   94,    1,   86,   94,    9,  122,    1,  149,\n",
      "          122,    9,  134,    3,   86,   95,   89,   22,   94,   10,  135,   23,\n",
      "            9,  134,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  164,    9,   11,    1,  104,  917,    1,   86,   87,    9,\n",
      "           95,   89,   22,   94,   10,  127,   23,    1,   86,  108,    9,   87,\n",
      "            3,  104,  108,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n",
      "['[CLS] mov qword ptr [ rbp - 0x18 ], rax [UNK] mov rdx, qword ptr [ rip + 0x77 0x18 ] [UNK] mov mov qword qword ptr [ rbp - 0x18 ] [UNK] mov rsi, rdx [SEP] mov rdi, rax [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] jmp jmpb6 [UNK] mov eax, dword ptr [ rip + 0xa2 0x10 ] [UNK] cmp eax, endbr64 [UNK] jne 0x57 0xa8 [SEP] mov rdi, rdi [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov qword ptr [ rbp - 8 ], rax [UNK] cmp qword ptr [ rbp - 8 ], rax [UNK] call 0xa je [UNK] mov rax, qword ptr [ rbp - 8 ] [SEP] add rax, 1 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] lea rax, [ rip + 0x41 0xa ] [UNK] mov rdi, rax [ rip call 0xa [UNK] mov edx, dword ptr [ rip + :e5 ] [SEP] lea rax, [ rbp - 0x30 ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rax, qword ptr [ rbp - 8 ] [UNK] mov qword ptr [ rbp - 8 ], rax [UNK] mov rax, qword ptr [ rbp - 8 ] [UNK] mov qword ptr [ rbp - 0x10 ], rax [SEP] mov eax, dword ptr [ rip + 0x25777 ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov eax, dword ptr [ rbp - 0x48 ] [UNK] mov edi, rax [UNK] call 1 [UNK] mov rax, qword ptr [ rbp - 4 ] [SEP] add rax, 1 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] endbr64 [UNK] push rbp [UNK] mov rbp, rsp [UNK] sub rsp, 0x20 [SEP] mov qword ptr [ rbp - 0x28 ], 0x20 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov edi, 0 [UNK] call 0x36 [UNK] mov rax, qword ptr [ rbp - 0x10 ] [UNK] mov rdi, rax [SEP] call rdi [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "torch.Size([8, 64]) tensor([[   2,   86,   95,   89,   22,   94,   10,  124,   23,    9,   87,    1,\n",
      "           86,  101,    9,   95,   89,   22,  107,    8, 2007, 1518,   23,    1,\n",
      "           86,   87,    9,   95,   89,   22,   94,   10,  124,   23,    1,   86,\n",
      "          123,    9,  101,    3,   86,  108,    9,   87,    3,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  119,  211, 1286,    1,   86,   96,    9,  100,   89,   22,  107,\n",
      "            8, 1965,  433,   23,    1,  118,   96,    9,   18,    1,  256, 1543,\n",
      "          277,    3,   86,  108,    9,   87,    3,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   95,   89,   22,   94,   10,   19,   23,    9,   87,    1,\n",
      "          118,   95,   89,   22,   94,   10,   19,   23,    9,   11,    1,  125,\n",
      "          732,  480,    1,   86,   87,    9,   95,   89,   22,   94,   10,   19,\n",
      "           23,    3,  115,   87,    9,   12,    3,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  116,   87,    9,   22,  107,    8, 1294,  475,   23,    1,   86,\n",
      "          108,    9,   87,    1,  104, 1183,  312,    1,   86,  120,    9,  100,\n",
      "           89,   22,  107,    8,  574, 2731,   23,    3,  116,   87,    9,   22,\n",
      "           94,   10,  202,   23,    3,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   94,   10,  124,   23,    1,\n",
      "           86,   95,   89,   22,   94,   10,   19,   23,    9,   87,    1,   86,\n",
      "           87,    9,   95,   89,   22,   94,   10,   19,   23,    1,   86,   95,\n",
      "           89,   22,   94,   10,  127,   23,    9,   87,    3,   86,   96,    9,\n",
      "          100,   89,   22,  107,    8, 5588,   23,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   96,    9,  100,   89,   22,   94,   10,  413,   23,    1,\n",
      "           86,  164,    9,   96,    1,  104,  431,    1,   86,   87,    9,   95,\n",
      "           89,   22,   94,   10,  285,   23,    3,  115,   96,    9,   12,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  180,    1,  162,   94,    1,   86,   94,    9,  122,    1,  149,\n",
      "          122,    9,  134,    3,   86,   95,   89,   22,   94,   10,  135,   23,\n",
      "            9,   87,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  164,    9,   11,    1,  104,  606,    1,   86,   87,    9,\n",
      "           95,   89,   22,   94,   10,  127,   23,    1,   86,  108,    9,   87,\n",
      "            3,  104,  650,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████████████| 1022/1022 [02:46<00:00,  6.15it/s, loss=0.682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.7388698630136986 0.7539952842546502 0.7064310260186549 0.7294386009377771 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 10: 100%|█████████████████| 1022/1022 [02:42<00:00,  6.29it/s, loss=0.797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.764554794520548 0.7906410603191777 0.7174766813942072 0.7522841333161755 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 11:  74%|█████████████▎    | 758/1022 [02:00<00:45,  5.85it/s, loss=0.518]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 30522]) tensor([[[ 4.8120,  4.2149, 11.0203,  ..., -6.6567, -4.9816, -5.7425],\n",
      "         [ 5.0032,  6.2727,  7.1272,  ...,  0.1404, -0.0703, -2.0883],\n",
      "         [ 6.7085,  4.8988,  5.8099,  ..., -0.6984, -1.0504, -3.1079],\n",
      "         ...,\n",
      "         [21.0035,  7.4241,  8.5138,  ..., -0.9447, -0.9265, -0.8267],\n",
      "         [21.9839,  7.6607,  9.4231,  ...,  0.7031, -0.1976, -1.4615],\n",
      "         [21.2325,  7.0218,  8.9304,  ..., -0.3440, -0.6520, -2.6210]],\n",
      "\n",
      "        [[ 5.9837,  4.5846, 13.4077,  ..., -4.8707, -4.3472, -5.7644],\n",
      "         [ 6.4231,  7.2978,  5.8957,  ..., -0.1557, -1.3648, -3.2416],\n",
      "         [ 7.8917, 10.7717,  7.8666,  ..., -1.0947,  0.4267,  0.1293],\n",
      "         ...,\n",
      "         [22.3188,  7.8779,  9.3309,  ...,  0.2682, -0.8682, -1.3427],\n",
      "         [21.9743,  7.7118,  9.6560,  ...,  0.3294, -1.1131, -0.5805],\n",
      "         [21.9701,  8.1777,  9.8869,  ...,  0.7213, -0.2708, -2.2278]],\n",
      "\n",
      "        [[ 7.3035,  6.6807, 14.6755,  ..., -3.7945, -3.4048, -1.3631],\n",
      "         [ 7.0885,  6.5668,  7.9420,  ..., -0.7891, -1.5093, -0.0370],\n",
      "         [ 9.1204,  7.1202,  6.5975,  ..., -1.9076, -0.6631, -2.3752],\n",
      "         ...,\n",
      "         [22.3141,  8.6580,  9.9310,  ...,  0.8338, -0.4907, -0.4952],\n",
      "         [22.2933,  8.6320,  9.5209,  ...,  0.5223, -0.0642, -1.1664],\n",
      "         [21.4537,  8.3497,  9.0867,  ..., -0.5854, -0.5955,  0.1125]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.1707,  4.0594, 11.4830,  ..., -5.2028, -4.3456, -5.6310],\n",
      "         [ 5.2138,  6.8069,  5.8712,  ..., -1.1133, -2.2100, -0.1013],\n",
      "         [ 6.8811,  5.4046,  5.1467,  ..., -0.9351, -0.8441, -2.4380],\n",
      "         ...,\n",
      "         [21.6016,  7.6366,  9.3902,  ..., -0.3778, -1.0405, -1.6677],\n",
      "         [21.8614,  8.5347, 10.1180,  ..., -0.3417, -0.8483, -1.2617],\n",
      "         [21.9077,  8.7111,  9.8489,  ...,  0.5560, -0.6641, -1.0195]],\n",
      "\n",
      "        [[ 6.5178,  7.3282, 15.1776,  ..., -2.7288, -2.5699, -2.0332],\n",
      "         [ 6.1108,  7.2193,  6.5023,  ...,  0.3435, -1.5109, -0.4315],\n",
      "         [ 8.8394, 10.9038,  8.3728,  ...,  0.2593,  0.5109, -0.3918],\n",
      "         ...,\n",
      "         [22.0464,  7.6980,  9.5032,  ..., -0.1924, -0.5337, -0.1416],\n",
      "         [23.2786,  9.8959,  9.9130,  ...,  1.5098,  0.4382, -0.5343],\n",
      "         [21.5310,  7.2523,  8.9912,  ..., -0.1588, -1.5370, -1.2977]],\n",
      "\n",
      "        [[ 6.8000,  7.2124, 13.6433,  ..., -4.1618, -3.7005, -2.2655],\n",
      "         [ 4.2644,  5.7004,  5.4842,  ..., -1.1653, -2.7113, -1.5293],\n",
      "         [ 8.1142,  7.3217,  6.3264,  ..., -0.1856, -1.1367, -2.3152],\n",
      "         ...,\n",
      "         [22.3284,  8.8501,  9.9603,  ...,  0.7021, -0.8232, -0.2804],\n",
      "         [22.6095,  9.4700,  9.7464,  ...,  1.1605, -0.4501, -1.5099],\n",
      "         [23.0167,  9.4906, 10.1866,  ...,  1.3222, -0.2749, -0.4762]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([[   2,  159,   87,    9,   15,    1,  115,   87,    9,  123,    1,   86,\n",
      "           95,   89,   22,   87,    8,   19,   23,    9,  101,    1,   86,   96,\n",
      "            9,  100,   89,   22,   94,   10,  235,   23,    3,   86,  164,    9,\n",
      "           96,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  108,    9,   87,    1,  104,  917,    1,   86,   95,   89,\n",
      "           22,   94,   10,  172,   23,    9,   87,    1,  115,   95,   89,   22,\n",
      "           94,   10,  172,   23,    9,   12,    3,   86,   87,    9,   95,   89,\n",
      "           22,   94,   10,  172,   23,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,  107,    8, 4423,   23,    1,\n",
      "           86,  155,    9,   87,    1,   86,  108,    9,   87,    1,  104,  164,\n",
      "            3,   86,   87,    9,  100,   89,   22,  107,    8, 4611,   23,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  104,  122,    9,  134,    1,   86,   95,   89,   22,   94,   10,\n",
      "           15,   23,    9,  108,    1,   86,  100,   89,   22,   94,   10,  188,\n",
      "           23,    9,  155,    1,   86,  100,   89,   22,   94,   10,   19,   23,\n",
      "            9,  120,    3,  118,  120,    9,   96,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  155,    9,  134,    1,   86,  108,    9,   87,    1,  104,\n",
      "          180,    1,   86,   96,    9,   87,    3,   86,   96,    9,  100,   89,\n",
      "           22,   94,   10,  140,   23,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   87,    8,   19,   23,    1,\n",
      "           86,   94,    3,  119, 1804,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  108,    9,   87,    1,  104,  108,    1,   86,   95,   89,\n",
      "           22,   94,   10,  236,   23,    9,   87,    1,   86,   87,    9,   95,\n",
      "           89,   22,   94,   10,  231,   23,    3,   86,  174,    9,  100,   89,\n",
      "           22,  107,    8,   15,   23,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   94,   10,   19,   23,    1,\n",
      "           86,  108,    9,   87,    1,  104,   87,    1,  115,   87,    9,   13,\n",
      "            3,   86,    9,    9,   12,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n",
      "['[CLS] shl rax, 4 [UNK] add rax, rsi [UNK] mov qword ptr [ rax + 8 ], rdx [UNK] mov eax, dword ptr [ rbp - fs ] [SEP] mov edi, eax [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rdi, rax [UNK] call 0x36 [UNK] mov qword ptr [ rbp - 0x48 ], rax [UNK] add qword ptr [ rbp - 0x48 ], 1 [SEP] mov rax, qword ptr [ rbp - 0x48 ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rax, qword ptr [ rip + 0x15018 ] [UNK] mov esi, rax [UNK] mov rdi, rax [UNK] call edi [SEP] mov rax, dword ptr [ rip + 0x14065 ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] call rsp, 0x20 [UNK] mov qword ptr [ rbp - 4 ], rdi [UNK] mov dword ptr [ rbp - 0xa8 ], esi [UNK] mov dword ptr [ rbp - 8 ], edx [SEP] cmp edx, eax [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov esi, 0x20 [UNK] mov rdi, rax [UNK] call endbr64 [UNK] mov eax, rax [SEP] mov eax, dword ptr [ rbp - 0x24 ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rax, qword ptr [ rax + 8 ] [UNK] mov rbp [SEP] jmp 0x20079 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rdi, rax [UNK] call rdi [UNK] mov qword ptr [ rbp - 0x60 ], rax [UNK] mov rax, qword ptr [ rbp - 0x70 ] [SEP] mov ecx, dword ptr [ rip + 4 ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rax, qword ptr [ rbp - 8 ] [UNK] mov rdi, rax [UNK] call rax [UNK] add rax, 2 [SEP] mov,, 1 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "torch.Size([8, 64]) tensor([[   2,  159,   87,    9,   15,    1,  115,   87,    9,  123,    1,   86,\n",
      "           95,   89,   22,   87,    8,   19,   23,    9,  101,    1,   86,   96,\n",
      "            9,  100,   89,   22,   94,   10,  576,   23,    3,   86,  164,    9,\n",
      "           96,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  108,    9,   87,    1,  104,  684,    1,   86,   95,   89,\n",
      "           22,   94,   10,  172,   23,    9,   87,    1,  115,   95,   89,   22,\n",
      "           94,   10,  172,   23,    9,   12,    3,   86,   87,    9,   95,   89,\n",
      "           22,   94,   10,  172,   23,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,  107,    8, 4423,   23,    1,\n",
      "           86,  155,    9,   11,    1,   86,  108,    9,   87,    1,  104,  550,\n",
      "            3,   86,  120,    9,  100,   89,   22,  107,    8, 4611,   23,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  149,  122,    9,  497,    1,   86,   95,   89,   22,   94,   10,\n",
      "          280,   23,    9,  108,    1,   86,  100,   89,   22,   94,   10,  408,\n",
      "           23,    9,  155,    1,   86,  100,   89,   22,   94,   10,  419,   23,\n",
      "            9,  120,    3,  118,  120,    9,   96,    3,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  155,    9,  134,    1,   86,  108,    9,   87,    1,  104,\n",
      "          472,    1,   86,   96,    9,  148,    3,  149,   96,    9,  100,   89,\n",
      "           22,   94,   10,  766,   23,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   87,    8,   19,   23,    1,\n",
      "          200,   94,    3,  119, 1804,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,  108,    9,   87,    1,  104,  237,    1,   86,   95,   89,\n",
      "           22,   94,   10,  236,   23,    9,   87,    1,   86,   87,    9,   95,\n",
      "           89,   22,   94,   10,  231,   23,    3,   86,  489,    9,  100,   89,\n",
      "           22,   87,    8,   15,   23,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   94,   10,  146,   23,    1,\n",
      "           86,  108,    9,   87,    1,  104,  206,    1,  115,   87,    9,   13,\n",
      "            3,   86,  164,    9,   12,    3,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|█████████████████| 1022/1022 [02:42<00:00,  6.28it/s, loss=0.793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.7969667318982387 0.8159685863874345 0.7650957290132547 0.7897137066126172 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 12: 100%|█████████████████| 1022/1022 [02:46<00:00,  6.13it/s, loss=0.514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.8165362035225049 0.8358559498956158 0.7862052037309769 0.810270680495826 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 13:  70%|████████████▌     | 714/1022 [01:53<00:49,  6.20it/s, loss=0.916]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 30522]) tensor([[[ 5.7142e+00,  5.5387e+00,  1.4037e+01,  ..., -4.8681e+00,\n",
      "          -5.1514e+00, -3.2522e+00],\n",
      "         [ 7.3290e+00,  1.0198e+01,  8.3858e+00,  ..., -1.1615e+00,\n",
      "          -1.2777e+00, -1.9209e+00],\n",
      "         [ 7.8848e+00,  5.7219e+00,  5.5768e+00,  ..., -8.7830e-01,\n",
      "          -1.3330e+00, -4.9574e+00],\n",
      "         ...,\n",
      "         [ 2.1396e+01,  6.3404e+00,  8.4142e+00,  ..., -5.1657e-01,\n",
      "          -1.8638e+00, -1.9525e+00],\n",
      "         [ 2.2452e+01,  7.3527e+00,  9.1214e+00,  ...,  5.9530e-01,\n",
      "          -1.0197e+00, -8.3408e-01],\n",
      "         [ 2.2257e+01,  6.7903e+00,  8.9188e+00,  ...,  1.1242e-01,\n",
      "          -1.7431e+00, -1.0996e+00]],\n",
      "\n",
      "        [[ 4.2575e+00,  7.0059e+00,  1.5569e+01,  ..., -3.0375e+00,\n",
      "          -2.2087e+00, -2.0360e+00],\n",
      "         [ 7.7110e+00,  8.9956e+00,  9.8084e+00,  ..., -1.9622e+00,\n",
      "          -1.3425e+00, -1.4067e+00],\n",
      "         [ 1.9427e+00,  5.0660e+00,  5.7174e+00,  ..., -1.6608e+00,\n",
      "          -1.8409e+00, -4.9501e+00],\n",
      "         ...,\n",
      "         [ 2.2940e+01,  9.6309e+00,  1.0798e+01,  ...,  3.7565e-01,\n",
      "           2.4634e-02,  4.3817e-01],\n",
      "         [ 2.2554e+01,  8.8824e+00,  1.0059e+01,  ...,  1.6408e-01,\n",
      "          -5.4987e-01, -1.0655e+00],\n",
      "         [ 2.3023e+01,  9.1791e+00,  9.8756e+00,  ...,  5.8815e-01,\n",
      "          -4.1097e-01, -1.2511e+00]],\n",
      "\n",
      "        [[ 7.6107e+00,  8.3668e+00,  1.6275e+01,  ..., -3.2976e+00,\n",
      "          -2.5829e+00, -4.9016e-01],\n",
      "         [ 5.8076e+00,  5.9469e+00,  7.5454e+00,  ..., -2.0285e+00,\n",
      "          -2.7801e+00,  1.0110e+00],\n",
      "         [ 4.4404e+00,  5.6924e+00,  6.3290e+00,  ...,  8.6518e-03,\n",
      "          -9.7763e-01,  8.7280e-01],\n",
      "         ...,\n",
      "         [ 2.3496e+01,  1.1191e+01,  1.1355e+01,  ...,  9.3193e-01,\n",
      "           1.0241e+00, -1.9965e+00],\n",
      "         [ 2.3008e+01,  9.4512e+00,  1.0761e+01,  ...,  1.2369e+00,\n",
      "           3.4072e-01,  3.3370e-01],\n",
      "         [ 2.2979e+01,  1.1120e+01,  1.0941e+01,  ...,  4.6440e-01,\n",
      "          -7.6907e-02, -2.1963e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 6.4547e+00,  6.3189e+00,  1.4133e+01,  ..., -4.2803e+00,\n",
      "          -3.9031e+00, -1.0500e+00],\n",
      "         [ 8.6230e+00,  8.5471e+00,  1.0865e+01,  ..., -1.7621e+00,\n",
      "          -2.1544e+00, -2.6609e+00],\n",
      "         [ 9.9530e+00,  7.8390e+00,  1.0767e+01,  ..., -2.6844e+00,\n",
      "          -3.7732e+00, -5.3665e+00],\n",
      "         ...,\n",
      "         [ 2.0746e+01,  8.1185e+00,  1.1801e+01,  ...,  8.9886e-01,\n",
      "          -8.1522e-01, -8.8250e-01],\n",
      "         [ 2.2241e+01,  8.8354e+00,  1.2081e+01,  ...,  2.3982e-01,\n",
      "           1.3886e-01, -2.2357e+00],\n",
      "         [ 2.1928e+01,  9.4678e+00,  1.2352e+01,  ...,  4.1753e-01,\n",
      "          -2.0587e-01, -9.8114e-01]],\n",
      "\n",
      "        [[ 3.7703e+00,  4.5600e+00,  1.2392e+01,  ..., -5.2732e+00,\n",
      "          -5.1086e+00, -6.9435e+00],\n",
      "         [ 6.4121e+00,  7.2242e+00,  6.9185e+00,  ..., -1.8460e+00,\n",
      "          -2.1638e+00, -2.1286e+00],\n",
      "         [ 5.6351e+00,  4.1687e+00,  4.8943e+00,  ..., -1.6304e+00,\n",
      "          -1.3143e+00, -4.4003e+00],\n",
      "         ...,\n",
      "         [ 2.1744e+01,  6.6135e+00,  8.7644e+00,  ...,  8.9510e-02,\n",
      "          -1.1661e+00, -2.0793e+00],\n",
      "         [ 2.2488e+01,  7.5839e+00,  9.8747e+00,  ..., -6.5185e-01,\n",
      "          -1.5923e+00, -2.4168e+00],\n",
      "         [ 2.1316e+01,  7.2747e+00,  8.4025e+00,  ..., -9.5497e-01,\n",
      "          -2.0085e+00, -3.4116e+00]],\n",
      "\n",
      "        [[ 4.8559e+00,  6.5068e+00,  1.3205e+01,  ..., -5.3031e+00,\n",
      "          -4.4821e+00, -1.5461e+00],\n",
      "         [ 8.9341e+00,  9.0317e+00,  1.0047e+01,  ..., -9.2775e-01,\n",
      "          -1.2354e+00,  1.5614e-01],\n",
      "         [ 8.7308e+00,  1.6055e+01,  9.8559e+00,  ..., -6.0169e-01,\n",
      "          -3.4554e-01, -3.4047e+00],\n",
      "         ...,\n",
      "         [ 2.2572e+01,  1.1034e+01,  9.7863e+00,  ..., -3.7178e-01,\n",
      "           2.1051e-01, -4.0183e-01],\n",
      "         [ 2.2715e+01,  1.0377e+01,  1.0547e+01,  ...,  8.6633e-01,\n",
      "           7.5109e-01,  1.4804e-01],\n",
      "         [ 2.2384e+01,  1.0004e+01,  1.0461e+01,  ...,  3.3940e-01,\n",
      "           3.6363e-01,  2.8614e-01]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[   2,  115,   87,    9,  101,    1,   86,  108,    9,   87,    1,  104,\n",
      "          237,    1,   86,   95,   89,   22,   94,   10,  135,   23,    9,   87,\n",
      "            3,   86,   87,    9,   95,   89,   22,   94,   10,  253,   23,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  125,  104,  188,    1,   86,   87,    9,   10,   12,    1,  119,\n",
      "          188,  183,    1,   86,   96,    9,   11,    3,   12,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   95,   89,   22,   94,   10,  228,   23,    9,   87,    1,\n",
      "           86,   87,    9,   95,   89,   22,  107,    8, 5219,   23,    1,   86,\n",
      "          108,    9,   87,    1,  104,  108,    3,  104,  207,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   87,    8,  199,   23,    1,\n",
      "          115,   87,    9,   23,    1,   86,  108,    9,   87,    1,  104,  237,\n",
      "            3,  104,  104,  917,    3,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   95,   89,   22,   94,   10,  202,   23,    9,   86,    1,\n",
      "           86,  100,   89,   22,   94,   10,  265,   23,    9,  120,    1,   86,\n",
      "           87,    9,   95,   89,  235,   22,   22,  135,   23,    1,   86,   95,\n",
      "           89,   22,   94,   10,   19,   23,    9,   87,    3,   86,  123,    9,\n",
      "          117,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,    3,    3,   86,   87,    9,   95,   89,   22,   94,   10,   19,\n",
      "           23,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   94,   10,  207,   23,    1,\n",
      "          115,   87,    9,  101,    1,   86,   87,    9,   95,   89,   22,   87,\n",
      "           23,    1,  133,   87,    9,   87,    3,   86,  155,    9,  134,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  180,    1,  162,   94,    1,   86,   94,    9,  122,    1,  162,\n",
      "          151,    3,   86,  108,    9,   12,    3,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n",
      "['[CLS] add rax, rdx [UNK] mov rdi, rax [UNK] call 0x24650 [UNK] mov qword ptr [ rbp - 0x28 ], rax [SEP] mov rax, qword ptr [ rbp - 0x80 ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] je call 0xa8 [UNK] mov rax, - 1 [UNK] jmp 0xa8 ret [UNK] mov eax, 0 [SEP] 1 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov qword ptr [ rbp - 0xc0 ], rax [UNK] mov rax, qword ptr [ rip + 0x25e1d ] [UNK] mov rdi, rax [UNK] call rdi [SEP] call 0x50 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rax, qword ptr [ rax + 0x40 ] [UNK] add rax, ] [UNK] mov rdi, rax [UNK] call 0x24650 [SEP] call call 0x36 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov qword ptr [ rbp - 0x30 ], mov [UNK] mov dword ptr [ rbp - 0x34 ], edx [UNK] mov rax, qword ptr fs [ [ 0x28 ] [UNK] mov qword ptr [ rbp - 8 ], rax [SEP] mov rsi, rcx [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] [SEP] [SEP] mov rax, qword ptr [ rbp - 8 ] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] mov rax, qword ptr [ rbp - 0x50 ] [UNK] add rax, rdx [UNK] mov rax, qword ptr [ rax ] [UNK] test rax, rax [SEP] mov esi, 0x20 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] endbr64 [UNK] push rbp [UNK] mov rbp, rsp [UNK] push rbx [SEP] mov rdi, 1 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "torch.Size([8, 64]) tensor([[   2,  115,   87,    9,  101,    1,   86,  108,    9,   87,    1,  104,\n",
      "          237,    1,   86,   95,   89,   22,   94,   10,  135,   23,    9,   87,\n",
      "            3,   86,   87,    9,   95,   89,   22,   94,   10,  253,   23,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  125,  824,  191,    1,   86,   87,    9,   10,   12,    1,  119,\n",
      "          824,  590,    1,   86,   96,    9,   11,    3,  209,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   95,   89,   22,   94,   10,  228,   23,    9,   87,    1,\n",
      "           86,   87,    9,   95,   89,   22,  107,    8, 5219,   23,    1,   86,\n",
      "          108,    9,   87,    1,  104,  523,    3,  104,  355,    3,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   87,    8,  281,   23,    1,\n",
      "          115,   87,    9,   12,    1,   86,  108,    9,   87,    1,  104,  237,\n",
      "            3,  104,  917,  226,    3,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   95,   89,   22,   94,   10,  202,   23,    9,  123,    1,\n",
      "           86,  100,   89,   22,   94,   10,  265,   23,    9,  120,    1,   86,\n",
      "           87,    9,   95,   89,  235,   21,   22,  135,   23,    1,   86,   95,\n",
      "           89,   22,   94,   10,   19,   23,    9,   87,    3,   86,  123,    9,\n",
      "          117,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  209,    3,   86,   87,    9,   95,   89,   22,   94,   10,   19,\n",
      "           23,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,   86,   87,    9,   95,   89,   22,   94,   10,  676,   23,    1,\n",
      "          115,   87,    9,  101,    1,   86,   87,    9,   95,   89,   22,   87,\n",
      "           23,    1,  133,   87,    9,   87,    3,   86,  155,    9,  134,    3,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0],\n",
      "        [   2,  180,    1,  162,   94,    1,   86,   94,    9,  122,    1,  162,\n",
      "          151,    3,   86,  164,    9,   12,    3,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|███████████████████| 1022/1022 [02:42<00:00,  6.29it/s, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  0.8408757338551859 0.8572532852357639 0.8166421207658321 0.8364550597108735 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1022 [00:00<?, ?it/s]/tmp/ipykernel_171369/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 14:   0%|                    | 5/1022 [00:00<02:38,  6.40it/s, loss=0.468]"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=5e-6)\n",
    "\n",
    "\n",
    "\n",
    "epochs = 1000\n",
    "counter = 0\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    \n",
    "    instruction_predictions_all, instruction_ground_truths_all = None, None\n",
    "    token_predictions_all, token_ground_truths_all = None, None\n",
    "    \n",
    "    # activate training mode\n",
    "    model.train()\n",
    "    for N,batch in enumerate(train_loop):\n",
    "\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        next_sentence_label=next_sentence_label,\n",
    "                        labels=labels)\n",
    "\n",
    "\n",
    "        token_prediction = torch.argmax(outputs.prediction_logits, axis=-1)\n",
    "\n",
    "        \n",
    "        token_prediction = token_prediction.detach().cpu().numpy().flatten()\n",
    "        token_ground_truth = labels.detach().cpu().numpy().flatten()\n",
    "        \n",
    "        counter+=1\n",
    "        if counter%2000==0 and counter!=0:\n",
    "            \n",
    "            print(outputs.prediction_logits.shape, outputs.prediction_logits)\n",
    "            print(torch.argmax(outputs.prediction_logits, axis=-1))\n",
    "\n",
    "            print(tokenizer.batch_decode(torch.argmax(outputs.prediction_logits, axis=-1)))\n",
    "\n",
    "            print(labels.shape , labels)\n",
    "            \n",
    "        \n",
    "        \n",
    "        instruction_prediction = torch.argmax(outputs.seq_relationship_logits, axis=-1)\n",
    "        instruction_prediction   = instruction_prediction.detach().cpu().numpy().flatten()\n",
    "        instruction_ground_truth = next_sentence_label.detach().cpu().numpy().flatten()\n",
    "        \n",
    "        if N==0:\n",
    "            instruction_predictions_all   = instruction_prediction\n",
    "            instruction_ground_truths_all = instruction_ground_truth\n",
    "            \n",
    "            token_predictions_all         = token_prediction\n",
    "            token_ground_truths_all       = token_ground_truth  \n",
    "        else:\n",
    "            instruction_predictions_all   = np.concatenate((instruction_predictions_all, instruction_prediction))\n",
    "            instruction_ground_truths_all = np.concatenate((instruction_ground_truths_all, instruction_ground_truth))\n",
    "            token_predictions_all   = np.concatenate((token_predictions_all, token_prediction))\n",
    "            token_ground_truths_all = np.concatenate((token_ground_truths_all, token_ground_truth))\n",
    "            \n",
    "\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        train_loop.set_description(f'Epoch {epoch}')\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    \n",
    "    instruction_accuracy = (accuracy_score(instruction_ground_truths_all,instruction_predictions_all))\n",
    "    instruction_precision, instruction_recall, instruction_f1, _ = precision_recall_fscore_support(instruction_ground_truths_all,instruction_predictions_all, average='binary')\n",
    "    print(\"Training: \", instruction_accuracy, instruction_precision, instruction_recall, instruction_f1, _)\n",
    "    \n",
    "    \n",
    "    ### EVAL Validation\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         v_predictions_all, v_ground_truths_all = None, None\n",
    "#         validation_loop = tqdm(validation_loader, leave=True)\n",
    "#         for N,v_batch in enumerate(validation_loop):\n",
    "#             v_input_ids = v_batch['input_ids'].to(device)\n",
    "#             v_attention_mask = v_batch['attention_mask'].to(device)\n",
    "#             v_token_type_ids = v_batch['token_type_ids'].to(device)\n",
    "#             v_labels = v_batch['labels'].to(device)\n",
    "#             # process\n",
    "#             v_outputs = model(v_input_ids, attention_mask=v_attention_mask,\n",
    "#                             token_type_ids=v_token_type_ids,\n",
    "#                             labels=v_labels)\n",
    "#             v_prediction = torch.argmax(v_outputs.logits, axis=-1)\n",
    "#             v_prediction = v_prediction.detach().cpu().numpy().flatten()\n",
    "#             v_ground_truth = v_labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "#             if N==0:\n",
    "#                 v_predictions_all = v_prediction\n",
    "#                 v_ground_truths_all = v_ground_truth\n",
    "#             else:\n",
    "#                 v_predictions_all   = np.concatenate((v_predictions_all, v_prediction))\n",
    "#                 v_ground_truths_all = np.concatenate((v_ground_truths_all, v_ground_truth))\n",
    "\n",
    "#         v_accuracy = (accuracy_score(v_ground_truths_all, v_predictions_all))\n",
    "#         v_precision, v_recall, v_f1, _ = precision_recall_fscore_support(v_ground_truths_all, \n",
    "#                                                                          v_predictions_all, average='binary')\n",
    "#         print(\"VALIDATION: \",v_accuracy, v_precision, v_recall, v_f1, _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the trained model weights\n",
    "# training_model.save_weights(\"weights/wghts\" + str(epoch + 1) + \".ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
