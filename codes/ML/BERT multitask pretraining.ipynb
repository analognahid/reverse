{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af388b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahid/anaconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de072e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os, pickle\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import BertForMaskedLM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "with (open('DFGDATA.pkl' , \"rb\")) as openfile:\n",
    "    all_input_list , all_label_list = pickle.load(openfile)\n",
    "\n",
    "\n",
    "# input_text = [\"I love apples.\", \"She hates oranges.\", \"I enjoy reading books.\", \"He likes playing football.\"]\n",
    "\n",
    "# labels_task1 = [0, 1,0,1]  # Example task 1 labels\n",
    "# labels_task2 = [2, 3,4,5]  # Example task 2 labels\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "input_text = all_input_list#[:180]\n",
    "labels_dfg = all_label_list#[:180]\n",
    "\n",
    "labels_dfg =  torch.LongTensor(labels_dfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a256faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE :  10000\n"
     ]
    }
   ],
   "source": [
    "tokenizer  = BertTokenizer.from_pretrained(\"./multytask-tokenizer\")\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "\n",
    "print('VOCAB SIZE : ', (tokenizer.vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8755564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# tokenizer.eos_token = \"<EOI>\"\n",
    "\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac256125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_collator(input_text_task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88bd9a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO fix inputs = tokenizer(history, next_instruction, return_tensors='pt', \n",
    "#                    max_length=64, truncation=True, padding='max_length')\n",
    "\n",
    "# Tokenize input text\n",
    "inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors='pt',)\n",
    "# encoded_inputs_task2 = tokenizer(input_text_task2, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7b32b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 100, 3], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('LOOK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c82fd9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels_dfg'] = labels_dfg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f369c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLM\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "\n",
    "\n",
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "        (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "\n",
    "#TODO FIX 101, 102\n",
    "\n",
    "# mask_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d919b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )\n",
    "# selection[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cb577f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58e34ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels_dfg', 'labels'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81a59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70219d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels_dfg', 'labels'])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.keys())\n",
    "print(inputs.token_type_ids)\n",
    "inputs.token_type_ids[0][0] =1\n",
    "print(inputs.token_type_ids)\n",
    "#TODO set token type ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd332543",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6640b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BinaryDataset(inputs)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "validation_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, validation_size])\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37a18e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_task2_metrices, global_task1_metrices ,v_global_task1_metrices, v_global_task2_metrices\n",
    "\n",
    "from numpy import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graph(task1_metrices, task2_metrices , v_task1_metrices, v_task2_metrices, label = \"Graph\" ):\n",
    "    \n",
    "    plt.ioff()\n",
    "\n",
    "    font_size = 10\n",
    "    x_labels = [ i for i in range(len(task1_metrices)) ]\n",
    "    \n",
    "    task1_f1 = [ i['f1'] for i in task1_metrices ]\n",
    "    task2_f1 = [ i['f1'] for i in task2_metrices ]\n",
    "    \n",
    "    v_task1_f1 = [ i['f1'] for i in v_task1_metrices ]\n",
    "    v_task2_f1 = [ i['f1'] for i in v_task2_metrices ]\n",
    "    \n",
    "\n",
    "    plt.ylabel(' F1 ',fontsize=font_size)\n",
    "    plt.plot(x_labels, task1_f1 , 'r') \n",
    "    plt.plot(x_labels, task2_f1 , 'b') \n",
    "    \n",
    "    plt.plot(x_labels, v_task1_f1 , 'r' , linestyle = '--') \n",
    "    plt.plot(x_labels, v_task2_f1 , 'b' , linestyle = '--') \n",
    "    \n",
    "    plt.xlabel(\"Epoch\", fontsize=font_size)\n",
    "    plt.title(label,fontsize=font_size)\n",
    "    plt.legend(['MLM Train', 'DFG Train', 'MLM Val', 'DFG Val'], loc='upper left')\n",
    "    \n",
    "    plt.savefig('./output/'+label+'_f1.pdf')\n",
    "    plt.close()\n",
    "#     plt.show()\n",
    "    \n",
    "    ################################\n",
    "    ################# LOSS #########\n",
    "    ################################\n",
    "    \n",
    "    task1_loss = [ i['loss'] for i in task1_metrices ]\n",
    "    task2_loss = [ i['loss'] for i in task2_metrices ]\n",
    "    \n",
    "    v_task1_loss = [ i['loss'] for i in v_task1_metrices ]\n",
    "    v_task2_loss = [ i['loss'] for i in v_task2_metrices ]\n",
    "    \n",
    "\n",
    "    plt.ylabel(' LOSS ',fontsize=font_size)\n",
    "    plt.plot(x_labels, task1_loss , 'r') \n",
    "    plt.plot(x_labels, task2_loss , 'b') \n",
    "    \n",
    "    plt.plot(x_labels, v_task1_loss , 'r' , linestyle = '--') \n",
    "    plt.plot(x_labels, v_task2_loss , 'b' , linestyle = '--') \n",
    "    \n",
    "    plt.xlabel(\"Epoch\", fontsize=font_size)\n",
    "    plt.title(label,fontsize=font_size)\n",
    "    plt.legend(['MLM Train', 'DFG Train', 'MLM Val', 'DFG Val'], loc='upper left')\n",
    "    \n",
    "    plt.savefig('./output/'+label+'_loss.pdf')\n",
    "    plt.close()\n",
    "#     plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82ddc34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# Define the multitask BERT model\n",
    "\n",
    "hidden_size = BertModel.from_pretrained('bert-base-uncased').config.hidden_size\n",
    "# vocab_size = bert_model.config.vocab_size\n",
    "class MultitaskBert(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultitaskBert, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased') #BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc = nn.Linear(  hidden_size , VOCAB_SIZE)\n",
    "        self.dfg_classifier = nn.Linear(hidden_size, 2) #todo was 768 num_classes_task2\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask ):\n",
    "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        hidden_states = bert_outputs.last_hidden_state\n",
    "        logits_mlm = self.fc(hidden_states)\n",
    "        \n",
    "        bert_pooled_output = bert_outputs.pooler_output\n",
    "        logits_dfg = self.dfg_classifier(bert_pooled_output)\n",
    "        \n",
    "        \n",
    "        return logits_mlm,   logits_dfg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4054b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "model = MultitaskBert()  # Example number of classes for each task\n",
    "model.to(device)\n",
    "\n",
    "# initialize optimizer\n",
    "optim = AdamW( model.parameters() , lr=5e-6)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6a0868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model ,data_loop, is_training = False):\n",
    "    \n",
    "    task1_prediction_s, task1_ground_truth_s = [], []\n",
    "    task1_losses = []\n",
    "    \n",
    "    task2_prediction_s, task2_ground_truth_s = [], []\n",
    "    task2_losses = []\n",
    "    \n",
    "    for N,batch in enumerate(data_loop):\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        if is_training == True:\n",
    "            optim.zero_grad()\n",
    "\n",
    "        logits_task1,   logits_task2 = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))\n",
    "\n",
    "\n",
    "        #Task 1\n",
    "        loss_task1 = criterion(logits_task1.view(-1, VOCAB_SIZE), batch['labels'].to(device).view(-1))\n",
    "        task1_losses.append(loss_task1.item())\n",
    "        predictions_task1 = torch.argmax(logits_task1, dim=2)\n",
    "\n",
    "\n",
    "        task1_prediction_s.extend(predictions_task1.detach().cpu().numpy().flatten())\n",
    "        task1_ground_truth_s.extend(batch['labels'].detach().cpu().numpy().flatten())\n",
    "\n",
    "        #Task2\n",
    "        loss_task2 = criterion(logits_task2, batch['labels_dfg'].to(device))\n",
    "        task2_losses.append(loss_task2.item())\n",
    "        predictions_task2 = torch.argmax(logits_task2, dim=1)\n",
    "\n",
    "\n",
    "        task2_prediction_s.extend(predictions_task2.detach().cpu().numpy().flatten())   \n",
    "        task2_ground_truth_s.extend(batch['labels_dfg'].detach().cpu().numpy().flatten())\n",
    "\n",
    "        if is_training == True:\n",
    "            (loss_task1+loss_task2).backward()\n",
    "            optim.step()\n",
    "\n",
    "\n",
    "        # print relevant info to progress bar\n",
    "        data_loop.set_description(f'Epoch {ecpoch}')\n",
    "        data_loop.set_postfix(loss=(loss_task1+loss_task2).item())\n",
    "\n",
    "    ###### Training Scores\n",
    "    task1_accuracy = (accuracy_score(task1_ground_truth_s, task1_prediction_s))    \n",
    "    task1_precision, task1_recall, task1_f1, _ = precision_recall_fscore_support(task1_ground_truth_s,task1_prediction_s,average='weighted')\n",
    "    task1_metrices = {'accuracy':task1_accuracy ,\n",
    "                      'precision':task1_precision, \n",
    "                      'recall':task1_recall, \n",
    "                      'f1':task1_f1,\n",
    "                      'loss': (sum(task1_losses) / len(task1_losses))}\n",
    "    \n",
    "    task2_accuracy = (accuracy_score(task2_ground_truth_s, task2_prediction_s))   \n",
    "    task2_precision, task2_recall, task2_f1, _ = precision_recall_fscore_support(task2_ground_truth_s,task2_prediction_s, average='binary')\n",
    "    task2_metrices = {'accuracy':task2_accuracy ,\n",
    "                      'precision':task2_precision, \n",
    "                      'recall':task2_recall, \n",
    "                      'f1':task2_f1,\n",
    "                      'loss': (sum(task2_losses) / len(task2_losses))}\n",
    "\n",
    "    return task1_metrices, task2_metrices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aebe501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/7706 [00:00<?, ?it/s]/tmp/ipykernel_1042747/3277124069.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0:   7%|█▎                | 541/7706 [04:38<1:04:31,  1.85it/s, loss=2.79]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "global_task2_metrices = []\n",
    "global_task1_metrices = []\n",
    "\n",
    "v_global_task1_metrices = []\n",
    "v_global_task2_metrices = []\n",
    "\n",
    "for ecpoch in range(EPOCHS):\n",
    "    \n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    model.train()\n",
    "    task1_metrices , task2_metrices = training_loop(model ,train_loop, is_training = True)\n",
    "    global_task1_metrices.append(task1_metrices)\n",
    "    global_task2_metrices.append(task2_metrices)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        validation_loop = tqdm(validation_loader, leave=True)\n",
    "        v_task1_metrices , v_task2_metrices = training_loop(model ,validation_loop, is_training = False)\n",
    "        v_global_task1_metrices.append(v_task1_metrices)\n",
    "        v_global_task2_metrices.append(v_task2_metrices)\n",
    "    \n",
    "    plot_graph(global_task1_metrices, global_task2_metrices ,v_global_task1_metrices, v_global_task2_metrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d63538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4772e023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
