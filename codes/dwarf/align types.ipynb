{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7eb126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    }
   ],
   "source": [
    "#TODO add STRUCT variables from dwarf info\n",
    "\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from elftools.dwarf.descriptions import (\n",
    "    describe_DWARF_expr, set_global_machine_arch)\n",
    "from elftools.dwarf.locationlists import (\n",
    "    LocationEntry, LocationExpr, LocationParser)\n",
    "import posixpath\n",
    "import sys,os,pickle\n",
    "from elftools.elf.segments import Segment\n",
    "from elftools.dwarf.locationlists import LocationParser, LocationExpr\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import collections\n",
    "import posixpath\n",
    "\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "net = Network(notebook=True)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import ntpath\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "import collections\n",
    "\n",
    "import clang.cindex\n",
    "from clang.cindex import CursorKind\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANALYSIS_DATA_PATH = '/home/nahid/temp_output/files/'\n",
    "SRC_N_BIN_PATH = '/home/nahid/temp_dir/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0922d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_bin_and_src_path(pkl_filename):\n",
    "    proj_name = pkl_filename.split('_____')[0]\n",
    "    bin_file_name = pkl_filename.split('_____')[1].split('.pkl')[0]\n",
    "    bin_path = os.path.join( SRC_N_BIN_PATH ,proj_name , 'elfs', bin_file_name )\n",
    "    src_dir_name  = [ dir_name  for dir_name in os.listdir( os.path.join(SRC_N_BIN_PATH ,proj_name)) if dir_name!='elfs'][0]\n",
    "    src_path = os.path.join( SRC_N_BIN_PATH ,proj_name , src_dir_name )\n",
    "    return bin_file_name ,proj_name, bin_path , src_path\n",
    "\n",
    "\n",
    "def fix_src_path(cu_path):#TODO reduce global var usage\n",
    "    compiler_machine_dependent_path = cu_path[:cu_path.find(project_name)]\n",
    "    cu_path = cu_path.replace(compiler_machine_dependent_path , SRC_N_BIN_PATH)\n",
    "    return cu_path\n",
    "\n",
    "def check_dwarf_ok(filePath):\n",
    "    with open(filePath, 'rb') as f:\n",
    "        elffile = ELFFile( f )\n",
    "\n",
    "        if not elffile.has_dwarf_info():\n",
    "            print('  file has no DWARF info')\n",
    "            return False\n",
    "        dwarfinfo = elffile.get_dwarf_info()\n",
    "        \n",
    "        try:\n",
    "            if len(list(dwarfinfo.iter_CUs()))==0:\n",
    "                return False\n",
    "            for CU in dwarfinfo.iter_CUs():\n",
    "                CU_DIR_PATH = None\n",
    "                CU_FILENAME = None\n",
    "                for attr in CU.get_top_DIE().attributes.values():\n",
    "                    if attr.name == 'DW_AT_comp_dir':\n",
    "                        CU_DIR_PATH = fix_src_path(attr.value.decode(\"utf-8\"))\n",
    "                    if attr.name == 'DW_AT_name':\n",
    "                        CU_FILENAME = (attr.value.decode(\"utf-8\"))\n",
    "                if CU_DIR_PATH==None or CU_FILENAME==None:\n",
    "                    return False\n",
    "                line_program = dwarfinfo.line_program_for_CU(CU)\n",
    "                if line_program is None:\n",
    "                    print('  DWARF info is missing a line program for this CU')\n",
    "                    return False\n",
    "            return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "def get_min_max_address(filePath):\n",
    "    with open(filePath, 'rb') as f:\n",
    "        elffile = ELFFile(f)\n",
    "\n",
    "        dwarfinfo = elffile.get_dwarf_info()\n",
    "        min_address = 10000000000000\n",
    "        max_address = -100000000000\n",
    "        for CU in dwarfinfo.iter_CUs():\n",
    "            CU_DIR_PATH = None\n",
    "            CU_FILENAME = None\n",
    "            for attr in CU.get_top_DIE().attributes.values():\n",
    "                if attr.name == 'DW_AT_comp_dir':\n",
    "                    CU_DIR_PATH = fix_src_path(attr.value.decode(\"utf-8\"))\n",
    "                if attr.name == 'DW_AT_name':\n",
    "                    CU_FILENAME = (attr.value.decode(\"utf-8\"))\n",
    "\n",
    "            line_program = dwarfinfo.line_program_for_CU(CU)\n",
    "\n",
    "            print(\"DBG: \",CU_DIR_PATH,CU_FILENAME)\n",
    "            cu_file_path  = os.path.join(CU_DIR_PATH, CU_FILENAME)\n",
    "\n",
    "            for line_entry in line_program.get_entries():\n",
    "                if line_entry.state!= None:\n",
    "                    src_file_name = line_program.header['file_entry'][line_entry.state.file-1].name.decode(\"utf-8\")\n",
    "                    if src_file_name==CU_FILENAME: # no match means library C code\n",
    "#                         if line_entry.state.line in bounds_matrix: #not always presend as disabled code might be present\n",
    "                        if line_entry.state.address>max_address:\n",
    "                            max_address = line_entry.state.address\n",
    "            \n",
    "                        if line_entry.state.address <min_address:\n",
    "                            min_address = line_entry.state.address\n",
    "    return min_address,max_address\n",
    "         \n",
    "def get_valid_instructions (filePath, addr_list, min_address, max_address):\n",
    "\n",
    "    fh = open(filePath, 'rb')\n",
    "    bin_bytearray = bytearray(fh.read())\n",
    "\n",
    "    address_inst = {}\n",
    "    \n",
    "    md = Cs(CS_ARCH_X86, CS_MODE_64)\n",
    "    md.detail = True\n",
    "    \n",
    "    for addr in addr_list:\n",
    "        \n",
    "\n",
    "        ops = bin_bytearray[addr: ]\n",
    "\n",
    "        #TODO make efficient\n",
    "        for inst in md.disasm(ops, addr):\n",
    "            if inst.address<=max_address and inst.address>=min_address:\n",
    "                address_inst[inst.address] = inst\n",
    "            break\n",
    "            \n",
    "    address_inst = collections.OrderedDict(sorted(address_inst.items()))\n",
    "    return address_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcce23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e22580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def line_entry_mapping(line_program,CU):\n",
    "    filename_map = defaultdict(int)\n",
    "\n",
    "    # The line program, when decoded, returns a list of line program\n",
    "    # entries. Each entry contains a state, which we'll use to build\n",
    "    # a reverse mapping of filename -> #entries.\n",
    "    lp_entries = line_program.get_entries()\n",
    "    if len(lp_entries)==0:\n",
    "        return None\n",
    "    for lpe in lp_entries:\n",
    "        # We skip LPEs that don't have an associated file.\n",
    "        # This can happen if instructions in the compiled binary\n",
    "        # don't correspond directly to any original source file.\n",
    "        if not lpe.state:# or lpe.state.file == 0\n",
    "            continue\n",
    "        filename = lpe_filename(line_program, lpe.state.file,CU)[0]\n",
    "        filename_map[filename] += 1\n",
    "\n",
    "    # for filename, lpe_count in filename_map.items():\n",
    "    #     print(\"    filename=%s -> %d entries\" % (filename, lpe_count))\n",
    "    return filename_map\n",
    "\n",
    "def lpe_filename(line_program, file_index, CU):\n",
    "    \n",
    "    \n",
    "    die_dict = {}                    \n",
    "    for attr in CU.get_top_DIE().attributes.values():\n",
    "        die_dict[attr.name] = attr\n",
    "    \n",
    "    \n",
    "    compilation_command = die_dict['DW_AT_producer'].value.decode(\"utf-8\")\n",
    "    \n",
    "    if 'clang' in compilation_command.lower():\n",
    "        COMPILER_SUBSTRACT = 1\n",
    "    elif 'gnu' in compilation_command.lower():\n",
    "        COMPILER_SUBSTRACT = 0\n",
    "    lp_header = line_program.header\n",
    "    file_entries = lp_header[\"file_entry\"]\n",
    "#     print(COMPILER_SUBSTRACT, compilation_command)\n",
    "    \n",
    "    # File and directory indices are 1-indexed.\n",
    "    file_entry = file_entries[file_index -COMPILER_SUBSTRACT]\n",
    "    dir_index = file_entry[\"dir_index\"]\n",
    "\n",
    "    # A dir_index of 0 indicates that no absolute directory was recorded during\n",
    "    # compilation; return just the basename.\n",
    "    if dir_index == 0:\n",
    "        return file_entry.name.decode(),dir_index\n",
    "    directory = lp_header[\"include_directory\"][dir_index -COMPILER_SUBSTRACT]\n",
    "    return posixpath.join(directory, file_entry.name).decode(),dir_index\n",
    "\n",
    "\n",
    "def show_loclist(loclist, dwarfinfo, indent, cu_offset):\n",
    "    \"\"\" Display a location list nicely, decoding the DWARF expressions\n",
    "        contained within.\n",
    "    \"\"\"\n",
    "    d = []\n",
    "    for loc_entity in loclist:\n",
    "        if isinstance(loc_entity, LocationEntry):\n",
    "            d.append('%s <<%s>>' % (\n",
    "                loc_entity,\n",
    "                describe_DWARF_expr(loc_entity.loc_expr, dwarfinfo.structs, cu_offset)))\n",
    "        else:\n",
    "            d.append(str(loc_entity))\n",
    "    return '\\n'.join(indent + s for s in d)\n",
    "\n",
    "\n",
    "########################################################\n",
    "######################   DWARF PERSER #######################\n",
    "###########################################################\n",
    "\n",
    "\n",
    "def get_DIE_at_offset(CU, offset):\n",
    "        for die in CU.iter_DIEs():\n",
    "            if die.offset == CU.cu_offset+offset:\n",
    "                return die \n",
    "        return None\n",
    "\n",
    "\n",
    "##TODO FIX CONSTANT TYPE\n",
    "def get_type_name(CU, offset):#get_DIE_at_offset(CU,attr.value)\n",
    "    die = get_DIE_at_offset(CU, offset)\n",
    "    \n",
    "    if die.tag == 'DW_TAG_const_type':\n",
    "        return \"const\"\n",
    "    \n",
    "    if die.tag == 'DW_TAG_pointer_type' :\n",
    "        for _attr in die.attributes.values():\n",
    "            if _attr.name== \"DW_AT_type\":\n",
    "                \n",
    "                return \"*\"+get_type_name(CU, _attr.value) \n",
    "\n",
    "    elif die.tag =='DW_TAG_subroutine_type':\n",
    "        \n",
    "\n",
    "        for _attr in die.attributes.values():\n",
    "            if _attr.name== \"DW_AT_sibling\":\n",
    "                return get_type_name(CU, _attr.value) \n",
    "            \n",
    "            if _attr.name== \"DW_AT_type\":\n",
    "                return \"*\"+get_type_name(CU, _attr.value) \n",
    "\n",
    "    for attr in die.attributes.values():\n",
    "        if attr.name== \"DW_AT_name\":\n",
    "            return attr.value.decode(\"utf-8\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "############################################################\n",
    "############################# CLANG #######################\n",
    "###########################################################\n",
    "\n",
    "# FUNCTION_DECL\n",
    "# https://stackoverflow.com/questions/43460605/function-boundary-identification-using-libclang\n",
    "# https://eli.thegreenplace.net/2011/07/03/parsing-c-in-python-with-clang\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_all_var_types(source_path):\n",
    "    srcFileName = source_path.split('/')[-1]\n",
    "    idx = clang.cindex.Index.create()\n",
    "    print(source_path)\n",
    "    tu = idx.parse(source_path)\n",
    "    \n",
    "    for f in tu.cursor.walk_preorder():\n",
    "        if f.kind == clang.cindex.CursorKind.VAR_DECL:\n",
    "            # print(dir(f))\n",
    "            print('file.name: ',f.extent.start.file.name)\n",
    "            originFileName = f.extent.start.file.name.split('/')[-1]\n",
    "            print('originFileName :',originFileName)\n",
    "            print('displayname:  ',f.displayname)\n",
    "            print('type.spelling:  ',f.type.spelling)\n",
    "            print('f.extent.start.line: ', f.extent.start.line, \"col: \",f.extent.start.column)\n",
    "            print('\\n')\n",
    "            \n",
    "            \n",
    "\n",
    "   \n",
    "\n",
    "def get_all_function_types(source_path):\n",
    "    idx = clang.cindex.Index.create()\n",
    "    tu = idx.parse(source_path)\n",
    "    \n",
    "    for f in tu.cursor.walk_preorder():\n",
    "        if f.kind == clang.cindex.CursorKind.FUNCTION_DECL:\n",
    "            # print(dir(f))\n",
    "            print(f.displayname)\n",
    "            print('function name: ',( f.spelling))\n",
    "            print('Returns: ',(f.result_type.spelling))\n",
    "            \n",
    "            \n",
    "            arg_len = len(list(f.type.argument_types()))\n",
    "            if arg_len>0:\n",
    "                arg_types = list(f.type.argument_types())\n",
    "                for arg_type in arg_types:\n",
    "                    print('arg_type:',arg_type.spelling)\n",
    "                args = list(f.get_arguments())\n",
    "                for arg in args:\n",
    "                    print('arg:',arg.spelling)\n",
    "\n",
    "\n",
    "            print(\"\\n\\n\\n\")\n",
    "\n",
    "            \n",
    "def get_function_boundaries(source_path): #TODO does not perse disabled Source code,not needed anyway\n",
    "    \n",
    "    function_boundary_by_name = {}\n",
    "    idx = clang.cindex.Index.create()\n",
    "    print(\"source_path: \",source_path)\n",
    "    tu = idx.parse(source_path)\n",
    "\n",
    "    for f in tu.cursor.walk_preorder():\n",
    "        \n",
    "        if f.kind == clang.cindex.CursorKind.FUNCTION_DECL:\n",
    "\n",
    "            function_name = f.displayname.split('(')[0]\n",
    "            function_boundary_by_name[function_name]={}\n",
    "            function_boundary_by_name[function_name] = { 'src_path':f.extent.start.file.name,\n",
    "                              'src_file':f.extent.start.file.name.split('/')[-1],\n",
    "                              'start_line':f.extent.start.line,\n",
    "                              'start_col':f.extent.start.column,\n",
    "                              'end_line':f.extent.end.line,\n",
    "                              'end_col':f.extent.end.column}\n",
    "\n",
    "    return function_boundary_by_name\n",
    "\n",
    "def get_containing_function(source_file_path, line, col=0):\n",
    "    function_boundary_by_name = get_function_boundaries(source_file_path)\n",
    "    \n",
    "    for function_name, item in function_boundary_by_name.items():\n",
    "        if item['src_path'] == source_file_path:\n",
    "            if line>= item['start_line'] and line<= item['end_line']:\n",
    "                return function_name\n",
    "        \n",
    "\n",
    "def form_function_bound_metrix(src_bounds, src_file_name):\n",
    "    bounds = {}\n",
    "    for func_info in src_bounds.items():\n",
    "        if func_info[1]['src_file'] == src_file_name:\n",
    "            start_line  = func_info[1]['start_line']\n",
    "            end_line    = func_info[1]['end_line']\n",
    "            print(func_info[0] ,start_line , end_line)\n",
    "            for i in range(start_line , end_line+1):\n",
    "                bounds[i] = func_info[0]\n",
    "               \n",
    "    return bounds\n",
    "\n",
    "\n",
    "\n",
    "def find_variables_per_line(source_path , line_to_function_matrix , dwarf_FUNC_PARAMS):\n",
    "    print(line_to_function_matrix)\n",
    "    srcFileName = source_path.split('/')[-1]\n",
    "    idx = clang.cindex.Index.create()\n",
    "    tu = idx.parse(source_path)\n",
    "    var_usage_matrix = {}\n",
    "    for f in tu.cursor.walk_preorder():\n",
    "\n",
    "        #TODO keep all with type info, explore CursorKind\n",
    "        #TODO function ends  }  should relate with fucntion return type\n",
    "        \n",
    "        if f.kind in [CursorKind.PARM_DECL ,CursorKind.DECL_REF_EXPR, CursorKind.VAR_DECL]  :\n",
    "            \n",
    "            originFileName = f.extent.start.file.name.split('/')[-1]\n",
    "            \n",
    "            if srcFileName!=originFileName:\n",
    "                continue\n",
    "\n",
    "\n",
    "            line = f.extent.start.line\n",
    "            col =f.extent.start.column\n",
    "            type_info = f.type.spelling\n",
    "            var_name = f.displayname\n",
    "\n",
    "            if line not in var_usage_matrix:\n",
    "                var_usage_matrix[line] = {}\n",
    "\n",
    "            if line in line_to_function_matrix:# func declaration, global variables,  might not present\n",
    "                if line_to_function_matrix[line] in dwarf_FUNC_PARAMS[source_path]:\n",
    "                    #because wiredrly some function info are not in DWARF INFO\n",
    "                    if var_name in dwarf_FUNC_PARAMS[source_path][line_to_function_matrix[line]]:\n",
    "                        var_usage_matrix[line][col] = {\n",
    "                                        'name'       : f.displayname ,\n",
    "                                        'dwarf_info' : dwarf_FUNC_PARAMS[source_path][line_to_function_matrix[line]][var_name],\n",
    "                                        'type'       : f.type.spelling }\n",
    "    return var_usage_matrix\n",
    "\n",
    "            \n",
    "###################################################################\n",
    "########  Find Src Code by filepath, line and col no  #############\n",
    "##################################################################\n",
    "\n",
    "def getSource(sourceFilePath, row , col):\n",
    "    print(sourceFilePath, row , col)\n",
    "    sourceFile = open(sourceFilePath, \"r\")\n",
    "    fileContent = sourceFile.readlines()\n",
    "    row_content =  fileContent[row-1]\n",
    "    row_content = row_content[:(col-1)] + '|'+row_content[(col-1)]+'|' +row_content[col:]\n",
    "    \n",
    "    return row_content\n",
    "\n",
    "######################################3#########\n",
    "########### ILLUSTRATE in file ##################\n",
    "#################################################\n",
    "def write_illustrated_file(bin_fname ,lineinfo_address_subprogram_complete):\n",
    "\n",
    "    REGISTER_SUBSTRACT_FACTOR = -0\n",
    "\n",
    "    with open(bin_fname+'.s', 'w') as outFile:\n",
    "        # outFile.write('file contents\\n')\n",
    "        lastSource = \"\"\n",
    "        for address in VALID_INSTRUCTIONS_SET:\n",
    "            address_hex = hex(address)\n",
    "            print(address_hex)\n",
    "            inst = VALID_INSTRUCTIONS_SET[address]\n",
    "            instrctionCode = (address_hex+\":\\t\"+ inst.mnemonic+\" \"+inst.op_str).ljust(45)\n",
    "\n",
    "            OFFSET = None\n",
    "            if len(inst.operands) > 0 :\n",
    "                c=-1\n",
    "                for o in inst.operands:\n",
    "                    c += 1\n",
    "                    if o.type == CS_OP_MEM:\n",
    "                        print(\"\\t\\toperands[%u].type: MEM\" %c)\n",
    "                        if o.value.mem.base != 0:\n",
    "                            print(\"\\t\\t\\toperands[%u].mem.base: REG = %s\" \\\n",
    "                                %(c, inst.reg_name(o.value.mem.base)))\n",
    "                        if o.value.mem.index != 0:\n",
    "                            print(\"\\t\\t\\toperands[%u].mem.index: REG = %s\" \\\n",
    "                                %(c, inst.reg_name(o.value.mem.index)))\n",
    "                        if o.value.mem.disp != 0:\n",
    "                            print(\"\\t\\t\\toperands[%u].mem.disp: 0x%x\" \\\n",
    "                                %(c, o.value.mem.disp))\n",
    "                            OFFSET = o.value.mem.disp\n",
    "                        print(hex(o.value.mem.disp),o.value.mem.disp)\n",
    "\n",
    "\n",
    "            if address in lineinfo_address_subprogram_complete:\n",
    "                if lineinfo_address_subprogram_complete[address]['lineinfo'].address == address: \n",
    "                    srcFilePath = lineinfo_address_subprogram_complete[address]['srcPath']\n",
    "                    if srcFilePath!=lastSource:\n",
    "                        outFile.write(\"\\n\"+ '#'*100+\"\\n\"+ srcFilePath.rjust(45) +'\\n'+'#'*100+ \"\\n\\n\")\n",
    "                        lastSource = srcFilePath\n",
    "\n",
    "\n",
    "                    src_line_no  = lineinfo_address_subprogram_complete[address]['lineinfo'].line\n",
    "                    src_col_no   = lineinfo_address_subprogram_complete[address]['lineinfo'].column\n",
    "                    sourceCode = getSource(srcFilePath,src_line_no, src_col_no)\n",
    "                    function_name = lineinfo_address_subprogram_complete[address]['func']\n",
    "\n",
    "                    print('##############',sourceCode)\n",
    "\n",
    "                    if '\\n' not in  sourceCode:\n",
    "                        sourceCode+=sourceCode+\"\\n\"\n",
    "                    outFile.write(instrctionCode+\"#\"+ sourceCode  )\n",
    "                    print(instrctionCode+\"#\"+ sourceCode)\n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "                    outFile.write(instrctionCode+ '\\n'  )\n",
    "                    print(instrctionCode)\n",
    "                if OFFSET:\n",
    "                    outFile.write(\"MEMORY OFFSET:     \"+str(hex(OFFSET))+\"     \"+str(OFFSET)+ \"  >>\"+str(OFFSET-REGISTER_SUBSTRACT_FACTOR)+'\\n\\n')\n",
    "                    pass\n",
    "######################################3#########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################\n",
    "########### Find variables in each src line  ##########\n",
    "######################################3################\n",
    "\n",
    "def create_variable_per_line_matrix(filename ,FUNCTION_PARAMS):\n",
    "    variables_in_line_matrix_all_files = {}\n",
    "    print('Processing file:', filename)\n",
    "    with open(filename, 'rb') as f:\n",
    "        elffile = ELFFile(f)\n",
    "\n",
    "        if not elffile.has_dwarf_info():\n",
    "            print('  file has no DWARF info')\n",
    "            return\n",
    "        dwarfinfo = elffile.get_dwarf_info()\n",
    "\n",
    "        location_lists = dwarfinfo.location_lists()\n",
    "        \n",
    "\n",
    "        # This is required for the descriptions module to correctly decode\n",
    "        # register names contained in DWARF expressions.\n",
    "        set_global_machine_arch(elffile.get_machine_arch())\n",
    "\n",
    "        loc_parser = LocationParser(location_lists)\n",
    "        section_offset = dwarfinfo.debug_info_sec.global_offset\n",
    "        # Offset of the .debug_info section in the stream\n",
    "        \n",
    "        \n",
    "        for CU in dwarfinfo.iter_CUs():\n",
    "            CU_DIR_PATH = None\n",
    "            CU_FILENAME = None\n",
    "            for attr in CU.get_top_DIE().attributes.values():\n",
    "                if attr.name == 'DW_AT_comp_dir':\n",
    "                    CU_DIR_PATH = fix_src_path(attr.value.decode(\"utf-8\"))\n",
    "                if attr.name == 'DW_AT_name':\n",
    "                    CU_FILENAME = (attr.value.decode(\"utf-8\"))\n",
    "\n",
    "            #########\n",
    "            cu_src_path = os.path.join(CU_DIR_PATH, CU_FILENAME)\n",
    "            cu_func_boundaries =get_function_boundaries(cu_src_path )\n",
    "            cu_src_line_to_function_matrix = form_function_bound_metrix(cu_func_boundaries , CU_FILENAME)\n",
    "            variables_in_line_matrix = find_variables_per_line(cu_src_path, cu_src_line_to_function_matrix , FUNCTION_PARAMS)\n",
    "            variables_in_line_matrix_all_files[cu_src_path] = variables_in_line_matrix\n",
    "            #########\n",
    "    return variables_in_line_matrix_all_files\n",
    "\n",
    "##########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################## #######################\n",
    "######### UTIL funcs related to aligning inst offset to dwarf location offset ########\n",
    "########################################################################################\n",
    "def diff_dict(matrix):\n",
    "    for i in range (len(matrix.keys()) -1):\n",
    "            ith_key = [*matrix.keys()][i]\n",
    "            i_plus_1th_key = [*matrix.keys()][i+1]\n",
    "            matrix[ith_key] = matrix[ith_key] -matrix[i_plus_1th_key] \n",
    "    return matrix\n",
    "\n",
    "def vars_to_types(var_list, cu_path, func):\n",
    "    types=[]\n",
    "    for variable_name in var_list:\n",
    "        types.append(FUNC_PARAMS[cu_path][func][variable_name]['type'])\n",
    "    return types\n",
    "\n",
    "\n",
    "#todo try func to address \n",
    "def build_line_to_relatedAddresses_matrix(address_lineinfo):#lineinfo_address_subprogram_complete\n",
    "    line_address = {}\n",
    "    for address  in VALID_INSTRUCTIONS_SET:#address_lineinfo.items():\n",
    "        info = address_lineinfo[address]\n",
    "        line          = info['lineinfo'].line\n",
    "        col           = info['lineinfo'].column\n",
    "        src_filepath  = info['srcPath']\n",
    "        func          = info['func']\n",
    "        \n",
    "        key= str(line)+\"_\"+ str(col)\n",
    "        \n",
    "        if src_filepath not in line_address:\n",
    "            line_address[src_filepath] ={}\n",
    "        if func not in line_address[src_filepath]:\n",
    "            line_address[src_filepath][func] = {}\n",
    "        if key not in line_address[src_filepath][func]:\n",
    "            line_address[src_filepath][func][key] = []\n",
    "        \n",
    "        line_address[src_filepath][func][key].append(address)\n",
    "        \n",
    "    return line_address\n",
    "\n",
    "def assign_twin_instructions_types(addr_list, type_list, twin_dict):\n",
    "        inst_to_type_dict = dict(zip(addr_list, type_list))\n",
    "\n",
    "        for main_address, twin_list in twin_dict.items():\n",
    "            for twin in twin_list:\n",
    "                if main_address in inst_to_type_dict:\n",
    "                    inst_to_type_dict[twin] = inst_to_type_dict[main_address]\n",
    "        return inst_to_type_dict\n",
    "         \n",
    "\n",
    "\n",
    "\n",
    "######################### ENFD UTILs ####################################\n",
    "\n",
    "\n",
    "\n",
    "######################################################################## ######\n",
    "############## parse DWARF info and create FUNC_PARAMS which   ##############\n",
    "#############  contains all the dwarf info about func perams, varts etc ####\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "def parse_dwarf_to_get_func_params(filename):\n",
    "    FUNC_PARAMS_DICT = {}\n",
    "    print('Processing file:', filename)\n",
    "    with open(filename, 'rb') as f:\n",
    "        elffile = ELFFile(f)\n",
    "\n",
    "        if not elffile.has_dwarf_info():\n",
    "            print('  file has no DWARF info')\n",
    "            return\n",
    "\n",
    "        # get_dwarf_info returns a DWARFInfo context object, which is the\n",
    "        # starting point for all DWARF-based processing in pyelftools.\n",
    "        dwarfinfo = elffile.get_dwarf_info()\n",
    "        # The location lists are extracted by DWARFInfo from the .debug_loc\n",
    "        # section, and returned here as a LocationLists object.\n",
    "        location_lists = dwarfinfo.location_lists()\n",
    "        \n",
    "\n",
    "        # This is required for the descriptions module to correctly decode\n",
    "        # register names contained in DWARF expressions.\n",
    "        set_global_machine_arch(elffile.get_machine_arch())\n",
    "\n",
    "        # Create a LocationParser object that parses the DIE attributes and\n",
    "        # creates objects representing the actual location information.\n",
    "        loc_parser = LocationParser(location_lists)\n",
    "        section_offset = dwarfinfo.debug_info_sec.global_offset\n",
    "        # Offset of the .debug_info section in the stream\n",
    "        \n",
    "        \n",
    "        for CU in dwarfinfo.iter_CUs():\n",
    "            CU_DIR_PATH = None\n",
    "            CU_FILENAME = None\n",
    "            for attr in CU.get_top_DIE().attributes.values():\n",
    "                if attr.name == 'DW_AT_comp_dir':\n",
    "                    CU_DIR_PATH = fix_src_path(attr.value.decode(\"utf-8\"))\n",
    "                if attr.name == 'DW_AT_name'    :\n",
    "                    CU_FILENAME = (attr.value.decode(\"utf-8\"))\n",
    "\n",
    "            line_program = dwarfinfo.line_program_for_CU(CU)\n",
    "\n",
    "         \n",
    "            CU_dictionary_key = os.path.join(CU_DIR_PATH, CU_FILENAME)\n",
    "            if CU_dictionary_key not in FUNC_PARAMS_DICT:\n",
    "                FUNC_PARAMS_DICT[CU_dictionary_key] = {}\n",
    "            \n",
    "            print('  Found a compile unit at offset %s, length %s' % (\n",
    "                CU.cu_offset, CU['unit_length']))\n",
    "\n",
    "            # A CU provides a simple API to iterate over all the DIEs in it.\n",
    "            die_depth = 0\n",
    "            are_DIEs_of_function = False\n",
    "            FUNC_name = None\n",
    "            for DIE in CU.iter_DIEs():\n",
    "                \n",
    "                ############################################################\n",
    "                #############   Prasing Function DIEs start ################\n",
    "\n",
    "                \n",
    "                if DIE.tag == 'DW_TAG_subprogram':\n",
    "                    if 'DW_AT_low_pc' in DIE.attributes and 'DW_AT_high_pc' in DIE.attributes :\n",
    "                        low_pc = DIE.attributes['DW_AT_low_pc'].value\n",
    "                        high_pc = DIE.attributes['DW_AT_high_pc'].value\n",
    "                        \n",
    "                        print(\"Low PC: \",hex(low_pc) , \" High PC\" , hex(high_pc))\n",
    "                    else:\n",
    "                        print(\"NO PC given\")\n",
    "                    are_DIEs_of_function = True\n",
    "                    \n",
    "                    for attr in DIE.attributes.values():\n",
    "                        if attr.name == \"DW_AT_name\": #FUNC NAME\n",
    "                            FUNC_name = attr.value.decode(\"utf-8\")\n",
    "                            if FUNC_name not in FUNC_PARAMS_DICT[CU_dictionary_key]:\n",
    "                                FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name] ={}\n",
    "                            print(\"SUBPROGRAM: \",FUNC_name)\n",
    "                            \n",
    "                if DIE.tag in[ 'DW_TAG_formal_parameter','DW_TAG_variable' ,'DW_TAG_member']:\n",
    "                    tags = [attr.name for attr in DIE.attributes.values()]\n",
    "                    PARAM_name = None\n",
    "                    if FUNC_name==None:\n",
    "                        \n",
    "                        FUNC_name =\"global\"\n",
    "                        \n",
    "                        if FUNC_name not in FUNC_PARAMS_DICT[CU_dictionary_key]:\n",
    "                            FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name]={}\n",
    "                        \n",
    "                    if \"DW_AT_name\" in tags:\n",
    "                        \n",
    "                        die_dict = {}\n",
    "                        \n",
    "                        for attr in DIE.attributes.values():\n",
    "                            die_dict[attr.name] = attr\n",
    "                        \n",
    "                        PARAM_name = die_dict['DW_AT_name'].value.decode(\"utf-8\")\n",
    "                        \n",
    "                        if PARAM_name not in FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name]:\n",
    "                            FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name][PARAM_name] = {}\n",
    "                        var_type = DIE.tag.split('_')[-1]\n",
    "                        FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name][PARAM_name] = {'type':get_type_name(CU,die_dict['DW_AT_type'].value) , 'kind':var_type}\n",
    "                        \n",
    "#                         print(die_dict)\n",
    "                        # Check if this attribute contains location information\n",
    "#                         if loc_parser.attribute_has_location(die_dict['DW_AT_location'], CU['version']):\n",
    "                        if 'DW_AT_location' in die_dict:\n",
    "\n",
    "                            try:\n",
    "                                loc = loc_parser.parse_from_attribute(die_dict['DW_AT_location'],\n",
    "                                                                      CU['version'])\n",
    "                                \n",
    "#                                 print(CU_dictionary_key,FUNC_name,PARAM_name)\n",
    "                                if isinstance(loc, LocationExpr):\n",
    "                                    loc_info_str = describe_DWARF_expr(loc.loc_expr, dwarfinfo.structs, CU.cu_offset)\n",
    "                                    offset_temp = (loc_info_str.split('-')[-1]).split(')')[0]\n",
    "#                                     print('1a ',loc_info_str, offset_temp)\n",
    "#                                     print('1b ', PARAM_name,loc_info_str, int(offset_temp)-LOCATION_SUBSTRACT_FACTOR)\n",
    "                                    FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name][PARAM_name][\"location\"]= loc_info_str\n",
    "\n",
    "                                elif isinstance(loc, list):\n",
    "                                    print(PARAM_name,show_loclist(loc,dwarfinfo,'      ', CU.cu_offset))\n",
    "                                    FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name][PARAM_name][\"location\"]= show_loclist(loc,\n",
    "                                                       dwarfinfo,'      ', CU.cu_offset)\n",
    "                            except:\n",
    "\n",
    "                                print(\"ERROR\",DIE)\n",
    "                                pass\n",
    "\n",
    "                ###############################################\n",
    "                #############  parsing  Function DIEs ends ################\n",
    "                \n",
    "\n",
    "\n",
    "                \n",
    "                if DIE.is_null(): #https://chromium.googlesource.com/chromiumos/third_party/pyelftools/+/25a77f7738d7fe824f2ed4d33a123136b9d8e88a/scripts/readelf.py\n",
    "                    are_DIEs_of_function = False\n",
    "                    FUNC_name = None\n",
    "                    \n",
    "                    die_depth -= 1\n",
    "                    continue\n",
    "                if DIE.has_children:\n",
    "                    die_depth += 1\n",
    "    \n",
    "    \n",
    "    return FUNC_PARAMS_DICT\n",
    "\n",
    "#############################  END FUNC PARAMS dictionary ######################\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "#################   create matrix for finding lineinfo for each address #################\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "def produce_address_to_lineinfo_matrix(bin_path):\n",
    "    lineinfo_address_subprogram = {}\n",
    "    with open(bin_path, 'rb') as f:\n",
    "        elffile = ELFFile(f)\n",
    "\n",
    "        if not elffile.has_dwarf_info():\n",
    "            print('  file has no DWARF info')\n",
    "            exit(0)\n",
    "\n",
    "        dwarfinfo = elffile.get_dwarf_info()\n",
    "        for CU in dwarfinfo.iter_CUs():\n",
    "            CU_DIR_PATH = None\n",
    "            CU_FILENAME = None\n",
    "            for attr in CU.get_top_DIE().attributes.values():\n",
    "                if attr.name == 'DW_AT_comp_dir':\n",
    "                    CU_DIR_PATH = fix_src_path(attr.value.decode(\"utf-8\"))\n",
    "                if attr.name == 'DW_AT_name':\n",
    "                    CU_FILENAME = (attr.value.decode(\"utf-8\"))\n",
    "\n",
    "            print('  Found a compile unit at offset %s, length %s' % (\n",
    "                CU.cu_offset, CU['unit_length']))\n",
    "\n",
    "            # Every compilation unit in the DWARF information may or may not\n",
    "            # have a corresponding line program in .debug_line.\n",
    "            line_program = dwarfinfo.line_program_for_CU(CU)\n",
    "            if line_program is None:\n",
    "                print('  DWARF info is missing a line program for this CU')\n",
    "                continue\n",
    "\n",
    "            print('DBG: CU_DIR_PATH',CU_DIR_PATH , ' CU_FILENAME: ',CU_FILENAME )\n",
    "            cu_file_path  = os.path.join(CU_DIR_PATH, CU_FILENAME)\n",
    "\n",
    "            bounds_matrix = form_function_bound_metrix( get_function_boundaries(cu_file_path)  , CU_FILENAME)\n",
    "\n",
    "\n",
    "            for line_entry in line_program.get_entries():\n",
    "                if line_entry.state!= None:\n",
    "                    src_file_name = line_program.header['file_entry'][line_entry.state.file-1].name.decode(\"utf-8\")\n",
    "                    if src_file_name==CU_FILENAME: # no match means library C code\n",
    "\n",
    "                        if line_entry.state.line in bounds_matrix: #not always presend as disabled code might be present\n",
    "                            lineinfo_address_subprogram[line_entry.state.address]  =   {\n",
    "                                'func':bounds_matrix[line_entry.state.line], \n",
    "                                'srcPath':cu_file_path,\n",
    "                                'lineinfo':line_entry.state\n",
    "                            } \n",
    "\n",
    "\n",
    "    #TODO make efficient with valid address only\n",
    "\n",
    "    lineinfo_address_subprogram = collections.OrderedDict(sorted(lineinfo_address_subprogram.items()))\n",
    "    lineinfo_address_subprogram_all_address = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('DBG: MIN MAX',MIN_ADDRESS ,MAX_ADDRESS)\n",
    "    temp_subprogram = lineinfo_address_subprogram[MIN_ADDRESS]\n",
    "    for i in range(MIN_ADDRESS,MAX_ADDRESS+1):\n",
    "        if i in lineinfo_address_subprogram:\n",
    "            temp_subprogram = lineinfo_address_subprogram[i]\n",
    "        lineinfo_address_subprogram_all_address[i] = temp_subprogram\n",
    "    \n",
    "    return lineinfo_address_subprogram_all_address\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce419d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx,analysed_pkl_filename in enumerate(os.listdir(ANALYSIS_DATA_PATH)):\n",
    "\n",
    "#     analysed_pkl_path = os.path.join(ANALYSIS_DATA_PATH  , analysed_pkl_filename )\n",
    "#     pkl_name = ntpath.basename ( analysed_pkl_path )\n",
    "\n",
    "#     binFileName, project_name, binary_path, src_dir_path = get_bin_and_src_path( pkl_name )\n",
    "\n",
    "#     if check_dwarf_ok(binary_path)==True:\n",
    "#         print(idx)\n",
    "\n",
    "\n",
    "# 3\n",
    "#   DWARF info is missing a line program for this CU\n",
    "# 17\n",
    "# 19\n",
    "#   DWARF info is missing a line program for this CU\n",
    "# 27\n",
    "# 33\n",
    "# 38\n",
    "# 39\n",
    "# 41\n",
    "# 42\n",
    "#   file has no DWARF info\n",
    "# 44 'int' object has no attribute 'decode'\n",
    "# 48\n",
    "# 49\n",
    "# 50\n",
    "# 54\n",
    "# 55\n",
    "# 57\n",
    "# 60 ok\n",
    "# 61\n",
    "# 64\n",
    "# 65\n",
    "# 69 ok\n",
    "#   DWARF info is missing a line program for this CU\n",
    "# 72\n",
    "# 74\n",
    "# 75\n",
    "# 77  str (not \"NoneType\") to str\n",
    "# 82\n",
    "# 83\n",
    "# 84 ok\n",
    "# 87\n",
    "# 88 cu_filename\n",
    "# 92\n",
    "# 93\n",
    "# 95\n",
    "# 96 cu_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b332495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0884f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = '/test/b/c'\n",
    "# b = '../../src.c'\n",
    "# print(os.path.realpath(b))\n",
    "# os.path.join(a,b)\n",
    "# from pathlib import Path\n",
    "\n",
    "# # `cwd`: current directory is straightforward\n",
    "# cwd = Path.cwd()\n",
    "\n",
    "# # `mod_path`: According to the accepted answer and combine with future power\n",
    "# # if we are in the `helper_script.py`\n",
    "# mod_path = Path(a)\n",
    "# # OR if we are `import helper_script`\n",
    "\n",
    "\n",
    "# # `src_path`: with the future power, it's just so straightforward\n",
    "# relative_path_2 = '../../or/any/level/up/'\n",
    "# src_path_2 = (mod_path / relative_path_2).resolve()\n",
    "# print(src_path_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7bd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c8fcc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def do_magic():\n",
    "    for cu_path, all_func_data in line_to_address_matrix.items():\n",
    "        for func, func_data in all_func_data.items():\n",
    "            for line_col, line_addresses in func_data.items():\n",
    "                line = int(line_col.split('_')[0])\n",
    "                print('\\n\\n\\nfile: ',cu_path,' func:',func,'\\nline: ',line,'\\n\\n')\n",
    "\n",
    "                #################### PROCESS ADDRESS LIST ##############################\n",
    "\n",
    "                inst_matrix = {  }\n",
    "                twin_instructions = {}\n",
    "                for address in line_addresses:\n",
    "                    address_hex = hex(address)\n",
    "                    inst = VALID_INSTRUCTIONS_SET[address]\n",
    "                    instrctionCode = (address_hex+\":\\t\"+ inst.mnemonic+\" \"+inst.op_str).ljust(45)\n",
    "\n",
    "                    disp = None\n",
    "                    if len(inst.operands) > 0 :\n",
    "                        oc=-1\n",
    "                        for o in inst.operands:\n",
    "                            oc += 1\n",
    "                            if o.type == CS_OP_MEM:\n",
    "                                if o.value.mem.disp != 0:\n",
    "                                    disp = o.value.mem.disp\n",
    "\n",
    "                                    if disp not in inst_matrix.values():\n",
    "                                        inst_matrix[address_hex]=disp\n",
    "                                    else:\n",
    "\n",
    "                                        twin_hex = list(inst_matrix.keys())[list(inst_matrix.values()).index(disp)] \n",
    "                                        if twin_hex not in twin_instructions:\n",
    "                                            twin_instructions[twin_hex] = [address_hex]\n",
    "                                        else:\n",
    "                                            twin_instructions[twin_hex].append(address_hex)\n",
    "                                        #TODO twin inst\n",
    "                inst_matrix = dict(sorted(inst_matrix.items(), key=lambda x: x[1] , reverse=True))\n",
    "                print(inst_matrix.values())\n",
    "\n",
    "\n",
    "                #######################  PROCESS SRC VARIABLES #############################\n",
    "                if line in variables_in_line[cu_path]: #ALL LINES SHOULD BE VALID, should not check\n",
    "                    var_list = variables_in_line[cu_path][line]\n",
    "                    print(\"DBG: \",cu_path ,line, var_list)\n",
    "                    var_matrix = {}               \n",
    "                    for col,var in var_list.items():\n",
    "\n",
    "                        if 'location' in var['dwarf_info'] :\n",
    "                            if len(var['dwarf_info']['location'])<15: #TODO, use regex.\n",
    "                                var_matrix[var['name']] = int(var['dwarf_info']['location'].split(':')[-1][:-1])\n",
    "\n",
    "                    var_matrix = dict (sorted(var_matrix.items(), key=lambda x: x[1] , reverse=True))\n",
    "\n",
    "                    print(var_matrix.values())\n",
    "\n",
    "\n",
    "\n",
    "                    ########################################\n",
    "                    ############# Compare & Align  ################\n",
    "                    ########################################\n",
    "                    inst_matrix_len = len(inst_matrix.items())\n",
    "                    var_matrix_len  = len( var_matrix.items())\n",
    "\n",
    "                    #TODO\n",
    "                    # rule 1: they have single inst and single var, so just match\n",
    "                    if inst_matrix_len==1 and var_matrix_len==1:\n",
    "\n",
    "                        types = vars_to_types(list(var_matrix.keys()), cu_path, func)\n",
    "                        insts = list(inst_matrix.keys())\n",
    "\n",
    "                        inst_to_type = assign_twin_instructions_types(insts,types,twin_instructions)\n",
    "                        print('Single > ', inst_to_type )\n",
    "\n",
    "                    #TODO\n",
    "                    # rule 2: if one have 1 item and another have 1+ item, can match\n",
    "                    #         only with coloumn alignment\n",
    "                    if 1 in [inst_matrix_len,var_matrix_len] and \\\n",
    "                            abs(inst_matrix_len-var_matrix_len)>0:\n",
    "                        continue\n",
    "\n",
    "                    #TODO\n",
    "                    # rule 3: if there are multiple longest matches\n",
    "                    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    inst_matrix = diff_dict(inst_matrix)\n",
    "\n",
    "                    var_matrix = diff_dict(var_matrix)\n",
    "\n",
    "\n",
    "                    match = SequenceMatcher(None, \n",
    "                                            list(var_matrix.values()), \n",
    "                                            list(inst_matrix.values())).find_longest_match()\n",
    "\n",
    "                    if match.size>0:#found matching seq\n",
    "                        print(\"MATCHED!\",match,var_matrix.keys() ,inst_matrix.keys() )\n",
    "\n",
    "                        var_matches  = list(var_matrix.keys()) [match.a:(match.a+match.size)+1]\n",
    "                        inst_matches = list(inst_matrix.keys())[match.b:(match.b+match.size)+1]\n",
    "\n",
    "                        print('var_matches: ',var_matches , ' INST matches:',inst_matches)\n",
    "\n",
    "                        ### assign types\n",
    "                        types = vars_to_types(var_matches, cu_path, func)\n",
    "                        print('inst_matches: ', inst_matches, '\\n types', types )\n",
    "\n",
    "                        ### handle twin,\n",
    "                        inst_to_type = assign_twin_instructions_types(inst_matches,types,twin_instructions)\n",
    "                        print(inst_to_type)\n",
    "\n",
    "\n",
    "                        \n",
    "                        \n",
    "################################################\n",
    "###################################################\n",
    "#####################################################\n",
    "# [3,60,69,84]\n",
    "for f_no,analysed_pkl_filename in enumerate(os.listdir(ANALYSIS_DATA_PATH)) : \n",
    "    \n",
    "#     if f_no not in [3,60,69,84]:\n",
    "#         continue\n",
    "\n",
    "    analysed_pkl_path = os.path.join(ANALYSIS_DATA_PATH  , analysed_pkl_filename )\n",
    "    pkl_name = ntpath.basename ( analysed_pkl_path )\n",
    "\n",
    "    binFileName, project_name, binary_path, src_dir_path = get_bin_and_src_path( pkl_name )\n",
    "\n",
    "    if check_dwarf_ok(binary_path)== False:\n",
    "        continue\n",
    "    \n",
    "    MIN_ADDRESS, MAX_ADDRESS =  get_min_max_address(binary_path)\n",
    "\n",
    "    #Load the analysed data\n",
    "    with (open(analysed_pkl_path , \"rb\")) as openfile:\n",
    "        bb_data , ins_data , tool_addresses_list = pickle.load(openfile)\n",
    "    \n",
    "   \n",
    "    VALID_INSTRUCTIONS_SET = get_valid_instructions(binary_path,tool_addresses_list,min_address=MIN_ADDRESS, max_address=MAX_ADDRESS)\n",
    "\n",
    "\n",
    "    ##########################################################\n",
    "    ################ CREATE HELPER DATA STRUCTURES   #########\n",
    "    ##########################################################\n",
    "    try:\n",
    "\n",
    "        # create matrix for finding lineinfo for each address\n",
    "        lineinfo_address_subprogram_complete = produce_address_to_lineinfo_matrix(binary_path)\n",
    "\n",
    "        FUNC_PARAMS = parse_dwarf_to_get_func_params(binary_path)\n",
    "\n",
    "        variables_in_line = create_variable_per_line_matrix(binary_path, FUNC_PARAMS)\n",
    "\n",
    "        line_to_address_matrix = build_line_to_relatedAddresses_matrix(lineinfo_address_subprogram_complete)\n",
    "\n",
    "        ##############################################################################\n",
    "        ##########################################################################\n",
    "        do_magic()\n",
    "        write_illustrated_file(binFileName ,lineinfo_address_subprogram_complete)\n",
    "    \n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(exc_type, fname, exc_tb.tb_lineno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SUBHANALLAH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8799eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [3,60,69,84]\n",
    "\n",
    "# analysed_pkl_filename = os.listdir(ANALYSIS_DATA_PATH)[60]\n",
    "\n",
    "# analysed_pkl_path = os.path.join(ANALYSIS_DATA_PATH  , analysed_pkl_filename )\n",
    "# pkl_name = ntpath.basename ( analysed_pkl_path )\n",
    "\n",
    "# binFileName, project_name, binary_path, src_dir_path = get_bin_and_src_path( pkl_name )\n",
    "\n",
    "# print(check_dwarf_ok(binary_path))\n",
    "\n",
    "# MIN_ADDRESS, MAX_ADDRESS =  get_min_max_address(binary_path)\n",
    "\n",
    "# #Load the analysed data\n",
    "# with (open(analysed_pkl_path , \"rb\")) as openfile:\n",
    "#     bb_data , ins_data , tool_addresses_list = pickle.load(openfile)\n",
    "            \n",
    "# VALID_INSTRUCTIONS_SET = get_valid_instructions(binary_path,tool_addresses_list,min_address=MIN_ADDRESS, max_address=MAX_ADDRESS)\n",
    "# len(tool_addresses_list),len(VALID_INSTRUCTIONS_SET)\n",
    "\n",
    "\n",
    "# ##########################################################\n",
    "# ################ CREATE HELPER DATA STRUCTURES   #########\n",
    "# ##########################################################\n",
    "\n",
    "# # create matrix for finding lineinfo for each address\n",
    "# lineinfo_address_subprogram_complete = produce_address_to_lineinfo_matrix(binary_path)\n",
    "\n",
    "# FUNC_PARAMS = parse_dwarf_to_get_func_params(binary_path)\n",
    "\n",
    "# variables_in_line = create_variable_per_line_matrix(binary_path, FUNC_PARAMS)\n",
    "\n",
    "# line_to_address_matrix = build_line_to_relatedAddresses_matrix(lineinfo_address_subprogram_complete)\n",
    "\n",
    "# ##############################################################################\n",
    "# ##########################################################################\n",
    "# do_magic()\n",
    "# write_illustrated_file(binFileName ,lineinfo_address_subprogram_complete)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "angr",
   "language": "python",
   "name": "angr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
