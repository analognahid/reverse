{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7eb126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    }
   ],
   "source": [
    "#TODO add STRUCT variables from dwarf info\n",
    "#TODO MIN_ADDRESS, MAX_ADDRESS concept is not going to work always.(for data sections) \n",
    "\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from elftools.dwarf.descriptions import (\n",
    "    describe_DWARF_expr, set_global_machine_arch)\n",
    "from elftools.dwarf.locationlists import (\n",
    "    LocationEntry, LocationExpr, LocationParser)\n",
    "import posixpath\n",
    "import sys,os,pickle\n",
    "from elftools.elf.segments import Segment\n",
    "from elftools.dwarf.locationlists import LocationParser, LocationExpr\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import collections\n",
    "import posixpath\n",
    "\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "net = Network(notebook=True)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import ntpath\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "import collections\n",
    "\n",
    "import clang.cindex\n",
    "from clang.cindex import CursorKind\n",
    "import traceback\n",
    "import sys\n",
    "import magic, hashlib\n",
    "\n",
    "\n",
    "\n",
    "ANALYSIS_DATA_PATH = '/home/nahid/dataset/analysis_pkl_files/files/'\n",
    "SRC_N_BIN_PATH = '/home/nahid/dataset/clones/'\n",
    "ILLUSTRATION_LOG_PATH = \"/home/nahid/dataset/illustration/\"\n",
    "TYPE_DATA_SAVE_PATH = '/home/nahid/dataset/instructions_and_type_data/'\n",
    "\n",
    "def is_elf_file(file_path):\n",
    "    try:\n",
    "        file_type = magic.from_file(file_path)\n",
    "        return 'ELF' in file_type\n",
    "    except Exception as e:\n",
    "        return False\n",
    "def find_elf_files( dir_path):\n",
    "    file_paths = []\n",
    "    for path, subdirs, files in os.walk(dir_path):\n",
    "        for name in files:\n",
    "            file_path = os.path.join(path, name)\n",
    "            if is_elf_file(file_path):\n",
    "                file_paths.append(file_path)\n",
    "\n",
    "    return file_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391b19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELF_FILE_PATHS = find_elf_files(SRC_N_BIN_PATH)\n",
    "\n",
    "# with open('ELF_FILE_PATHS.pkl', 'wb') as file:\n",
    "#     pickle.dump(ELF_FILE_PATHS, file)\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open('ELF_FILE_PATHS.pkl', 'rb') as file:\n",
    "    # Call load method to deserialze\n",
    "    ELF_FILE_PATHS = pickle.load(file)\n",
    "    \n",
    "print(len(ELF_FILE_PATHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b75297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fix_src_path(cu_path):#TODO reduce global var usage\n",
    "    key='/clones/'\n",
    "    replacing_str = cu_path[: (cu_path.find(key)+len(key))]\n",
    "    cu_path = cu_path.replace(replacing_str , SRC_N_BIN_PATH)\n",
    "    return cu_path\n",
    "\n",
    "def check_dwarf_ok(filePath):\n",
    "    with open(filePath, 'rb') as f:\n",
    "        try:\n",
    "            \n",
    "            elffile = ELFFile( f )\n",
    "            if not elffile.has_dwarf_info():\n",
    "                print('  file has no DWARF info')\n",
    "                return False\n",
    "            dwarfinfo = elffile.get_dwarf_info()\n",
    "\n",
    "        \n",
    "            if len(list(dwarfinfo.iter_CUs()))==0:\n",
    "                return False\n",
    "            for CU in dwarfinfo.iter_CUs():\n",
    "                CU_DIR_PATH = None\n",
    "                CU_FILENAME = None\n",
    "                for attr in CU.get_top_DIE().attributes.values():\n",
    "#                     if attr.name == 'DW_AT_comp_dir':\n",
    "#                         CU_DIR_PATH = fix_src_path(attr.value.decode(\"utf-8\"))\n",
    "                    if attr.name == 'DW_AT_name':\n",
    "                        CU_DIR_PATH = os.path.dirname(attr.value.decode(\"utf-8\"))\n",
    "                        CU_FILENAME = os.path.basename(attr.value.decode(\"utf-8\"))\n",
    "                if CU_DIR_PATH==None or CU_FILENAME==None:\n",
    "                    return False\n",
    "                line_program = dwarfinfo.line_program_for_CU(CU)\n",
    "                if line_program is None:\n",
    "                    print('  DWARF info is missing a line program for this CU')\n",
    "                    return False\n",
    "            return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "            print(exc_type, fname, exc_tb.tb_lineno)\n",
    "            print(traceback.format_exc())\n",
    "\n",
    "            return False\n",
    "\n",
    "def get_min_max_address(filePath):\n",
    "    with open(filePath, 'rb') as f:\n",
    "        elffile = ELFFile(f)\n",
    "\n",
    "        dwarfinfo = elffile.get_dwarf_info()\n",
    "        min_address = 10000000000000\n",
    "        max_address = -100000000000\n",
    "        for CU in dwarfinfo.iter_CUs():\n",
    "            CU_DIR_PATH = None\n",
    "            CU_FILENAME = None\n",
    "            for attr in CU.get_top_DIE().attributes.values():\n",
    "#                 if attr.name == 'DW_AT_comp_dir':\n",
    "#                     CU_DIR_PATH = fix_src_path(attr.value.decode(\"utf-8\"))\n",
    "                if attr.name == 'DW_AT_name':\n",
    "                    CU_DIR_PATH = os.path.dirname(attr.value.decode(\"utf-8\"))\n",
    "                    CU_FILENAME = os.path.basename(attr.value.decode(\"utf-8\"))\n",
    "\n",
    "            line_program = dwarfinfo.line_program_for_CU(CU)\n",
    "\n",
    "\n",
    "            for line_entry in line_program.get_entries():\n",
    "                \n",
    "                if line_entry.state!= None:\n",
    "                    src_file_name = line_program.header['file_entry'][line_entry.state.file-1].name.decode(\"utf-8\")\n",
    "                    if src_file_name==CU_FILENAME: # no match means library C code\n",
    "#                         if line_entry.state.line in bounds_matrix: #not always presend as disabled code might be present\n",
    "                        if line_entry.state.address>max_address:\n",
    "                            max_address = line_entry.state.address\n",
    "            \n",
    "                        if line_entry.state.address <min_address:\n",
    "                            min_address = line_entry.state.address\n",
    "    return min_address,max_address\n",
    "         \n",
    "def get_valid_instructions (filePath, addr_list, min_address, max_address):\n",
    "\n",
    "    fh = open(filePath, 'rb')\n",
    "    bin_bytearray = bytearray(fh.read())\n",
    "\n",
    "    address_inst = {}\n",
    "    \n",
    "    md = Cs(CS_ARCH_X86, CS_MODE_64)\n",
    "    md.detail = True\n",
    "    \n",
    "    for addr in addr_list:\n",
    "        \n",
    "\n",
    "        ops = bin_bytearray[addr: ]\n",
    "\n",
    "        #TODO make efficient\n",
    "        for inst in md.disasm(ops, addr):\n",
    "            if inst.address<=max_address and inst.address>=min_address:\n",
    "                address_inst[inst.address] = inst\n",
    "            break\n",
    "            \n",
    "    address_inst = collections.OrderedDict(sorted(address_inst.items()))\n",
    "    return address_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bbd1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e22580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def line_entry_mapping(line_program,CU):\n",
    "    filename_map = defaultdict(int)\n",
    "\n",
    "    # The line program, when decoded, returns a list of line program\n",
    "    # entries. Each entry contains a state, which we'll use to build\n",
    "    # a reverse mapping of filename -> #entries.\n",
    "    lp_entries = line_program.get_entries()\n",
    "    if len(lp_entries)==0:\n",
    "        return None\n",
    "    for lpe in lp_entries:\n",
    "        # We skip LPEs that don't have an associated file.\n",
    "        # This can happen if instructions in the compiled binary\n",
    "        # don't correspond directly to any original source file.\n",
    "        if not lpe.state:# or lpe.state.file == 0\n",
    "            continue\n",
    "        filename = lpe_filename(line_program, lpe.state.file,CU)[0]\n",
    "        filename_map[filename] += 1\n",
    "\n",
    "    # for filename, lpe_count in filename_map.items():\n",
    "    #     print(\"    filename=%s -> %d entries\" % (filename, lpe_count))\n",
    "    return filename_map\n",
    "\n",
    "def lpe_filename(line_program, file_index, CU):\n",
    "    \n",
    "    \n",
    "    die_dict = {}                    \n",
    "    for attr in CU.get_top_DIE().attributes.values():\n",
    "        die_dict[attr.name] = attr\n",
    "    \n",
    "    \n",
    "    compilation_command = die_dict['DW_AT_producer'].value.decode(\"utf-8\")\n",
    "    \n",
    "    if 'clang' in compilation_command.lower():\n",
    "        COMPILER_SUBSTRACT = 1\n",
    "    elif 'gnu' in compilation_command.lower():\n",
    "        COMPILER_SUBSTRACT = 0\n",
    "    lp_header = line_program.header\n",
    "    file_entries = lp_header[\"file_entry\"]\n",
    "#     print(COMPILER_SUBSTRACT, compilation_command)\n",
    "    \n",
    "    # File and directory indices are 1-indexed.\n",
    "    file_entry = file_entries[file_index -COMPILER_SUBSTRACT]\n",
    "    dir_index = file_entry[\"dir_index\"]\n",
    "\n",
    "    # A dir_index of 0 indicates that no absolute directory was recorded during\n",
    "    # compilation; return just the basename.\n",
    "    if dir_index == 0:\n",
    "        return file_entry.name.decode(),dir_index\n",
    "    directory = lp_header[\"include_directory\"][dir_index -COMPILER_SUBSTRACT]\n",
    "    return posixpath.join(directory, file_entry.name).decode(),dir_index\n",
    "\n",
    "\n",
    "def show_loclist(loclist, dwarfinfo, indent, cu_offset):\n",
    "    \"\"\" Display a location list nicely, decoding the DWARF expressions\n",
    "        contained within.\n",
    "    \"\"\"\n",
    "    d = []\n",
    "    for loc_entity in loclist:\n",
    "        if isinstance(loc_entity, LocationEntry):\n",
    "            d.append('%s <<%s>>' % (\n",
    "                loc_entity,\n",
    "                describe_DWARF_expr(loc_entity.loc_expr, dwarfinfo.structs, cu_offset)))\n",
    "        else:\n",
    "            d.append(str(loc_entity))\n",
    "    return '\\n'.join(indent + s for s in d)\n",
    "\n",
    "\n",
    "########################################################\n",
    "######################   DWARF PERSER #######################\n",
    "###########################################################\n",
    "\n",
    "\n",
    "def get_DIE_at_offset(CU, offset):\n",
    "        for die in CU.iter_DIEs():\n",
    "            if die.offset == CU.cu_offset+offset:\n",
    "                return die \n",
    "        return None\n",
    "\n",
    "\n",
    "##TODO FIX CONSTANT TYPE\n",
    "def get_type_name(CU, offset):#get_DIE_at_offset(CU,attr.value)\n",
    "    die = get_DIE_at_offset(CU, offset)\n",
    "    \n",
    "    if die.tag == 'DW_TAG_const_type':\n",
    "        return \"const\"\n",
    "    \n",
    "    if die.tag == 'DW_TAG_pointer_type' :\n",
    "        for _attr in die.attributes.values():\n",
    "            if _attr.name== \"DW_AT_type\":\n",
    "                \n",
    "                return \"*\"+get_type_name(CU, _attr.value) \n",
    "\n",
    "    elif die.tag =='DW_TAG_subroutine_type':\n",
    "        \n",
    "\n",
    "        for _attr in die.attributes.values():\n",
    "            if _attr.name== \"DW_AT_sibling\":\n",
    "                return get_type_name(CU, _attr.value) \n",
    "            \n",
    "            if _attr.name== \"DW_AT_type\":\n",
    "                return \"*\"+get_type_name(CU, _attr.value) \n",
    "\n",
    "    for attr in die.attributes.values():\n",
    "        if attr.name== \"DW_AT_name\":\n",
    "            return attr.value.decode(\"utf-8\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "############################################################\n",
    "############################# CLANG #######################\n",
    "###########################################################\n",
    "\n",
    "# FUNCTION_DECL\n",
    "# https://stackoverflow.com/questions/43460605/function-boundary-identification-using-libclang\n",
    "# https://eli.thegreenplace.net/2011/07/03/parsing-c-in-python-with-clang\n",
    "\n",
    "            \n",
    "def get_function_boundaries(source_path): #TODO does not perse disabled Source code,not needed anyway\n",
    "    \n",
    "    function_boundary_by_name = {}\n",
    "    idx = clang.cindex.Index.create()\n",
    "    tu = idx.parse(source_path)\n",
    "\n",
    "    for f in tu.cursor.walk_preorder():\n",
    "        \n",
    "        if f.kind == clang.cindex.CursorKind.FUNCTION_DECL:\n",
    "\n",
    "            function_name = f.displayname.split('(')[0]\n",
    "            function_boundary_by_name[function_name]={}\n",
    "            function_boundary_by_name[function_name] = { 'src_path':f.extent.start.file.name,\n",
    "                              'src_file':f.extent.start.file.name.split('/')[-1],\n",
    "                              'start_line':f.extent.start.line,\n",
    "                              'start_col':f.extent.start.column,\n",
    "                              'end_line':f.extent.end.line,\n",
    "                              'end_col':f.extent.end.column}\n",
    "\n",
    "    return function_boundary_by_name\n",
    "\n",
    "def get_containing_function(source_file_path, line, col=0):\n",
    "    function_boundary_by_name = get_function_boundaries(source_file_path)\n",
    "    \n",
    "    for function_name, item in function_boundary_by_name.items():\n",
    "        if item['src_path'] == source_file_path:\n",
    "            if line>= item['start_line'] and line<= item['end_line']:\n",
    "                return function_name\n",
    "        \n",
    "\n",
    "def form_function_bound_metrix(src_bounds, src_file_name):\n",
    "    bounds = {}\n",
    "    for func_info in src_bounds.items():\n",
    "        if func_info[1]['src_file'] == src_file_name:\n",
    "            start_line  = func_info[1]['start_line']\n",
    "            end_line    = func_info[1]['end_line']\n",
    "#             print(func_info[0] ,start_line , end_line)\n",
    "            for i in range(start_line , end_line+1):\n",
    "                bounds[i] = func_info[0]\n",
    "               \n",
    "    return bounds\n",
    "\n",
    "\n",
    "\n",
    "def find_variables_per_line(source_path , line_to_function_matrix , dwarf_FUNC_PARAMS):\n",
    "    srcFileName = source_path.split('/')[-1]\n",
    "    idx = clang.cindex.Index.create()\n",
    "    tu = idx.parse(source_path)\n",
    "    var_usage_matrix = {}\n",
    "    for f in tu.cursor.walk_preorder():\n",
    "\n",
    "        #TODO keep all with type info, explore CursorKind\n",
    "        #TODO function ends  }  should relate with fucntion return type\n",
    "        \n",
    "        if f.kind in [CursorKind.PARM_DECL ,CursorKind.DECL_REF_EXPR, CursorKind.VAR_DECL]  :\n",
    "            \n",
    "            originFileName = f.extent.start.file.name.split('/')[-1]\n",
    "            \n",
    "            if srcFileName!=originFileName:\n",
    "                continue\n",
    "\n",
    "\n",
    "            line = f.extent.start.line\n",
    "            col =f.extent.start.column\n",
    "            type_info = f.type.spelling\n",
    "            var_name = f.displayname\n",
    "\n",
    "            if line not in var_usage_matrix:\n",
    "                var_usage_matrix[line] = {}\n",
    "\n",
    "            if line in line_to_function_matrix:# func declaration, global variables,  might not present\n",
    "                if line_to_function_matrix[line] in dwarf_FUNC_PARAMS[source_path]:\n",
    "                    #because wiredrly some function info are not in DWARF INFO\n",
    "                    if var_name in dwarf_FUNC_PARAMS[source_path][line_to_function_matrix[line]]:\n",
    "                        var_usage_matrix[line][col] = {\n",
    "                                        'name'       : f.displayname ,\n",
    "                                        'dwarf_info' : dwarf_FUNC_PARAMS[source_path][line_to_function_matrix[line]][var_name],\n",
    "                                        'type'       : f.type.spelling }\n",
    "    return var_usage_matrix\n",
    "\n",
    "            \n",
    "###################################################################\n",
    "########  Find Src Code by filepath, line and col no  #############\n",
    "##################################################################\n",
    "\n",
    "def getSource(sourceFilePath, row , col):\n",
    "    sourceFile = open(sourceFilePath, \"r\")\n",
    "    fileContent = sourceFile.readlines()\n",
    "    row_content =  fileContent[row-1]\n",
    "    row_content = row_content[:(col-1)] + '|'+row_content[(col-1)]+'|' +row_content[col:]\n",
    "    \n",
    "    return row_content\n",
    "\n",
    "######################################3#########\n",
    "########### ILLUSTRATE in file ##################\n",
    "#################################################\n",
    "def write_illustrated_file(bin_fname ,lineinfo_address_subprogram_complete , all_inst_type):\n",
    "\n",
    "    REGISTER_SUBSTRACT_FACTOR = -0\n",
    "    save_path = os.path.join(ILLUSTRATION_LOG_PATH , (bin_fname+'.s'))\n",
    "    \n",
    "    with open(save_path, 'w') as outFile:\n",
    "        # outFile.write('file contents\\n')\n",
    "        lastSource = \"\"\n",
    "        for address in VALID_INSTRUCTIONS_SET:\n",
    "            address_hex = hex(address)\n",
    "            inst = VALID_INSTRUCTIONS_SET[address]\n",
    "            instrctionCode = (address_hex+\":\\t\"+ inst.mnemonic+\" \"+inst.op_str).ljust(45)\n",
    "\n",
    "            OFFSET = None\n",
    "            if len(inst.operands) > 0 :\n",
    "                c=-1\n",
    "                for o in inst.operands:\n",
    "                    c += 1\n",
    "                    if o.type == CS_OP_MEM:\n",
    "#                         print(\"\\t\\toperands[%u].type: MEM\" %c)\n",
    "                        if o.value.mem.base != 0:\n",
    "                            pass\n",
    "#                             print(\"\\t\\t\\toperands[%u].mem.base: REG = %s\" \\\n",
    "#                                 %(c, inst.reg_name(o.value.mem.base)))\n",
    "                        if o.value.mem.index != 0:\n",
    "                            pass\n",
    "#                             print(\"\\t\\t\\toperands[%u].mem.index: REG = %s\" \\\n",
    "#                                 %(c, inst.reg_name(o.value.mem.index)))\n",
    "                        if o.value.mem.disp != 0:\n",
    "#                             print(\"\\t\\t\\toperands[%u].mem.disp: 0x%x\" \\\n",
    "#                                 %(c, o.value.mem.disp))\n",
    "                            OFFSET = o.value.mem.disp\n",
    "#                         print(hex(o.value.mem.disp),o.value.mem.disp)\n",
    "\n",
    "\n",
    "            if address in lineinfo_address_subprogram_complete:\n",
    "                if lineinfo_address_subprogram_complete[address]['lineinfo'].address == address: \n",
    "                    srcFilePath = lineinfo_address_subprogram_complete[address]['srcPath']\n",
    "                    if srcFilePath!=lastSource:\n",
    "                        outFile.write(\"\\n\"+ '#'*100+\"\\n\"+ srcFilePath.rjust(45) +'\\n'+'#'*100+ \"\\n\\n\")\n",
    "                        lastSource = srcFilePath\n",
    "\n",
    "\n",
    "                    src_line_no  = lineinfo_address_subprogram_complete[address]['lineinfo'].line\n",
    "                    src_col_no   = lineinfo_address_subprogram_complete[address]['lineinfo'].column\n",
    "                    sourceCode = getSource(srcFilePath,src_line_no, src_col_no)\n",
    "                    function_name = lineinfo_address_subprogram_complete[address]['func']\n",
    "\n",
    "\n",
    "                    if '\\n' not in  sourceCode:\n",
    "                        sourceCode+=sourceCode+\"\\n\"\n",
    "                    outFile.write(instrctionCode+\"#\"+ sourceCode  )\n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "                    outFile.write(instrctionCode+ '\\n'  )\n",
    "                \n",
    "                #Write TYPE info\n",
    "                if hex(address) in all_inst_type:\n",
    "                    if all_inst_type[hex(address)] is not None:\n",
    "                        outFile.write('TYPE:>  [ '+all_inst_type[hex(address)]+' ]\\n')\n",
    "                    else:\n",
    "                        outFile.write('TYPE:>  [ NONE ]\\n')\n",
    "\n",
    "                            \n",
    "                if OFFSET:\n",
    "                    outFile.write(\"MEMORY OFFSET:     \"+str(hex(OFFSET))+\"     \"+str(OFFSET)+ \"  >>\"+str(OFFSET-REGISTER_SUBSTRACT_FACTOR)+'\\n\\n')\n",
    "                    pass\n",
    "######################################3#########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################\n",
    "########### Find variables in each src line  ##########\n",
    "######################################3################\n",
    "\n",
    "def create_variable_per_line_matrix(filename ,FUNCTION_PARAMS):\n",
    "    variables_in_line_matrix_all_files = {}\n",
    "#     print('Processing file:', filename)\n",
    "    with open(filename, 'rb') as f:\n",
    "        elffile = ELFFile(f)\n",
    "\n",
    "        if not elffile.has_dwarf_info():\n",
    "            print('  file has no DWARF info')\n",
    "            return\n",
    "        dwarfinfo = elffile.get_dwarf_info()\n",
    "\n",
    "        location_lists = dwarfinfo.location_lists()\n",
    "        \n",
    "\n",
    "        # This is required for the descriptions module to correctly decode\n",
    "        # register names contained in DWARF expressions.\n",
    "        set_global_machine_arch(elffile.get_machine_arch())\n",
    "\n",
    "        loc_parser = LocationParser(location_lists)\n",
    "        section_offset = dwarfinfo.debug_info_sec.global_offset\n",
    "        # Offset of the .debug_info section in the stream\n",
    "        \n",
    "        \n",
    "        for CU in dwarfinfo.iter_CUs():\n",
    "            CU_DIR_PATH = None\n",
    "            CU_FILENAME = None\n",
    "            for attr in CU.get_top_DIE().attributes.values():#TODO fix\n",
    "#                 if attr.name == 'DW_AT_comp_dir':\n",
    "#                     CU_DIR_PATH = fix_src_path(attr.value.decode(\"utf-8\"))\n",
    "                if attr.name == 'DW_AT_name':\n",
    "                    CU_DIR_PATH = os.path.dirname(attr.value.decode(\"utf-8\"))\n",
    "                    CU_FILENAME = os.path.basename(attr.value.decode(\"utf-8\"))\n",
    "\n",
    "            #########\n",
    "            cu_src_path = os.path.join(CU_DIR_PATH, CU_FILENAME)\n",
    "            cu_func_boundaries =get_function_boundaries(cu_src_path )\n",
    "            cu_src_line_to_function_matrix = form_function_bound_metrix(cu_func_boundaries , CU_FILENAME)\n",
    "            variables_in_line_matrix = find_variables_per_line(cu_src_path, cu_src_line_to_function_matrix , FUNCTION_PARAMS)\n",
    "            variables_in_line_matrix_all_files[cu_src_path] = variables_in_line_matrix\n",
    "            #########\n",
    "    return variables_in_line_matrix_all_files\n",
    "\n",
    "##########################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################## #######################\n",
    "######### UTIL funcs related to aligning inst offset to dwarf location offset ########\n",
    "########################################################################################\n",
    "def diff_dict(matrix):\n",
    "    for i in range (len(matrix.keys()) -1):\n",
    "            ith_key = [*matrix.keys()][i]\n",
    "            i_plus_1th_key = [*matrix.keys()][i+1]\n",
    "            matrix[ith_key] = matrix[ith_key] -matrix[i_plus_1th_key] \n",
    "    return matrix\n",
    "\n",
    "def vars_to_types(var_list, cu_path, func):\n",
    "    types=[]\n",
    "    for variable_name in var_list:\n",
    "        types.append(FUNC_PARAMS[cu_path][func][variable_name]['type'])\n",
    "    return types\n",
    "\n",
    "\n",
    "#todo try func to address \n",
    "def build_line_to_relatedAddresses_matrix(address_lineinfo):#lineinfo_address_subprogram_complete\n",
    "    line_address = {}\n",
    "    for address  in VALID_INSTRUCTIONS_SET:#address_lineinfo.items():\n",
    "        info = address_lineinfo[address]\n",
    "        line          = info['lineinfo'].line\n",
    "        col           = info['lineinfo'].column\n",
    "        src_filepath  = info['srcPath']\n",
    "        func          = info['func']\n",
    "        \n",
    "        key= str(line)+\"_\"+ str(col)\n",
    "        \n",
    "        if src_filepath not in line_address:\n",
    "            line_address[src_filepath] ={}\n",
    "        if func not in line_address[src_filepath]:\n",
    "            line_address[src_filepath][func] = {}\n",
    "        if key not in line_address[src_filepath][func]:\n",
    "            line_address[src_filepath][func][key] = []\n",
    "        \n",
    "        line_address[src_filepath][func][key].append(address)\n",
    "        \n",
    "    return line_address\n",
    "\n",
    "def assign_twin_instructions_types(addr_list, type_list, twin_dict):\n",
    "        inst_to_type_dict = dict(zip(addr_list, type_list))\n",
    "\n",
    "        for main_address, twin_list in twin_dict.items():\n",
    "            for twin in twin_list:\n",
    "                if main_address in inst_to_type_dict:\n",
    "                    inst_to_type_dict[twin] = inst_to_type_dict[main_address]\n",
    "        return inst_to_type_dict\n",
    "         \n",
    "\n",
    "\n",
    "\n",
    "######################### ENFD UTILs ####################################\n",
    "\n",
    "\n",
    "\n",
    "######################################################################## ######\n",
    "############## parse DWARF info and create FUNC_PARAMS which   ##############\n",
    "#############  contains all the dwarf info about func perams, varts etc ####\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "def parse_dwarf_to_get_func_params(filename):\n",
    "    FUNC_PARAMS_DICT = {}\n",
    "    print('Processing file:', filename)\n",
    "    with open(filename, 'rb') as f:\n",
    "        elffile = ELFFile(f)\n",
    "\n",
    "        if not elffile.has_dwarf_info():\n",
    "            print('  file has no DWARF info')\n",
    "            return\n",
    "\n",
    "        # get_dwarf_info returns a DWARFInfo context object, which is the\n",
    "        # starting point for all DWARF-based processing in pyelftools.\n",
    "        dwarfinfo = elffile.get_dwarf_info()\n",
    "        # The location lists are extracted by DWARFInfo from the .debug_loc\n",
    "        # section, and returned here as a LocationLists object.\n",
    "        location_lists = dwarfinfo.location_lists()\n",
    "        \n",
    "\n",
    "        # This is required for the descriptions module to correctly decode\n",
    "        # register names contained in DWARF expressions.\n",
    "        set_global_machine_arch(elffile.get_machine_arch())\n",
    "\n",
    "        # Create a LocationParser object that parses the DIE attributes and\n",
    "        # creates objects representing the actual location information.\n",
    "        loc_parser = LocationParser(location_lists)\n",
    "        section_offset = dwarfinfo.debug_info_sec.global_offset\n",
    "        # Offset of the .debug_info section in the stream\n",
    "        \n",
    "        \n",
    "        for CU in dwarfinfo.iter_CUs():\n",
    "            CU_DIR_PATH = None\n",
    "            CU_FILENAME = None\n",
    "            for attr in CU.get_top_DIE().attributes.values():\n",
    "                if attr.name == 'DW_AT_comp_dir':\n",
    "                    CU_DIR_PATH = fix_src_path(attr.value.decode(\"utf-8\"))\n",
    "                if attr.name == 'DW_AT_name'    :\n",
    "                    CU_FILENAME = (attr.value.decode(\"utf-8\"))\n",
    "\n",
    "            line_program = dwarfinfo.line_program_for_CU(CU)\n",
    "\n",
    "         \n",
    "            CU_dictionary_key = os.path.join(CU_DIR_PATH, CU_FILENAME)\n",
    "            if CU_dictionary_key not in FUNC_PARAMS_DICT:\n",
    "                FUNC_PARAMS_DICT[CU_dictionary_key] = {}\n",
    "            \n",
    "\n",
    "\n",
    "            # A CU provides a simple API to iterate over all the DIEs in it.\n",
    "            die_depth = 0\n",
    "            are_DIEs_of_function = False\n",
    "            FUNC_name = None\n",
    "            for DIE in CU.iter_DIEs():\n",
    "                \n",
    "                ############################################################\n",
    "                #############   Prasing Function DIEs start ################\n",
    "\n",
    "                \n",
    "                if DIE.tag == 'DW_TAG_subprogram':\n",
    "                    if 'DW_AT_low_pc' in DIE.attributes and 'DW_AT_high_pc' in DIE.attributes :\n",
    "                        low_pc = DIE.attributes['DW_AT_low_pc'].value\n",
    "                        high_pc = DIE.attributes['DW_AT_high_pc'].value\n",
    "                        \n",
    "#                         print(\"Low PC: \",hex(low_pc) , \" High PC\" , hex(high_pc))\n",
    "                    else:\n",
    "                        pass\n",
    "#                         print(\"NO PC given\")\n",
    "                    are_DIEs_of_function = True\n",
    "                    \n",
    "                    for attr in DIE.attributes.values():\n",
    "                        if attr.name == \"DW_AT_name\": #FUNC NAME\n",
    "                            FUNC_name = attr.value.decode(\"utf-8\")\n",
    "                            if FUNC_name not in FUNC_PARAMS_DICT[CU_dictionary_key]:\n",
    "                                FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name] ={}\n",
    "#                             print(\"SUBPROGRAM: \",FUNC_name)\n",
    "                            \n",
    "                if DIE.tag in[ 'DW_TAG_formal_parameter','DW_TAG_variable' ,'DW_TAG_member']:\n",
    "                    tags = [attr.name for attr in DIE.attributes.values()]\n",
    "                    PARAM_name = None\n",
    "                    if FUNC_name==None:\n",
    "                        \n",
    "                        FUNC_name =\"global\"\n",
    "                        \n",
    "                        if FUNC_name not in FUNC_PARAMS_DICT[CU_dictionary_key]:\n",
    "                            FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name]={}\n",
    "                        \n",
    "                    if \"DW_AT_name\" in tags:\n",
    "                        \n",
    "                        die_dict = {}\n",
    "                        \n",
    "                        for attr in DIE.attributes.values():\n",
    "                            die_dict[attr.name] = attr\n",
    "                        \n",
    "                        PARAM_name = die_dict['DW_AT_name'].value.decode(\"utf-8\")\n",
    "                        \n",
    "                        if PARAM_name not in FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name]:\n",
    "                            FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name][PARAM_name] = {}\n",
    "                        var_type = DIE.tag.split('_')[-1]\n",
    "                        FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name][PARAM_name] = {'type':get_type_name(CU,die_dict['DW_AT_type'].value) , 'kind':var_type}\n",
    "                        \n",
    "#                         print(die_dict)\n",
    "                        # Check if this attribute contains location information\n",
    "#                         if loc_parser.attribute_has_location(die_dict['DW_AT_location'], CU['version']):\n",
    "                        if 'DW_AT_location' in die_dict:\n",
    "\n",
    "                            try:\n",
    "                                loc = loc_parser.parse_from_attribute(die_dict['DW_AT_location'],\n",
    "                                                                      CU['version'])\n",
    "                                \n",
    "#                                 print(CU_dictionary_key,FUNC_name,PARAM_name)\n",
    "                                if isinstance(loc, LocationExpr):\n",
    "                                    loc_info_str = describe_DWARF_expr(loc.loc_expr, dwarfinfo.structs, CU.cu_offset)\n",
    "                                    offset_temp = (loc_info_str.split('-')[-1]).split(')')[0]\n",
    "#                                     print('1a ',loc_info_str, offset_temp)\n",
    "#                                     print('1b ', PARAM_name,loc_info_str, int(offset_temp)-LOCATION_SUBSTRACT_FACTOR)\n",
    "                                    FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name][PARAM_name][\"location\"]= loc_info_str\n",
    "\n",
    "                                elif isinstance(loc, list):\n",
    "#                                     print(PARAM_name,show_loclist(loc,dwarfinfo,'      ', CU.cu_offset))\n",
    "                                    FUNC_PARAMS_DICT[CU_dictionary_key][FUNC_name][PARAM_name][\"location\"]= show_loclist(loc,\n",
    "                                                       dwarfinfo,'      ', CU.cu_offset)\n",
    "                            except:\n",
    "\n",
    "                                print(\"ERROR\",DIE)\n",
    "                                pass\n",
    "\n",
    "                ###############################################\n",
    "                #############  parsing  Function DIEs ends ################\n",
    "                \n",
    "\n",
    "\n",
    "                \n",
    "                if DIE.is_null(): #https://chromium.googlesource.com/chromiumos/third_party/pyelftools/+/25a77f7738d7fe824f2ed4d33a123136b9d8e88a/scripts/readelf.py\n",
    "                    are_DIEs_of_function = False\n",
    "                    FUNC_name = None\n",
    "                    \n",
    "                    die_depth -= 1\n",
    "                    continue\n",
    "                if DIE.has_children:\n",
    "                    die_depth += 1\n",
    "    \n",
    "    \n",
    "    return FUNC_PARAMS_DICT\n",
    "\n",
    "#############################  END FUNC PARAMS dictionary ######################\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "#################   create matrix for finding lineinfo for each address #################\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "def produce_address_to_lineinfo_matrix(bin_path):\n",
    "    lineinfo_address_subprogram = {}\n",
    "    with open(bin_path, 'rb') as f:\n",
    "        elffile = ELFFile(f)\n",
    "\n",
    "        if not elffile.has_dwarf_info():\n",
    "            print('  file has no DWARF info')\n",
    "            exit(0)\n",
    "\n",
    "        dwarfinfo = elffile.get_dwarf_info()\n",
    "        for CU in dwarfinfo.iter_CUs():\n",
    "            CU_DIR_PATH = None\n",
    "            CU_FILENAME = None\n",
    "            for attr in CU.get_top_DIE().attributes.values():\n",
    "#                 if attr.name == 'DW_AT_comp_dir':\n",
    "#                     CU_DIR_PATH = fix_src_path(attr.value.decode(\"utf-8\"))\n",
    "                if attr.name == 'DW_AT_name':\n",
    "                    CU_DIR_PATH = os.path.dirname(attr.value.decode(\"utf-8\"))\n",
    "                    CU_FILENAME = os.path.basename(attr.value.decode(\"utf-8\"))\n",
    "\n",
    "\n",
    "            # Every compilation unit in the DWARF information may or may not\n",
    "            # have a corresponding line program in .debug_line.\n",
    "            line_program = dwarfinfo.line_program_for_CU(CU)\n",
    "            if line_program is None:\n",
    "                print('  DWARF info is missing a line program for this CU')\n",
    "                continue\n",
    "\n",
    "            \n",
    "            cu_file_path  = os.path.join(CU_DIR_PATH, CU_FILENAME)\n",
    "            \n",
    "            bounds_matrix = form_function_bound_metrix( get_function_boundaries(cu_file_path)  , CU_FILENAME)\n",
    "\n",
    "\n",
    "            for line_entry in line_program.get_entries():\n",
    "                if line_entry.state!= None:\n",
    "                    src_file_name = line_program.header['file_entry'][line_entry.state.file-1].name.decode(\"utf-8\")\n",
    "                    if src_file_name==CU_FILENAME: # no match means library C code\n",
    "\n",
    "                        if line_entry.state.line in bounds_matrix: #not always presend as disabled code might be present\n",
    "                            lineinfo_address_subprogram[line_entry.state.address]  =   {\n",
    "                                'func':bounds_matrix[line_entry.state.line], \n",
    "                                'srcPath':cu_file_path,\n",
    "                                'lineinfo':line_entry.state\n",
    "                            } \n",
    "\n",
    "\n",
    "    #TODO make efficient with valid address only\n",
    "\n",
    "    lineinfo_address_subprogram = collections.OrderedDict(sorted(lineinfo_address_subprogram.items()))\n",
    "    lineinfo_address_subprogram_all_address = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    temp_subprogram = lineinfo_address_subprogram[MIN_ADDRESS]\n",
    "    for i in range(MIN_ADDRESS,MAX_ADDRESS+1):\n",
    "        if i in lineinfo_address_subprogram:\n",
    "            temp_subprogram = lineinfo_address_subprogram[i]\n",
    "        lineinfo_address_subprogram_all_address[i] = temp_subprogram\n",
    "    \n",
    "    return lineinfo_address_subprogram_all_address\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e696f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## analyzed data preprocess\n",
    "#### it merges the subgraphs. Then find the basic blocks that encapsulate the merged graphs\n",
    "#############################################################\n",
    "def process_graphs(ins_data):\n",
    "\n",
    "    merged_ins_data= {}\n",
    "\n",
    "\n",
    "    for fname, connected_comps in ins_data.items():\n",
    "        Graph = nx.DiGraph()\n",
    "        for ia, connected_comp in enumerate(connected_comps):\n",
    "            for addr in connected_comp:\n",
    "                if int(addr,16)>=MIN_ADDRESS and int(addr,16)<=MAX_ADDRESS:\n",
    "                    Graph.add_node(addr)\n",
    "\n",
    "        all_nodes = list(Graph.nodes)\n",
    "        for k in range(len(all_nodes)-1):\n",
    "            Graph.add_edge(all_nodes[k] , all_nodes[k+1])\n",
    "\n",
    "        merged_conn_comps = list(nx.weakly_connected_components(Graph) )\n",
    "        merged_conn_comps = [ list(i) for i in merged_conn_comps]\n",
    "\n",
    "\n",
    "\n",
    "        merged_ins_data[fname] = merged_conn_comps\n",
    "    \n",
    "    \n",
    "    valid_addresses_set= VALID_INSTRUCTIONS_SET.keys()\n",
    "    connected_comps_and_slice=[]\n",
    "    for fname, connected_comps in merged_ins_data.items():\n",
    "\n",
    "        for connected_comp in connected_comps:\n",
    "            if len(connected_comp)<2:\n",
    "                continue\n",
    "            bbs = []\n",
    "            for addr in connected_comp:\n",
    "                addr_int = int(addr, 16)\n",
    "                if addr_int not in bb_data: #address out of scope\n",
    "                    continue\n",
    "                bb_inf = bb_data[addr_int]  \n",
    "\n",
    "                if bb_inf not in bbs:\n",
    "                    bbs.append(bb_inf)\n",
    "            #TODO merge ranges to make faster\n",
    "            ## get the instructions in the bbs\n",
    "            bb_min = min([bb[0] for bb in bbs])\n",
    "            bb_max = max([bb[1] for bb in bbs])\n",
    "            \n",
    "            #\n",
    "            program_slice=[]\n",
    "            for addr in valid_addresses_set:\n",
    "                if addr<bb_min or addr>bb_max:\n",
    "                    continue\n",
    "                \n",
    "                if any( lower<=addr<=upper  for (lower,upper) in bbs):\n",
    "                    program_slice.append(addr)\n",
    "            \n",
    "            #TODO find a better way to discard samples\n",
    "            if len(connected_comp)>5:\n",
    "#                 print(MIN_ADDRESS, MAX_ADDRESS)\n",
    "#                 print(bbs,bb_min,bb_max)\n",
    "#                 print([ int(a,16) for a in connected_comp], program_slice )\n",
    "#                 print('\\n\\n\\n')\n",
    "                connected_comps_and_slice.append({'connected_comp': [ int(a,16) for a in connected_comp], 'program_slice':program_slice } )\n",
    "        \n",
    "    return connected_comps_and_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c8fcc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahid/anaconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x04-more_functions_nested_loops/9-fizz_buzz_elf_file_\n",
      "{4469: 'int', 4481: 'int', 4550: 'int', 4610: 'int', 4698: 'int', 4714: 'int', 4718: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x04-more_functions_nested_loops/100-prime_factor_elf_file_\n",
      "{}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0E-structures_typedef/3-main_elf_file_\n",
      "{}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0E-structures_typedef/0-main_elf_file_\n",
      "{}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/1-last_digit_elf_file_\n",
      "{4592: 'int', 4635: 'int', 4595: 'int', 4638: 'int', 4641: 'int', 4666: 'int', 4692: 'int', 4718: 'int', 4724: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/0-positive_or_negative_elf_file_\n",
      "{4560: 'int', 4563: 'int', 4596: 'int'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/101-print_comb4_elf_file_\n",
      "{4437: 'int', 4455: 'int', 4449: 'int', 4469: 'int', 4463: 'int', 4477: 'int', 4519: 'int', 4529: 'int', 4571: 'int', 4581: 'int', 4623: 'int', 4702: 'int', 4706: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/100-print_comb3_elf_file_\n",
      "{4437: 'int', 4455: 'int', 4449: 'int', 4463: 'int', 4505: 'int', 4515: 'int', 4557: 'int', 4616: 'int', 4620: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/2-print_alphabet_elf_file_\n",
      "{4437: 'char', 4443: 'char', 4454: 'char', 4461: 'char', 4464: 'char'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/9-print_comb_elf_file_\n",
      "{4437: 'int', 4446: 'int', 4488: 'int', 4498: 'int', 4527: 'int', 4531: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/4-print_alphabt_elf_file_\n",
      "{4437: 'char', 4443: 'char', 4449: 'char', 4455: 'char', 4466: 'char', 4473: 'char', 4476: 'char'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/8-print_base16_elf_file_\n",
      "{4437: 'int', 4446: 'int', 4488: 'int', 4498: 'int', 4502: 'int', 4508: 'char', 4514: 'char', 4525: 'char', 4532: 'char', 4535: 'char'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/7-print_tebahpla_elf_file_\n",
      "{4437: 'int', 4446: 'int', 4456: 'int', 4460: 'int'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/3-print_alphabets_elf_file_\n",
      "{4437: 'char', 4443: 'char', 4454: 'char', 4461: 'char', 4464: 'char', 4470: 'char', 4476: 'char', 4487: 'char', 4494: 'char', 4497: 'char'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/6-print_numberz_elf_file_\n",
      "{4437: 'int', 4446: 'int', 4488: 'int', 4498: 'int', 4502: 'int'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/102-print_comb5_elf_file_\n",
      "{4437: 'int', 4449: 'int', 4464: 'int', 4461: 'int', 4473: 'int', 4512: 'int', 4554: 'int', 4574: 'int', 4613: 'int', 4655: 'int', 4697: 'int', 4701: 'int', 4711: 'int', 4715: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x01-variables_if_else_while/5-print_numbers_elf_file_\n",
      "{4469: 'int', 4503: 'int', 4507: 'int'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x03-debugging/1-main_elf_file_\n",
      "{4452: 'int'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x03-debugging/positive_or_negative_elf_file_\n",
      "{4560: 'int', 4563: 'int', 4596: 'int', 4629: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x02-functions_nested_loops/104-fibonacci_elf_file_\n",
      "{4503: 'int', 4570: 'int', 4574: 'int', 4912: 'int', 4916: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x02-functions_nested_loops/103-fibonacci_elf_file_\n",
      "{4458: 'int', 4475: 'int', 4470: 'int', 4467: 'int', 4478: 'int', 4481: 'int', 4484: 'int', 4487: 'int', 4490: 'int', 4503: 'int', 4500: 'int', 4506: 'int'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x02-functions_nested_loops/0-putchar_elf_file_\n",
      "{}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x02-functions_nested_loops/102-fibonacci_elf_file_\n",
      "{4485: 'int', 4552: 'int', 4590: 'int', 4594: 'int'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x02-functions_nested_loops/101-natural_elf_file_\n",
      "{4444: 'int', 4453: 'int', 4491: 'int', 4535: 'int', 4532: 'int', 4538: 'int', 4542: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0F-function_pointers/100-main_opcodes_elf_file_\n",
      "{4583: 'int', 4636: 'int', 4682: '*char', 4676: 'int', 4748: 'int', 4745: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x15-file_io/3-cp_elf_file_\n",
      "{4639: 'int', 4645: '**char', 4659: '**char', 4694: 'int', 4700: '**char', 4714: '**char', 4795: 'int', 4937: 'int', 4943: 'int', 4930: '**char', 4981: 'int', 5019: '**char', 5058: 'int', 5091: '**char', 5146: 'int', 5133: 'int', 5152: 'int', 5217: 'int', 5204: 'int', 5223: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x15-file_io/100-elf_header_elf_file_\n",
      "{4729: 'int', 4738: 'int', 4758: 'int', 4778: 'int', 4798: 'int', 4853: 'int', 4857: 'int', 4903: 'int', 4912: 'int', 4953: 'int', 4981: 'int', 4985: 'int', 6260: 'int', 6369: 'int', 6375: '**char', 6389: '**char', 6445: 'int', 6455: '**char', 6469: '**char', 6529: 'int', 6547: 'int', 6557: '**char', 6571: '**char', 6765: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x17-doubly_linked_lists/103-keygen_elf_file_\n",
      "{4638: '*char', 4632: 'int', 4651: 'int', 4702: 'int', 4699: 'int', 4734: 'int', 4791: 'int', 4788: 'int', 4823: 'int', 4904: 'int', 4901: 'int', 4909: 'int', 4948: 'int', 5027: 'int', 5024: 'int', 5072: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x06-pointers_arrays_strings/102-magic_elf_file_\n",
      "{4495: '*int', 4491: 'int', 4499: '*int'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0A-argc_argv/2-args_elf_file_\n",
      "{4453: 'int', 4466: '**char', 4488: 'int', 4491: 'int'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0A-argc_argv/100-change_elf_file_\n",
      "{4590: 'int', 4643: 'int', 4671: 'int', 4678: 'int', 4681: 'int', 4684: 'int', 4693: 'int', 4711: 'int', 4732: 'int', 4750: 'int', 4754: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0A-argc_argv/3-mul_elf_file_\n",
      "{4508: 'int', 4587: 'int', 4583: 'int', 4580: 'int'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0A-argc_argv/0-whatsmyname_elf_file_\n",
      "{4444: '**char'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0A-argc_argv/1-args_elf_file_\n",
      "{}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0A-argc_argv/4-add_elf_file_\n",
      "{4540: 'int', 4661: 'int', 4674: '**char', 4741: 'int', 4744: 'int'}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x00-hello_world/6-size_elf_file_\n",
      "{}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x00-hello_world/4-puts_elf_file_\n",
      "{}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x00-hello_world/101-quote_elf_file_\n",
      "{}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x00-hello_world/5-printf_elf_file_\n",
      "{}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0D-preprocessor/1-main_elf_file_\n",
      "{}\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n",
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0D-preprocessor/4-main_elf_file_\n",
      "{4437: 'int'}\n",
      "<class 'TypeError'> 2528286154.py 182\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_250787/2528286154.py\", line 182, in <module>\n",
      "    process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
      "  File \"/home/nahid/reverse/codes/dwarf/process_typedata_for_model.py\", line 49, in process_data_4_model_and_save\n",
      "    for target_address, target_type in inst_type_data():\n",
      "TypeError: 'dict' object is not callable\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_*  *_* \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /home/nahid/dataset/clones/Princexz_____alx-low_level_programming/0x0D-preprocessor/3-main_elf_file_\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 172\u001b[0m\n\u001b[1;32m    167\u001b[0m lineinfo_address_subprogram_complete \u001b[38;5;241m=\u001b[39m produce_address_to_lineinfo_matrix(binary_path)\n\u001b[1;32m    169\u001b[0m FUNC_PARAMS \u001b[38;5;241m=\u001b[39m parse_dwarf_to_get_func_params(binary_path)\n\u001b[0;32m--> 172\u001b[0m variables_in_line \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_variable_per_line_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinary_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFUNC_PARAMS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m line_to_address_matrix \u001b[38;5;241m=\u001b[39m build_line_to_relatedAddresses_matrix(lineinfo_address_subprogram_complete)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m##############################################################################\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m##########################################################################\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 332\u001b[0m, in \u001b[0;36mcreate_variable_per_line_matrix\u001b[0;34m(filename, FUNCTION_PARAMS)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m#########\u001b[39;00m\n\u001b[1;32m    331\u001b[0m cu_src_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(CU_DIR_PATH, CU_FILENAME)\n\u001b[0;32m--> 332\u001b[0m cu_func_boundaries \u001b[38;5;241m=\u001b[39m\u001b[43mget_function_boundaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcu_src_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m cu_src_line_to_function_matrix \u001b[38;5;241m=\u001b[39m form_function_bound_metrix(cu_func_boundaries , CU_FILENAME)\n\u001b[1;32m    334\u001b[0m variables_in_line_matrix \u001b[38;5;241m=\u001b[39m find_variables_per_line(cu_src_path, cu_src_line_to_function_matrix , FUNCTION_PARAMS)\n",
      "Cell \u001b[0;32mIn[4], line 133\u001b[0m, in \u001b[0;36mget_function_boundaries\u001b[0;34m(source_path)\u001b[0m\n\u001b[1;32m    131\u001b[0m         function_name \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdisplayname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    132\u001b[0m         function_boundary_by_name[function_name]\u001b[38;5;241m=\u001b[39m{}\n\u001b[0;32m--> 133\u001b[0m         function_boundary_by_name[function_name] \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc_path\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    134\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc_file\u001b[39m\u001b[38;5;124m'\u001b[39m:f\u001b[38;5;241m.\u001b[39mextent\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    135\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_line\u001b[39m\u001b[38;5;124m'\u001b[39m:f\u001b[38;5;241m.\u001b[39mextent\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;241m.\u001b[39mline,\n\u001b[1;32m    136\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_col\u001b[39m\u001b[38;5;124m'\u001b[39m:f\u001b[38;5;241m.\u001b[39mextent\u001b[38;5;241m.\u001b[39mstart\u001b[38;5;241m.\u001b[39mcolumn,\n\u001b[1;32m    137\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_line\u001b[39m\u001b[38;5;124m'\u001b[39m:f\u001b[38;5;241m.\u001b[39mextent\u001b[38;5;241m.\u001b[39mend\u001b[38;5;241m.\u001b[39mline,\n\u001b[1;32m    138\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_col\u001b[39m\u001b[38;5;124m'\u001b[39m:f\u001b[38;5;241m.\u001b[39mextent\u001b[38;5;241m.\u001b[39mend\u001b[38;5;241m.\u001b[39mcolumn}\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_boundary_by_name\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/clang/cindex.py:272\u001b[0m, in \u001b[0;36mSourceLocation.file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfile\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    271\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the file represented by this source location.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_instantiation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/clang/cindex.py:244\u001b[0m, in \u001b[0;36mSourceLocation._get_instantiation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m f, l, c, o \u001b[38;5;241m=\u001b[39m c_object_p(), c_uint(), c_uint(), c_uint()\n\u001b[1;32m    242\u001b[0m conf\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mclang_getInstantiationLocation(\u001b[38;5;28mself\u001b[39m, byref(f), byref(l),\n\u001b[1;32m    243\u001b[0m         byref(c), byref(o))\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f:\n\u001b[1;32m    245\u001b[0m     f \u001b[38;5;241m=\u001b[39m File(f)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from process_typedata_for_model import *\n",
    "def do_magic():\n",
    "    all_inst_to_type = {}\n",
    "    for cu_path, all_func_data in line_to_address_matrix.items():\n",
    "        for func, func_data in all_func_data.items():\n",
    "            for line_col, line_addresses in func_data.items():\n",
    "                line = int(line_col.split('_')[0])\n",
    "\n",
    "                #################### PROCESS ADDRESS LIST ##############################\n",
    "\n",
    "                inst_matrix = {  }\n",
    "                twin_instructions = {}\n",
    "                for address in line_addresses:\n",
    "                    address_hex = hex(address)\n",
    "                    inst = VALID_INSTRUCTIONS_SET[address]\n",
    "                    instrctionCode = (address_hex+\":\\t\"+ inst.mnemonic+\" \"+inst.op_str).ljust(45)\n",
    "\n",
    "                    disp = None\n",
    "                    if len(inst.operands) > 0 :\n",
    "                        oc=-1\n",
    "                        for o in inst.operands:\n",
    "                            oc += 1\n",
    "                            if o.type == CS_OP_MEM:\n",
    "                                if o.value.mem.disp != 0:\n",
    "                                    disp = o.value.mem.disp\n",
    "\n",
    "                                    if disp not in inst_matrix.values():\n",
    "                                        inst_matrix[address_hex]=disp\n",
    "                                    else:\n",
    "\n",
    "                                        twin_hex = list(inst_matrix.keys())[list(inst_matrix.values()).index(disp)] \n",
    "                                        if twin_hex not in twin_instructions:\n",
    "                                            twin_instructions[twin_hex] = [address_hex]\n",
    "                                        else:\n",
    "                                            twin_instructions[twin_hex].append(address_hex)\n",
    "                                        #TODO twin inst\n",
    "                inst_matrix = dict(sorted(inst_matrix.items(), key=lambda x: x[1] , reverse=True))\n",
    "\n",
    "\n",
    "\n",
    "                #######################  PROCESS SRC VARIABLES #############################\n",
    "                if line in variables_in_line[cu_path]: #ALL LINES SHOULD BE VALID, should not check\n",
    "                    var_list = variables_in_line[cu_path][line]\n",
    "                    var_matrix = {} \n",
    "                    \n",
    "                    \n",
    "                    for col,var in var_list.items():\n",
    "\n",
    "                        if 'location' in var['dwarf_info'] :\n",
    "                            if ('DW_OP_fbreg' in var['dwarf_info']['location']): #TODO, use regex.\n",
    "                                var_matrix[var['name']] = int(var['dwarf_info']['location'].split(':')[-1][:-1])\n",
    "\n",
    "                    var_matrix = dict (sorted(var_matrix.items(), key=lambda x: x[1] , reverse=True))\n",
    "\n",
    "\n",
    "                    ########################################\n",
    "                    ############# Compare & Align  ################\n",
    "                    ########################################\n",
    "                    inst_matrix_len = len(inst_matrix.items())\n",
    "                    var_matrix_len  = len( var_matrix.items())\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    #TODO\n",
    "                    # rule 1: they have single inst and single var, so just match\n",
    "                    if inst_matrix_len==1 and var_matrix_len==1:\n",
    "\n",
    "                        types = vars_to_types(list(var_matrix.keys()), cu_path, func)\n",
    "                        insts = list(inst_matrix.keys())\n",
    "\n",
    "                        inst_to_type = assign_twin_instructions_types(insts,types,twin_instructions)\n",
    "#                         all_inst_to_type = all_inst_to_type | inst_to_type\n",
    "                        all_inst_to_type = {**all_inst_to_type , **inst_to_type}\n",
    "        \n",
    "\n",
    "                    #TODO\n",
    "                    # rule 2: if one have 1 item and another have 1+ item, can match\n",
    "                    #         only with coloumn alignment\n",
    "                    if 1 in [inst_matrix_len,var_matrix_len] and \\\n",
    "                            abs(inst_matrix_len-var_matrix_len)>0:\n",
    "                        continue\n",
    "\n",
    "                    #TODO\n",
    "                    # rule 3: if there are multiple longest matches\n",
    "                    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    inst_matrix = diff_dict(inst_matrix)\n",
    "\n",
    "                    var_matrix = diff_dict(var_matrix)\n",
    "\n",
    "\n",
    "                    match = SequenceMatcher(isjunk = None, \n",
    "                                            a=list(var_matrix.values()), \n",
    "                                            b=list(inst_matrix.values()),\n",
    "                                            autojunk=True).find_longest_match(alo=0, ahi=len(var_matrix.values()), blo=0, bhi=len(inst_matrix.values()))\n",
    "\n",
    "                    if match.size>0:#found matching seq\n",
    "#                         print(\"MATCHED!\",match,var_matrix.keys() ,inst_matrix.keys() )\n",
    "\n",
    "                        var_matches  = list(var_matrix.keys()) [match.a:(match.a+match.size)+1]\n",
    "                        inst_matches = list(inst_matrix.keys())[match.b:(match.b+match.size)+1]\n",
    "\n",
    "#                         print('var_matches: ',var_matches , ' INST matches:',inst_matches)\n",
    "\n",
    "                        ### assign types\n",
    "                        types = vars_to_types(var_matches, cu_path, func)\n",
    "#                         print('inst_matches: ', inst_matches, '\\n types', types )\n",
    "\n",
    "                        ### handle twin,\n",
    "                        inst_to_type = assign_twin_instructions_types(inst_matches,types,twin_instructions)\n",
    "#                         all_inst_to_type = all_inst_to_type | inst_to_type\n",
    "                        all_inst_to_type = {**all_inst_to_type , **inst_to_type}\n",
    "                        \n",
    "    return all_inst_to_type \n",
    "################################################\n",
    "###################################################\n",
    "#####################################################\n",
    "\n",
    "\n",
    "\n",
    "error_log = open(\"error.log\", \"w\")\n",
    "counter = 0\n",
    "for binary_path in (ELF_FILE_PATHS) : \n",
    "    \n",
    "    unique_path = binary_path.split('clones')[1]\n",
    "    unique_pkl_file_name=(hashlib.md5(unique_path.encode())).hexdigest()\n",
    "    analysed_pkl_path = os.path.join( ANALYSIS_DATA_PATH ,unique_pkl_file_name+'.pkl')\n",
    "    \n",
    "    if os.path.isfile(analysed_pkl_path) == False:#no analysis file present\n",
    "        continue\n",
    "        \n",
    "    \n",
    "\n",
    "    binFileName = os.path.basename(binary_path)\n",
    "    \n",
    "\n",
    "    \n",
    "    if check_dwarf_ok(binary_path)== False:\n",
    "        continue\n",
    "    \n",
    "    print(\" *_* \"*10)\n",
    "\n",
    "    \n",
    "    MIN_ADDRESS, MAX_ADDRESS =  get_min_max_address(binary_path)\n",
    "\n",
    "\n",
    "    #Load the analysed data\n",
    "    with (open(analysed_pkl_path , \"rb\")) as openfile:\n",
    "        bb_data , ins_data , tool_addresses_list = pickle.load(openfile)\n",
    "    \n",
    "    try:\n",
    "        VALID_INSTRUCTIONS_SET = get_valid_instructions(binary_path,tool_addresses_list,min_address=MIN_ADDRESS, max_address=MAX_ADDRESS)\n",
    "        connected_addrs_and_program_slice = process_graphs(ins_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##########################################################\n",
    "    ################ CREATE HELPER DATA STRUCTURES   #########\n",
    "    ##########################################################\n",
    "    \n",
    "\n",
    "        # create matrix for finding lineinfo for each address\n",
    "        lineinfo_address_subprogram_complete = produce_address_to_lineinfo_matrix(binary_path)\n",
    "\n",
    "        FUNC_PARAMS = parse_dwarf_to_get_func_params(binary_path)\n",
    "\n",
    "\n",
    "        variables_in_line = create_variable_per_line_matrix(binary_path, FUNC_PARAMS)\n",
    "\n",
    "        line_to_address_matrix = build_line_to_relatedAddresses_matrix(lineinfo_address_subprogram_complete)\n",
    "        \n",
    "        ##############################################################################\n",
    "        ##########################################################################\n",
    "        inst_type_info = do_magic()\n",
    "        write_illustrated_file(binFileName ,lineinfo_address_subprogram_complete , inst_type_info)\n",
    "        \n",
    "        ###################################################################################\n",
    "        process_data_4_model_and_save(VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info,unique_pkl_file_name)\n",
    "        \n",
    "#         VALID_INSTRUCTIONS_SET , connected_addrs_and_program_slice,inst_type_info\n",
    "        \n",
    "    \n",
    "    except Exception as e:#TODO, solve the most frequent errors\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(exc_type, fname, exc_tb.tb_lineno)\n",
    "        print(traceback.format_exc(),'\\n\\n\\n\\n')\n",
    "        error_log.write('\\n\\n')\n",
    "        error_log.write(' analysed_pkl_path: '+ analysed_pkl_path + '\\n')\n",
    "        error_log.write(str(exc_type) +\" fname: \"+fname + \" lineno: \"+ str(exc_tb.tb_lineno) )\n",
    "    counter+=1\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c0c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SUBHANALLAH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4fea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c03a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
